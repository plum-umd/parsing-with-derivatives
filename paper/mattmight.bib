@inproceedings{mattmight:Earl:2010:Pushdown,
    address = {Montreal, Canada},
    author = {Earl, Christopher and Might, Matthew and Van Horn, David},
    booktitle = {Proceedings of the 2010 Workshop on Scheme and Functional Programming},
    citeulike-article-id = {9169357},
    date-added = {2011-04-18 05:08:46},
    key = {Earl:2010:Pushdown},
    keywords = {pushdown-analysis, static-analysis},
    month = aug,
    priority = {2},
    title = {Pushdown control-flow analysis of higher-order programs},
    year = {2010}
}

@inproceedings{mattmight:Might:2010:Free,
    abstract = {In small-step abstract interpretations, the concrete and abstract semantics bear an uncanny resemblance. In this work, we present an analysis-design methodology that both explains and exploits that resemblance. Specifically, we present a two-step method to convert a smallstep concrete semantics into a family of sound, computable abstract interpretations. The first step re-factors the concrete state-space to eliminate recursive structure; this refactoring of the state-space simultaneously determines a store-passing-style transformation on the underlying concrete semantics. The second step uses inference rules to generate an abstract state-space and a Galois connection simultaneously. The Galois connection allows the calculation of the "optimal" abstract interpretation. The two-step process is unambiguous, but nondeterministic: at each step, analysis designers face choices. Some of these choices ultimately influence properties such as flow-, field- and context-sensitivity. Thus, under the method, we can give the emergence of these properties a graphtheoretic characterization. To illustrate the method, we systematically abstract the continuation-passing style lambda calculus to arrive at two distinct families of analyses. The first is the well-known {k-CFA} family of analyses. The second consists of novel "environment-centric" abstract interpretations, none of which appear in the literature on static analysis of higher-order programs.},
    author = {Might, Matthew},
    booktitle = {SAS 2010: Proceedings of the 17th {S}tatic {A}nalysis {S}ymposium},
    citeulike-article-id = {9169193},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1882119},
    date-added = {2011-04-18 01:25:03},
    isbn = {3-642-15768-8, 978-3-642-15768-4},
    keywords = {abstract-interpretation, cfa, static-analysis},
    location = {Perpignan, France},
    pages = {407--421},
    priority = {0},
    publisher = {Springer-Verlag},
    series = {SAS'10},
    title = {Abstract interpreters for free},
    url = {http://portal.acm.org/citation.cfm?id=1882119},
    year = {2010}
}

@article{mattmight:Schmidt:2007:State,
    abstract = {History and context are given regarding the development of the {WNF}-machine, the first example of a Krivine machine.},
    address = {Hingham, MA, USA},
    author = {Schmidt, David A.},
    citeulike-article-id = {9122654},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1325150},
    date-added = {2011-04-18 00:05:28},
    issn = {1388-3690},
    journal = {Higher Order Symbol. Comput.},
    keywords = {formal-semantics},
    month = sep,
    pages = {333--335},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {State-transition machines, revisited},
    url = {http://portal.acm.org/citation.cfm?id=1325150},
    volume = {20},
    year = {2007}
}

@article{mattmight:Aiken:1999:Constraint,
    abstract = {This paper given an introduction to using set constraints to specify program analyses. Several standard analysis problems are formulated using set constraints, which serves both to illustrate the style of using constraints to specify program analysis problems and the range of application of set constraints.},
    author = {Aiken, A.},
    citeulike-article-id = {4153},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=339897},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/S0167-6423(99)00007-6},
    citeulike-linkout-2 = {http://linkinghub.elsevier.com/retrieve/pii/S0167-6423(99)00007-6},
    date-added = {2011-04-17 23:53:12},
    doi = {10.1016/S0167-6423(99)00007-6},
    issn = {01676423},
    journal = {Science of Computer Programming},
    keywords = {set-based-analysis, static-analysis},
    month = nov,
    number = {2-3},
    pages = {79--111},
    priority = {2},
    publisher = {Elsevier North-Holland, Inc.},
    title = {Introduction to set constraint-based program analysis},
    url = {http://dx.doi.org/10.1016/S0167-6423(99)00007-6},
    volume = {35},
    year = {1999}
}

@article{mattmight:Cousot:2002:Hierarchy,
    abstract = {We construct a hierarchy of semantics by successive abstract interpretations. Starting from the maximal trace semantics of a transition system, we derive the big-step semantics, termination and nontermination semantics, Plotkin's natural, Smyth's demoniac and Hoare's angelic relational semantics and equivalent nondeterministic denotational semantics (with alternative powerdomains to the {Egli–Milner} and Smyth constructions), D. Scott's deterministic denotational semantics, the generalized and Dijkstra's conservative/liberal predicate transformer semantics, the generalized/total and Hoare's partial correctness axiomatic semantics and the corresponding proof methods. All the semantics are presented in a uniform fixpoint form and the correspondences between these semantics are established through composable Galois connections, each semantics being formally calculated by abstract interpretation of a more concrete one using Kleene and/or Tarski fixpoint approximation transfer theorems.},
    author = {Cousot, P.},
    citeulike-article-id = {4298357},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0304-3975(00)00313-3},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0304-3975(00)00313-3},
    date-added = {2011-04-17 22:15:23},
    day = {28},
    doi = {10.1016/S0304-3975(00)00313-3},
    issn = {03043975},
    journal = {Theoretical Computer Science},
    keywords = {abstract-interpretation, static-analysis},
    month = apr,
    number = {1-2},
    pages = {47--103},
    priority = {2},
    title = {Constructive design of a hierarchy of semantics of a transition system by abstract interpretation},
    url = {http://dx.doi.org/10.1016/S0304-3975(00)00313-3},
    volume = {277},
    year = {2002}
}

@inproceedings{mattmight:Prabhu:2011:EigenCFA,
    abstract = {We describe, implement and benchmark {EigenCFA}, an algorithm for accelerating higher-order control-flow analysis (specifically, {0CFA}) with a {GPU}. Ultimately, our program transformations, reductions and optimizations achieve a factor of 72 speedup over an optimized {CPU} implementation. We began our investigation with the view that {GPUs} accelerate high-arithmetic, data-parallel computations with a poor tolerance for branching. Taking that perspective to its limit, we reduced Shivers's abstract-interpretive {0CFA} to an algorithm synthesized from linear-algebra operations. Central to this reduction were "abstract" Church encodings, and encodings of the syntax tree and abstract domains as vectors and matrices. A straightforward (dense-matrix) implementation of {EigenCFA} performed slower than a fast {CPU} implementation. Ultimately, sparse-matrix data structures and operations turned out to be the critical accelerants. Because control-flow graphs are sparse in practice (up to 96\% empty), our control-flow matrices are also sparse, giving the sparse matrix operations an overwhelming space and speed advantage. We also achieved speedups by carefully permitting data races. The monotonicity of {0CFA} makes it sound to perform analysis operations in parallel, possibly using stale or even partially-updated data.},
    address = {New York, NY, USA},
    author = {Prabhu, Tarun and Ramalingam, Shreyas and Might, Matthew and Hall, Mary},
    booktitle = {Proceedings of the 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {8760993},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1926385.1926445},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1925844.1926445},
    date-added = {2011-04-17 22:04:04},
    doi = {10.1145/1925844.1926445},
    issn = {0362-1340},
    keywords = {cfa, gpu, static-analysis},
    month = jan,
    pages = {511--522},
    priority = {0},
    publisher = {ACM Press},
    title = {{EigenCFA}: Accelerating flow analysis with {GPUs}},
    url = {http://dx.doi.org/10.1145/1925844.1926445},
    volume = {38},
    year = {2011}
}

@inproceedings{mattmight:Jensen:2009:TAJS,
    abstract = {{JavaScript} is the main scripting language for Web browsers, and it is essential to modern Web applications. Programmers have started using it for writing complex applications, but there is still little tool support available during development. We present a static program analysis infrastructure that can infer detailed and sound type information for {JavaScript} programs using abstract interpretation. The analysis is designed to support the full language as defined in the {ECMAScript} standard, including its peculiar object model and all built-in functions. The analysis results can be used to detect common programming errors --- or rather, prove their absence, and for producing type information for program comprehension. Preliminary experiments conducted on real-life {JavaScript} code indicate that the approach is promising regarding analysis precision on small and medium size programs, which constitute the majority of {JavaScript} applications. With potential for further improvement, we propose the analysis as a foundation for building tools that can aid {JavaScript} programmers.},
    address = {Berlin, Heidelberg},
    author = {Jensen, Simon H. and M{\o}ller, Anders and Thiemann, Peter},
    booktitle = {Proceedings of the 16th International Symposium on Static Analysis},
    chapter = {17},
    citeulike-article-id = {7228966},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1615441.1615460},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-642-03237-0\_17},
    citeulike-linkout-2 = {http://www.springerlink.com/content/yv60v168w42k2484},
    date-added = {2011-04-08 21:25:09},
    doi = {10.1007/978-3-642-03237-0\_17},
    isbn = {978-3-642-03236-3},
    keywords = {javascript, static-analysis},
    location = {Los Angeles, CA},
    pages = {238--255},
    priority = {2},
    publisher = {Springer-Verlag},
    series = {SAS '09},
    title = {Type Analysis for {JavaScript}},
    url = {http://dx.doi.org/10.1007/978-3-642-03237-0\_17},
    volume = {5673},
    year = {2009}
}

@inproceedings{mattmight:Jensen:2010:Interprocedural,
    abstract = {We propose lazy propagation as a technique for flow- and context-sensitive interprocedural analysis of programs with objects and first-class functions where transfer functions may not be distributive. The technique is described formally as a systematic modification of a variant of the monotone framework and its theoretical properties are shown. It is implemented in a type analysis tool for {JavaScript} where it results in a significant improvement in performance.},
    address = {Berlin, Heidelberg},
    author = {Jensen, Simon H. and M{\o}ller, Anders and Thiemann, Peter},
    booktitle = {Proceedings of the 17th international conference on Static analysis},
    citeulike-article-id = {9122734},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1882114},
    date-added = {2011-04-08 21:15:10},
    isbn = {3-642-15768-8, 978-3-642-15768-4},
    keywords = {javascript},
    location = {Perpignan, France},
    pages = {320--339},
    priority = {2},
    publisher = {Springer-Verlag},
    series = {SAS'10},
    title = {Interprocedural analysis with lazy propagation},
    url = {http://portal.acm.org/citation.cfm?id=1882114},
    year = {2010}
}

@inproceedings{mattmight:Queinnec:2000:Browsers,
    abstract = {While developping the software of a browser-operated educational {CD}-{ROM}, we had to face a number of problems. This paper presents these problems and the solutions we found. Amusingly, most of our solutions rely on continuations. Are browsers and multimedia the future of continuations ? Through their ``Back'' button or ``Clone window'' menu item, browsers have powerful abilities that force servers to take care of multiply and simultaneously answered questions. A comprehensive tool to apprehend these problems as well as to solve them is to view these abilities as operators acting on the continuations of the computation performed by servers. Thematical trails are provided to walk through the {CD}-{ROM} but do not prevent students to wander elsewhere. A trail may contain choices or quizzes so the rest of the trail should adapt to the walked part. We consider the trail as a computation and the position of the student as a continuation within that computation. Moreover this paper advocates a computation-centric view of servers (in opposition to the usual page-centric view) where interactions with users suspend the computation into continuations that may be later resumed. This approach is superior because the continuation reifies automatically and without errors the whole state of the computation.},
    address = {Montreal (Canada)},
    author = {Queinnec, Christian},
    citeulike-article-id = {9063601},
    citeulike-linkout-0 = {http://youpou.lip6.fr/queinnec/VideoC/ps3i.html},
    date-added = {2011-03-26 03:16:25},
    keywords = {continuations},
    month = sep,
    pages = {23--33},
    priority = {2},
    title = {The Influence of Browsers on Evaluators or, Continuations to Program Web Servers},
    url = {http://youpou.lip6.fr/queinnec/VideoC/ps3i.html},
    year = {2000}
}

@incollection{mattmight:Navabi:2009:Futures,
    abstract = {A future is a well-known programming construct used to introduce concurrency to sequential programs. Computations annotated as futures are executed asynchronously and run concurrently with their continuations. Typically, futures are not transparent annotations: a program with futures need not produce the same result as the sequential program from which it was derived. Safe futures guarantee a future-annotated program produce the same result as its sequential counterpart. Ensuring safety is especially challenging in the presence of constructs such as exceptions that permit the expression of non-local control-flow. For example, a future may raise an exception whose handler is in its continuation. To ensure safety, we must guarantee the continuation does not discard this handler regardless of the continuation's own internal control-flow (e.g. exceptions it raises or futures it spawns). In this paper, we present a formulation of safe futures for a higher-order functional language with first-class exceptions. Safety can be guaranteed dynamically by stalling the execution of a continuation that has an exception handler potentially required by its future until the future completes. To enable greater concurrency, we develop a static analysis and instrumentation and formalize the runtime behavior for instrumented programs that allows execution to discard handlers precisely when it is safe to do so.},
    address = {Berlin, Heidelberg},
    author = {Navabi, Armand and Jagannathan, Suresh},
    booktitle = {Coordination Models and Languages},
    chapter = {3},
    citeulike-article-id = {7750280},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-02053-7\_3},
    citeulike-linkout-1 = {http://www.springerlink.com/content/n2780775v1545662},
    date-added = {2011-03-25 20:21:23},
    doi = {10.1007/978-3-642-02053-7\_3},
    editor = {Field, John and Vasconcelos, Vasco},
    isbn = {978-3-642-02052-0},
    keywords = {futures, parallelism},
    pages = {47--65},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {Exceptionally Safe Futures},
    url = {http://dx.doi.org/10.1007/978-3-642-02053-7\_3},
    volume = {5521},
    year = {2009}
}

@article{mattmight:Flanagan:1999:Futures,
    abstract = {The future annotation of {MultiLisp} provides a simple method for taming the implicit parallelism of functional programs. Prior research on future has concentrated on implementation and design issues, and has largely ignored the development of a semantic characterization of future. This paper considers an idealized functional language with futures and presents a series of operational semantics with increasing degrees of intensionality. The first semantics defines future to be a semantically transparent annotation. The second semantics interprets a future expression as a potentially parallel task. The third semantics explicates the coordination of parallel tasks by introducing placeholder objects and touch {operations.We} use the last semantics to derive a program analysis algorithm and an optimization algorithm that removes provably redundant touch operations. Experiments with the Gambit compiler indicate that this optimization significantly reduces the overhead imposed by touch operations.},
    author = {Flanagan, C. and Felleisen, M.},
    citeulike-article-id = {7796538},
    citeulike-linkout-0 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=44231},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/S0956796899003329},
    date-added = {2011-03-25 19:43:17},
    doi = {10.1017/S0956796899003329},
    journal = {Journal of Functional Programming},
    keywords = {futures, parallelism},
    number = {01},
    pages = {1--31},
    priority = {4},
    title = {The semantics of future and an application},
    url = {http://dx.doi.org/10.1017/S0956796899003329},
    volume = {9},
    year = {1999}
}

@inproceedings{mattmight:Danielsson:2010:Total,
    abstract = {A monadic parser combinator library which guarantees termination of parsing, while still allowing many forms of left recursion, is described. The library's interface is similar to those of many other parser combinator libraries, with two important differences: one is that the interface clearly specifies which parts of the constructed parsers may be infinite, and which parts have to be finite, using dependent types and a combination of induction and coinduction; and the other is that the parser type is unusually informative. The library comes with a formal semantics, using which it is proved that the parser combinators are as expressive as possible. The implementation is supported by a machine-checked correctness proof.},
    address = {New York, NY, USA},
    author = {Danielsson, Nils A.},
    booktitle = {Proceedings of the 15th ACM SIGPLAN international conference on Functional programming},
    citeulike-article-id = {8346185},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1863585},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1863543.1863585},
    date-added = {2011-03-23 23:53:23},
    doi = {10.1145/1863543.1863585},
    isbn = {978-1-60558-794-3},
    location = {Baltimore, Maryland, USA},
    pages = {285--296},
    priority = {2},
    publisher = {ACM},
    series = {ICFP '10},
    title = {Total parser combinators},
    url = {http://dx.doi.org/10.1145/1863543.1863585},
    year = {2010}
}

@inproceedings{mattmight:Swierstra:1998:Combinator,
    abstract = {this paper we will assume the
availablity of a set of parsing combinators, that enables us to coinstruct such
a mapping almost without e\#ort.},
    author = {Swierstra, Doaitse S. and Pablo and Sariava, Joao},
    booktitle = {Advanced Functional Programming},
    citeulike-article-id = {2637235},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.30.4121},
    date-added = {2011-03-23 21:42:03},
    pages = {150--206},
    priority = {2},
    title = {Designing and Implementing Combinator Languages},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.30.4121},
    year = {1998}
}

@incollection{mattmight:Swierstra:2009:Tutorial,
    abstract = {There are numerous ways to implement a parser for a given syntax; using parser combinators is a powerful approach to parsing which derives much of its power and expressiveness from the type system and semantics of the host programming language. This tutorial begins with the construction of a small library of parsing combinators. This library introduces the basics of combinator parsing and, more generally, demonstrates how domain specific embedded languages are able to leverage the facilities of the host language. After having constructed our small combinator library, we investigate some shortcomings of the na\"{i}ve implementation introduced in the first part, and incrementally develop an implementation without these problems. Finally we discuss some further extensions of the presented library and compare our approach with similar libraries.},
    address = {Berlin, Heidelberg},
    author = {Swierstra, S.},
    booktitle = {Language Engineering and Rigorous Software Development},
    chapter = {6},
    citeulike-article-id = {6258618},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-03153-3\_6},
    citeulike-linkout-1 = {http://www.springerlink.com/content/t6j722881374302g},
    date-added = {2011-03-23 21:40:15},
    doi = {10.1007/978-3-642-03153-3\_6},
    editor = {Bove,, Ana and Barbosa,, Lu\'{\i}s and Pardo,, Alberto and Pinto,, Jorge},
    isbn = {978-3-642-03152-6},
    journal = {Language Engineering and Rigorous Software Development},
    pages = {252--300},
    priority = {0},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {Combinator Parsing: A Short Tutorial},
    url = {http://dx.doi.org/10.1007/978-3-642-03153-3\_6},
    volume = {5520},
    year = {2009}
}

@book{mattmight:Appel:1991:Compiling,
    abstract = {{This book shows how continuation-passing style is used as an intermediate representation to perform optimizations and program transformations. Continuations can be used to compile most programming languages.  The method is illustrated in a compiler for the programming language Standard ML.  Prior knowledge of ML, however, is not necessary, as the author carefully explains each concept as it arises. This is the first book to show how concepts from the theory of programming languages can be applied to the production of practical optimizing compilers for modern languages like ML. All the details of compiling are covered, including the interface to a runtime system and garbage collector.}},
    author = {Appel, Andrew W.},
    citeulike-article-id = {2429806},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0521416957},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0521416957},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0521416957},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0521416957},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0521416957/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0521416957},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0521416957},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0521416957},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0521416957\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0521416957},
    date-added = {2010-12-16 06:16:43},
    day = {29},
    howpublished = {Hardcover},
    isbn = {0521416957},
    keywords = {compilers},
    month = nov,
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Compiling with Continuations},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0521416957},
    year = {1991}
}

@inproceedings{mattmight:Lopes:2011:Distributed,
    author = {Lopes, Nuno P. and Rybalchenko, Andrey},
    booktitle = {Proc. of the 12th International Conference on Verification, Model Checking, and Abstract Interpretation (VMCAI)},
    citeulike-article-id = {8219702},
    date-added = {2010-11-08 21:26:29},
    keywords = {model-checking, parallelism, static-analysis},
    month = jan,
    priority = {2},
    title = {{Distributed and Predictable Software Model Checking}},
    year = {2011}
}

@inproceedings{mattmight:VanHorn:2010:Abstract,
    abstract = {We describe a derivational approach to abstract interpretation that yields novel and transparently sound static analyses when applied to well-established abstract machines. To demonstrate the technique and support our claim, we transform the {CEK} machine of Felleisen and Friedman, a lazy variant of Krivine's machine, and the stack-inspecting {CM} machine of Clements and Felleisen into abstract interpretations of themselves. The resulting analyses bound temporal ordering of program events; predict return-flow and stack-inspection behavior; and approximate the flow and evaluation of by-need parameters. For all of these machines, we find that a series of well-known concrete machine refactorings, plus a technique we call store-allocated continuations, leads to machines that abstract into static analyses simply by bounding their stores. We demonstrate that the technique scales up uniformly to allow static analysis of realistic language features, including tail calls, conditionals, side effects, exceptions, first-class continuations, and even garbage collection.},
    author = {Van Horn, David and Might, Matthew},
    booktitle = {ICFP '10: Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {7956643},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1863543.1863553},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1863543.1863553},
    date-added = {2010-11-08 20:29:18},
    doi = {10.1145/1863543.1863553},
    isbn = {978-1-60558-794-3},
    keywords = {cfa, control-flow-analysis, static-analysis},
    location = {Baltimore, Maryland, USA},
    pages = {51--62},
    priority = {2},
    publisher = {ACM Press},
    title = {Abstracting abstract machines},
    url = {http://dx.doi.org/10.1145/1863543.1863553},
    year = {2010}
}

@article{mattmight:Mendez-Lojo:2010:PointsTo,
    abstract = {Inclusion-based points-to analysis provides a good trade-off between precision of results and speed of analysis, and it has been incorporated into several production compilers including gcc. There is an extensive literature on how to speed up this algorithm using heuristics such as detecting and collapsing cycles of pointer-equivalent variables. This paper describes a complementary approach based on exploiting parallelism. Our implementation exploits two key insights. First, we show that inclusion-based points-to analysis can be formulated entirely in terms of graphs and graph rewrite rules. This exposes the amorphous data-parallelism in this algorithm and makes it easier to develop a parallel implementation. Second, we show that this graph-theoretic formulation reveals certain key properties of the algorithm that can be exploited to obtain an efficient parallel implementation. Our parallel implementation achieves a scaling of up to 3x on a 8-core machine for a suite of ten large C programs. For all but the smallest benchmarks, the parallel analysis outperforms a state-of-the-art, highly optimized, serial implementation of the same algorithm. To the best of our knowledge, this is the first parallel implementation of a points-to analysis.},
    address = {New York, NY, USA},
    author = {M\'{e}ndez-Lojo, Mario and Mathew, Augustine and Pingali, Keshav},
    booktitle = {Proceedings of the ACM International Conference on Object Oriented Programming Systems languages and Applications},
    citeulike-article-id = {8219643},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1869459.1869495},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1869459.1869495},
    date-added = {2010-11-08 20:27:48},
    doi = {10.1145/1869459.1869495},
    isbn = {978-1-4503-0203-6},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {parallelism, static-analysis},
    location = {Reno/Tahoe, Nevada, USA},
    month = oct,
    pages = {428--443},
    priority = {2},
    publisher = {ACM},
    series = {OOPSLA '10},
    title = {Parallel inclusion-based points-to analysis},
    url = {http://dx.doi.org/10.1145/1869459.1869495},
    volume = {45},
    year = {2010}
}

@inproceedings{mattmight:Chaudhuri:2008:Subcubic,
    abstract = {We show that the reachability problem for recursive state machines (or equivalently, pushdown systems), believed for long to have cubic worst-case complexity, can be solved in slightly subcubic time. All that is necessary for the new bound is a simple adaptation of a known technique. We also show that a better algorithm exists if the input machine does not have infinite recursive loops.},
    address = {New York, NY, USA},
    author = {Chaudhuri, Swarat},
    booktitle = {Proceedings of the 35th annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {8219613},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1328460},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1328438.1328460},
    date-added = {2010-11-08 20:09:29},
    doi = {10.1145/1328438.1328460},
    isbn = {978-1-59593-689-9},
    keywords = {algorithm, static-analysis},
    location = {San Francisco, California, USA},
    pages = {159--169},
    priority = {3},
    publisher = {ACM},
    series = {POPL '08},
    title = {Subcubic algorithms for recursive state machines},
    url = {http://dx.doi.org/10.1145/1328438.1328460},
    year = {2008}
}

@inproceedings{mattmight:Might:2010:mCFA,
    abstract = {Low-level program analysis is a fundamental problem, taking the shape of "flow analysis" in functional languages and "points-to" analysis in imperative and object-oriented languages. Despite the similarities, the vocabulary and results in the two communities remain largely distinct, with limited cross-understanding. One of the few links is Shivers's {k-CFA} work, which has advanced the concept of "context-sensitive analysis" and is widely known in both communities. Recent results indicate that the relationship between the functional and object-oriented incarnations of {k-CFA} is not as well understood as thought. Van Horn and Mairson proved {k-CFA} for k ≥ 1 to be {EXPTIME}-complete; hence, no polynomial-time algorithm can exist. Yet, there are several polynomial-time formulations of context-sensitive points-to analyses in object-oriented languages. Thus, it seems that functional {k-CFA} may actually be a profoundly different analysis from object-oriented {k-CFA}. We resolve this paradox by showing that the exact same specification of {k-CFA} is polynomial-time for object-oriented languages yet exponential-time for functional ones: objects and closures are subtly different, in a way that interacts crucially with context-sensitivity and complexity. This illumination leads to an immediate payoff: by projecting the object-oriented treatment of objects onto closures, we derive a polynomial-time hierarchy of context-sensitive {CFAs} for functional programs.},
    author = {Might, Matthew and Smaragdakis, Yannis and Van Horn, David},
    booktitle = {PLDI '10: Proceedings of the 2010 ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {7329790},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1806596.1806631},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1806596.1806631},
    date-added = {2010-07-13 23:19:09},
    doi = {10.1145/1806596.1806631},
    isbn = {978-1-4503-0019-3},
    keywords = {cfa, control-flow-analysis, k-cfa, kcfa, m-cfa, mcfa},
    location = {Toronto, Ontario, Canada},
    pages = {305--315},
    priority = {0},
    publisher = {ACM Press},
    series = {PLDI '10},
    title = {Resolving and exploiting the k-{CFA} paradox: {I}lluminating functional vs. object-oriented program analysis},
    url = {http://dx.doi.org/10.1145/1806596.1806631},
    year = {2010}
}

@inproceedings{mattmight:Thiemann:2005:Strings,
    abstract = {We specify a polymorphic type system for an applied lambda calculus that refines the string type with a subtype hierarchy derived from language containment. It enables us to find a language for each string-type expression such that the value of the expression is a member of that language. Type inference for this system infers language inclusion constraints that can be viewed as a context-free grammar with a nonterminal for each string-valued {expression.Then} we present two algorithms that solve language inclusion constraints with respect to a fixed context-free reference grammar. The solutions are sound but incomplete because the general problem of context-free language inclusion is undecidable. Both algorithms are derived from Earley's parsing algorithm for context-free {languages.Taking} the two parts together enables us to answer questions like: Is the value of a string-type expression derivable from a given nonterminal in the reference grammar?},
    address = {New York, NY, USA},
    author = {Thiemann, Peter},
    booktitle = {TLDI 2005: Proceedings of the 2005 ACM SIGPLAN International Workshop on Types in Languages Design and Implementation},
    citeulike-article-id = {1864427},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1040294.1040300},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1040294.1040300},
    date-added = {2010-06-25 17:46:11},
    doi = {10.1145/1040294.1040300},
    isbn = {1-58113-999-3},
    keywords = {javascript, string-analysis},
    location = {Long Beach, California, USA},
    pages = {59--70},
    priority = {2},
    publisher = {ACM},
    title = {Grammar-based analysis of string expressions},
    url = {http://dx.doi.org/10.1145/1040294.1040300},
    year = {2005}
}

@inproceedings{mattmight:Christensen:2003:Strings,
    abstract = {We perform static analysis of Java programs to answer a simple question: which values may occur as results of string expressions? The answers are summarized for each expression by a regular language that is guaranteed to contain all possible values. We present several applications of this analysis, including statically checking the syntax of dynamically generated expressions, such as {SQL} queries. Our analysis constructs flow graphs from class files and generates a context-free grammar with a nonterminal for each string expression. The language of this grammar is then widened into a regular language through a variant of an algorithm previously used for speech recognition. The collection of resulting regular languages is compactly represented as a special kind of multi-level automaton from which individual answers may be extracted. If a program error is detected, examples of invalid strings are automatically produced. We present extensive benchmarks demonstrating that the analysis is efficient and produces results of useful precision.},
    address = {Berlin, Heidelberg},
    author = {Christensen, Aske S. and M{\o}ller, Anders and Schwartzbach, Michael I.},
    booktitle = {SAS 2003: Proceedings of the 10th Static Analysis Symposium},
    citeulike-article-id = {7359433},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1760269},
    date-added = {2010-06-25 17:39:38},
    isbn = {3-540-40325-6},
    keywords = {java, string-analysis},
    location = {San Diego, CA, USA},
    pages = {1--18},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Precise analysis of string expressions},
    url = {http://portal.acm.org/citation.cfm?id=1760269},
    year = {2003}
}

@inproceedings{mattmight:Anderson:2005:Javascript,
    author = {Anderson, Christopher and Giannini, Paola and Drossopoulou, Sophia},
    booktitle = {Proceedings of the 19th European Conference on Object-Oriented Programming},
    citeulike-article-id = {2973461},
    citeulike-linkout-0 = {http://pubs.doc.ic.ac.uk/typeinferenceforjavascript-ecoop/typeinferenceforjavascript-ecoop.pdf},
    date-added = {2010-06-22 22:30:23},
    keywords = {javascript},
    priority = {2},
    publisher = {Springer},
    title = {Towards Type Inference for {JavaScript}},
    url = {http://pubs.doc.ic.ac.uk/typeinferenceforjavascript-ecoop/typeinferenceforjavascript-ecoop.pdf},
    year = {2005}
}

@inproceedings{mattmight:Ong:2006:ModelChecking,
    abstract = {We prove that the modal mu-calculus model-checking problem for (ranked and ordered) node-labelled trees that are generated by order-n recursion schemes (whether safe or not, and whether homogeneously typed or not) is {n-EXPTIME} complete, for every nges0. It follows that the monadic second-order theories of these trees are decidable. There are three major ingredients. The first is a certain transference principle from the tree generated by the scheme - the value tree - to an auxiliary computation tree, which is itself a tree generated by a related order-0 recursion scheme (equivalently, a regular tree). Using innocent game semantics in the sense of Hyland and Ong, we establish a strong correspondence between paths in the value tree and traversals in the computation tree. This allows us to prove that a given alternating parity tree automaton ({APT}) has an (accepting) run-tree over the value tree iff it has an (accepting) traversal-tree over the computation tree. The second ingredient is the simulation of an (accepting) traversal-tree by a certain set of annotated paths over the computation tree; we introduce traversal-simulating {APT} as a recognising device for the latter. Finally, for the complexity result, we prove that traversal-simulating {APT} enjoy a succinctness property: for deciding acceptance, it is enough to consider run-trees that have a reduced branching factor. The desired bound is then obtained by analysing the complexity of solving an associated (finite) acceptance parity game},
    address = {Los Alamitos, CA, USA},
    author = {Ong, C. H. L.},
    booktitle = {21st Annual IEEE Symposium on Logic in Computer Science (LICS'06)},
    citeulike-article-id = {6941050},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/LICS.2006.38},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/LICS.2006.38},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1691219},
    date-added = {2010-04-02 01:59:47},
    doi = {10.1109/LICS.2006.38},
    isbn = {0-7695-2631-4},
    issn = {1043-6871},
    journal = {Symposium on Logic in Computer Science},
    keywords = {model-checking, recursion-schemes},
    location = {Seattle, WA, USA},
    pages = {81--90},
    priority = {2},
    publisher = {IEEE},
    title = {On {Model-Checking} Trees Generated by {Higher-Order} Recursion Schemes},
    url = {http://dx.doi.org/10.1109/LICS.2006.38},
    volume = {0},
    year = {2006}
}

@inproceedings{mattmight:Felleisen:1987:CESK,
    abstract = {Imperative assignments are abstractions of recurring programming patterns in purely functional programming languages. When added to higher-order functional languages, they provide a higher-level of modularity and security but invalidate the simple substitution semantics. We show that, given an operational interpretation of a denotational semantics for such a language, it is possible to design a two-level extension of the \&lgr; u -calculus. This calculus provides a location-free rewriting semantics of the language and offers new possibilities for reasoning with assignments. The upper level of the calculus factors out all the steps in a reduction sequence which must be in a linear order; the lower level allows a partial ordering of reduction steps.},
    address = {New York, NY, USA},
    author = {Felleisen, Matthias and Friedman, Daniel P.},
    booktitle = {POPL '87: Proceedings of the 14th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
    citeulike-article-id = {6745776},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=41625.41654},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/41625.41654},
    date-added = {2010-04-01 16:01:27},
    doi = {10.1145/41625.41654},
    isbn = {0-89791-215-2},
    location = {Munich, West Germany},
    pages = {314+},
    priority = {2},
    publisher = {ACM},
    title = {A calculus for assignments in higher-order languages},
    url = {http://dx.doi.org/10.1145/41625.41654},
    year = {1987}
}

@incollection{mattmight:Vardoulakis:2010:CFA2,
    abstract = {In a functional language, the dominant control-flow mechanism is function call and return. Most higher-order flow analyses, including {k-CFA}, do not handle call and return well: they remember only a bounded number of pending calls because they approximate programs with control-flow graphs. Call/return mismatch introduces precision-degrading spurious control-flow paths and increases the analysis time. We describe {CFA2}, the first flow analysis with precise call/return matching in the presence of higher-order functions and tail calls. We formulate {CFA2} as an abstract interpretation of programs in continuation passing style and describe a sound and complete summarization algorithm for our abstract semantics. A preliminary evaluation shows that {CFA2} gives more accurate data-flow information than {0CFA} and {1CFA}.},
    address = {Berlin, Heidelberg},
    author = {Vardoulakis, Dimitrios and Shivers, Olin},
    booktitle = {Programming Languages and Systems},
    chapter = {30},
    citeulike-article-id = {6938175},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-11957-6\_30},
    citeulike-linkout-1 = {http://www.springerlink.com/content/5346r6033gnl6788},
    date-added = {2010-04-01 04:42:05},
    doi = {10.1007/978-3-642-11957-6\_30},
    editor = {Gordon, Andrew D.},
    isbn = {978-3-642-11956-9},
    pages = {570--589},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {{CFA2}: A {Context-Free} Approach to {Control-Flow} Analysis},
    url = {http://dx.doi.org/10.1007/978-3-642-11957-6\_30},
    volume = {6012},
    year = {2010}
}

@article{mattmight:Melski:2000:CFL,
    abstract = {We show the interconvertibility of context-free-language reachability problems and a class of set-constraint problems: given a context-free-language reachability problem, we show how to construct a set-constraint problem whose answer gives a solution to the reachability problem; given a set-constraint problem, we show how to construct a context-free-language reachability problem whose answer gives a solution to the set-constraint problem. The interconvertibility of these two formalisms offers a conceptual advantage akin to the advantage gained from the interconvertibility of finite-state automata and regular expressions in formal language theory, namely, a problem can be formulated in whichever formalism is most natural. It also offers some insight into the  ” O(n3) bottleneck” for different types of program-analysis problems and allows results previously obtained for context-free-language reachability problems to be applied to set-constraint problems and vice versa.},
    author = {Melski, David and Reps, Thomas W.},
    citeulike-article-id = {1864454},
    citeulike-linkout-0 = {http://dblp.uni-trier.de/rec/bibtex/journals/tcs/MelskiR00},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/S0304-3975(00)00049-9},
    citeulike-linkout-2 = {http://linkinghub.elsevier.com/retrieve/pii/S0304-3975(00)00049-9},
    citeulike-linkout-3 = {http://www.sciencedirect.com/science/article/B6V1G-417WC1H-3/2/018512a151722fb8a2667f64e9f3f2af},
    date-added = {2010-04-01 04:38:03},
    day = {6},
    doi = {10.1016/S0304-3975(00)00049-9},
    issn = {03043975},
    journal = {Theoretical Computer Science},
    keywords = {cfl},
    month = oct,
    number = {1-2},
    pages = {29--98},
    priority = {2},
    title = {Interconvertibility of a class of set constraints and context-free-language reachability},
    url = {http://dx.doi.org/10.1016/S0304-3975(00)00049-9},
    volume = {248},
    year = {2000}
}

@article{mattmight:Kodumal:2004:CFL,
    abstract = {Many program analyses can be reduced to graph reachability problems involving a limited form of context-free language reachability called {Dyck-CFL} reachability. We show a new reduction from {Dyck-CFL} reachability to set constraints that can be used in practice to solve these problems. Our reduction is much simpler than the general reduction from context-free language reachability to set constraints. We have implemented our reduction on top of a set constraints toolkit and tested its performance on a substantial polymorphic flow analysis application.},
    address = {New York, NY, USA},
    author = {Kodumal, John and Aiken, Alex},
    booktitle = {PLDI '04: Proceedings of the ACM SIGPLAN 2004 conference on Programming language design and implementation},
    citeulike-article-id = {6938153},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=996841.996867},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/996841.996867},
    date-added = {2010-04-01 04:29:44},
    doi = {10.1145/996841.996867},
    isbn = {1-58113-807-5},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {cfl, context-free-languages, k},
    location = {Washington DC, USA},
    month = jun,
    pages = {207--218},
    priority = {2},
    publisher = {ACM},
    title = {The set {constraint/CFL} reachability connection in practice},
    url = {http://dx.doi.org/10.1145/996841.996867},
    volume = {39},
    year = {2004}
}

@book{mattmight:Sipser:2005:Theory,
    abstract = {{"Intended as an upper-level undergraduate or introductory graduate text in computer science theory," this book lucidly covers the key concepts and theorems of the theory of computation. The presentation is remarkably clear; for example, the "proof idea," which offers the reader an intuitive feel for how the proof was constructed, accompanies many of the theorems and a proof. <I>Introduction to the Theory of Computation</I> covers the usual topics for this type of text plus it features a solid section on complexity theory--including an entire chapter on space complexity. The final chapter introduces more advanced topics, such as the discussion of complexity classes associated with probabilistic algorithms.} {This highly anticipated revision builds upon the strengths of the previous edition. Sipser's candid, crystal-clear style allows students at every level to understand and enjoy this field.}},
    author = {Sipser, Michael},
    citeulike-article-id = {1470019},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0534950973},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0534950973},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0534950973},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0534950973},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0534950973/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0534950973},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0534950973},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0534950973},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0534950973\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0534950973},
    date-added = {2010-04-01 04:24:50},
    day = {15},
    edition = {2},
    howpublished = {Hardcover},
    isbn = {0534950973},
    keywords = {theory},
    month = feb,
    priority = {2},
    publisher = {Course Technology},
    title = {Introduction to the Theory of Computation},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0534950973},
    year = {2005}
}

@article{mattmight:Asveld:2000:Inclusion,
    abstract = {By a reduction to Post's Correspondence Problem we provide a direct proof of the known fact that the inclusion problem for unambiguous context-free grammars is undecidable. The argument or some straightforward modification also applies to some other subclasses of context-free languages such as linear languages, sequential languages, and {DSC}-languages (i.e., languages generated by context-free grammars with disjunct syntactic categories). We also consider instances of the problem  ” Is L ( D 1 ) L ( D 2 )?” where D 1 and D 2 are taken from possibly different descriptor families of subclasses of context-free languages.},
    author = {Asveld, Peter R. J. and Nijholt, Anton},
    citeulike-article-id = {6916110},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0304-3975(99)00113-9},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0304-3975(99)00113-9},
    date-added = {2010-03-26 16:39:27},
    day = {6},
    doi = {10.1016/S0304-3975(99)00113-9},
    issn = {03043975},
    journal = {Theoretical Computer Science},
    keywords = {context-free-languages, decidability, languages, regular-languages, theory},
    month = jan,
    number = {1-2},
    pages = {247--256},
    priority = {2},
    title = {The inclusion problem for some subclasses of context-free languages},
    url = {http://dx.doi.org/10.1016/S0304-3975(99)00113-9},
    volume = {230},
    year = {2000}
}

@incollection{mattmight:Codish2002Metacircular,
    abstract = {We give an introduction to the meta-circular approach to the abstract interpretation of logic programs. This approach is particularly useful for prototyping and for introductory classes on abstract interpretation. Using interpreters, students can immediately write, adapt, and experiment with interpreters and working dataflow analysers. We use a simple meta-circular interpreter, based on a "non-ground {TP}" semantics, as a generic analysis engine. Instantiating the engine is a matter of providing an appropriate domain of approximations, together with definitions of "abstract" unification and disjunction. Small changes of the interpreter let us vary both what can be "observed" by an analyser, and how fixed point computation is done. Amongst the dataflow analyses used to exemplify this approach are a parity analysis, groundness dependency analysis, call patterns, depth- analysis, and a "pattern" analys is to establish most specific generalisations of calls and success sets.},
    author = {Codish, Michael and S{\o}ndergaard, Harald},
    citeulike-article-id = {1943509},
    citeulike-linkout-0 = {http://www.springerlink.com/content/c8p7nvpqrvdpur8p},
    date-added = {2010-03-15 14:29:19},
    journal = {The Essence of Computation. Complexity, Analysis, Transformation : Essays Dedicated to Neil D. Jones},
    pages = {109--134},
    priority = {2},
    title = {Meta-circular Abstract Interpretation in Prolog},
    url = {http://www.springerlink.com/content/c8p7nvpqrvdpur8p},
    year = {2002}
}

@inproceedings{mattmight:Qian:2009:Automatic,
    abstract = {Abstraction plays a fundamental role in combating state-space explosion in model checking. Firstly, we study how to abstract models of mu-calculus and derive abstractions that are sound, and apply them to abstracting Kripke structures. However, a lack of completeness in the abstract interpretation leads to spurious counterexamples in the abstract model checking. In order to eliminate spurious counterexamples, the paper describes a method for minimally making abstract interpretations complete, and this refined complete abstract domain always exists.},
    address = {Washington, DC, USA},
    author = {Qian, Junyan and Zhao, Lingzhong and Cai, Guoyong and Gu, Tianlong},
    booktitle = {ICIS '09: Proceedings of the 2009 Eigth IEEE/ACIS International Conference on Computer and Information Science},
    citeulike-article-id = {6849964},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1605395.1606002},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ICIS.2009.145},
    date-added = {2010-03-15 06:11:38},
    doi = {10.1109/ICIS.2009.145},
    isbn = {978-0-7695-3641-5},
    keywords = {abstract-interpretation},
    pages = {927--932},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Automatic Construction of Complete Abstraction by Abstract Interpretation},
    url = {http://dx.doi.org/10.1109/ICIS.2009.145},
    year = {2009}
}

@phdthesis{mattmight:Midtgaard:2007:Dissertation,
    author = {Midtgaard, Jan},
    citeulike-article-id = {6849947},
    date-added = {2010-03-15 06:09:26},
    keywords = {formal-semantics, transformation},
    priority = {2},
    school = {University of Aarhus},
    title = {Transformation, Analysis, and Interpretation of {Higher-Order} Procedural Programs},
    year = {2007}
}

@inproceedings{mattmight:Ager:2003:Functional,
    author = {Ager, Mads S. and Biernacki, Dariusz and Danvy, Olivier and Midtgaard, Jan},
    booktitle = {PPDP '03: Proceedings of the 5th ACM SIGPLAN International Conference on Principles and Practice of Declarative Programming},
    citeulike-article-id = {3272},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=888254},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/888251.888254},
    date-added = {2010-03-15 06:03:01},
    doi = {10.1145/888251.888254},
    isbn = {1581137052},
    keywords = {formal-semantics},
    pages = {8--19},
    priority = {2},
    publisher = {ACM Press},
    title = {A functional correspondence between evaluators and abstract machines},
    url = {http://dx.doi.org/10.1145/888251.888254},
    year = {2003}
}

@article{mattmight:Ager:2004:Functional,
    abstract = {We bridge the gap between compositional evaluators and abstract machines for the lambda-calculus, using closure conversion, transformation into continuation-passing style, and defunctionalization of continuations. This article is a followup of our article at {PPDP} 2003, where we consider call by name and call by value. Here, however, we consider call by need. We derive a lazy abstract machine from an ordinary call-by-need evaluator that threads a heap of updatable cells. In this resulting abstract machine, the continuation fragment for updating a heap cell naturally appears as an 'update marker', an implementation technique that was invented for the Three Instruction Machine and subsequently used to construct lazy variants of Krivine's abstract machine. Tuning the evaluator leads to other implementation techniques such as unboxed values. The correctness of the resulting abstract machines is a corollary of the correctness of the original evaluators and of the program transformations used in the derivation.},
    author = {Ager, Mads S. and Danvy, Olivier and Midtgaard, Jan},
    citeulike-article-id = {2917380},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.ipl.2004.02.012},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0020-0190(04)00063-8},
    citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B6V0F-4C47N5K-1/1/fc45ae0b61f9fcd63d1600e9061b28cb},
    date-added = {2010-03-15 06:01:36},
    day = {15},
    doi = {10.1016/j.ipl.2004.02.012},
    issn = {00200190},
    journal = {Information Processing Letters},
    keywords = {formal-semantics},
    month = jun,
    number = {5},
    pages = {223--232},
    priority = {2},
    title = {A functional correspondence between call-by-need evaluators and lazy abstract machines},
    url = {http://dx.doi.org/10.1016/j.ipl.2004.02.012},
    volume = {90},
    year = {2004}
}

@article{mattmight:Ager:2005:Functional,
    abstract = {We extend our correspondence between evaluators and abstract machines from the pure setting of the  λ -calculus to the impure setting of the computational  λ -calculus. We show how to derive new abstract machines from monadic evaluators for the computational  λ -calculus. Starting from (1) a generic evaluator parameterized by a monad and (2) a monad specifying a computational effect, we inline the components of the monad in the generic evaluator to obtain an evaluator written in a style that is specific to this computational effect. We then derive the corresponding abstract machine by closure-converting, {CPS}-transforming, and defunctionalizing this specific evaluator. We illustrate the construction with the identity monad, obtaining the {CEK} machine, and with a lifted state monad, obtaining a variant of the {CEK} machine with error and state. In addition, we characterize the tail-recursive stack inspection presented by Clements and Felleisen as a lifted state monad. This enables us to combine this stack-inspection monad with other monads and to construct abstract machines for languages with properly tail-recursive stack inspection and other computational effects. The construction scales to other monads—including one more properly dedicated to stack inspection than the lifted state monad—and other monadic evaluators.},
    author = {Ager, Mads and Danvy, Olivier and Midtgaard, Jan},
    citeulike-article-id = {6745807},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.tcs.2005.06.008},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0304397505003439},
    date-added = {2010-03-15 06:01:14},
    day = {06},
    doi = {10.1016/j.tcs.2005.06.008},
    issn = {03043975},
    journal = {Theoretical Computer Science},
    month = sep,
    number = {1},
    pages = {149--172},
    priority = {2},
    title = {A functional correspondence between monadic evaluators and abstract machines for languages with computational effects},
    url = {http://dx.doi.org/10.1016/j.tcs.2005.06.008},
    volume = {342},
    year = {2005}
}

@article{mattmight:Danvy:2008:Rational,
    abstract = {Landin's {SECD} machine was the first abstract machine for applicativeexpressions, i.e., functional programs. Landin's J operator was the firstcontrol operator for functional languages, and was specified by an extension ofthe {SECD} machine. We present a family of evaluation functions corresponding tothis extension of the {SECD} machine, using a series of elementarytransformations (transformation into continu-ation-passing style ({CPS}) anddefunctionalization, chiefly) and their left inverses (transformation intodirect style and refunctionalization). To this end, we modernize the {SECDmachine} into a bisimilar one that operates in lockstep with the original onebut that (1) does not use a data stack and (2) uses the caller-save rather thanthe callee-save convention for environments. We also identify that the dumpcomponent of the {SECD} machine is managed in a callee-save way. The caller-savecounterpart of the modernized {SECD} machine precisely corresponds to Thielecke'sdouble-barrelled continuations and to Felleisen's encoding of J in terms ofcall/cc. We then variously characterize the J operator in terms of {CPS} and interms of delimited-control operators in the {CPS} hierarchy. As a byproduct, wealso present several reduction semantics for applicative expressions with the Joperator, based on Curien's original calculus of explicit substitutions. Thesereduction semantics mechanically correspond to the modernized versions of {theSECD} machine and to the best of our knowledge, they provide the first syntactictheories of applicative expressions with the J operator.},
    archivePrefix = {arXiv},
    author = {Danvy, Olivier and Millikin, Kevin},
    citeulike-article-id = {5441449},
    citeulike-linkout-0 = {http://arxiv.org/abs/0811.3231},
    citeulike-linkout-1 = {http://arxiv.org/pdf/0811.3231},
    citeulike-linkout-2 = {http://dx.doi.org/10.2168/LMCS-4(4:12)2008},
    date-added = {2010-03-15 05:13:25},
    day = {29},
    doi = {10.2168/LMCS-4(4:12)2008},
    editor = {Tennent, Robert},
    eprint = {0811.3231},
    issn = {1860-5974},
    journal = {Logical Methods in Computer Science},
    keywords = {formal-semantics},
    month = nov,
    number = {4},
    priority = {2},
    title = {A Rational Deconstruction of Landin's {SECD} Machine with the J Operator},
    url = {http://dx.doi.org/10.2168/LMCS-4(4:12)2008},
    volume = {4},
    year = {2008}
}

@article{mattmight:Danvy:2009:Refunctionalization,
    abstract = {We present the left inverse of Reynolds' defunctionalization and we show its relevance to programming and to programming languages. We propose two methods to transform a program that is almost in defunctionalized form into one that is actually in defunctionalized form, and we illustrate them with a recognizer for Dyck words and with Dijkstra's shunting-yard algorithm.},
    author = {Danvy, Olivier and Millikin, Kevin},
    citeulike-article-id = {5333740},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.scico.2007.10.007},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0167642309000227},
    date-added = {2010-03-15 05:13:01},
    day = {01},
    doi = {10.1016/j.scico.2007.10.007},
    issn = {01676423},
    journal = {Science of Computer Programming},
    keywords = {formal-semantics},
    month = jun,
    number = {8},
    pages = {534--549},
    priority = {2},
    title = {Refunctionalization at work},
    url = {http://dx.doi.org/10.1016/j.scico.2007.10.007},
    volume = {74},
    year = {2009}
}

@inproceedings{mattmight:Reynolds:1972:Definitional,
    abstract = {Higher-order programming languages (i.e., languages in which procedures or labels can occur as values) are usually defined by interpreters which are themselves written in a programming language based on the lambda calculus (i.e., an applicative language such as pure {LISP}). Examples include {McCarthy}'s definition of {LISP}, Landin's {SECD} machine, the Vienna definition of {PL}/I, Reynolds' definitions of {GEDANKEN}, and recent unpublished work by L. Morris and C. Wadsworth. Such definitions can be classified according to whether the interpreter contains higher-order functions, and whether the order of application (i.e., call-by-value versus call-by-name) in the defined language depends upon the order of application in the defining language. As an example, we consider the definition of a simple applicative programming language by means of an interpreter written in a similar language. Definitions in each of the above classifications are derived from one another by informal but constructive methods. The treatment of imperative features such as jumps and assignment is also discussed.},
    address = {New York, NY, USA},
    author = {Reynolds, John C.},
    booktitle = {ACM 1972: Proceedings of the ACM Annual Conference},
    citeulike-article-id = {205727},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=805852},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/800194.805852},
    date-added = {2010-03-15 05:08:24},
    doi = {10.1145/800194.805852},
    keywords = {formal-semantics},
    location = {Boston, Massachusetts, United States},
    pages = {717--740},
    priority = {2},
    publisher = {ACM},
    title = {Definitional interpreters for higher-order programming languages},
    url = {http://dx.doi.org/10.1145/800194.805852},
    year = {1972}
}

@book{mattmight:Nielson:1999:Principles,
    abstract = {{Program analysis concerns static techniques for computing reliable approximate information about the dynamic behaviour of programs. Applications include compilers (for code improvement), software validation (for detecting errors in algorithms or breaches of security) and transformations between data representation (for solving problems such as the Y2K problem). This book is unique in giving an overview of the four major approaches to program analysis: data flow analysis, constraint based analysis, abstract interpretation, and type and effect systems. The presentation demonstrates the extensive similarities between the approaches; this will aid the reader in choosing the right approach and in enhancing it with insights from the other approaches. The book covers basic semantic properties as well as more advanced algorithmic techniques. The book is aimed at M.Sc. and Ph.D. students but will be valuable also for experienced researchers and professionals.}},
    author = {Nielson, Flemming and Nielson, Hanne R. and Hankin, Chris},
    citeulike-article-id = {761800},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/3540654100},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/3540654100},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/3540654100},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/3540654100},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/3540654100/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/3540654100},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/3540654100},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN3540654100},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=3540654100\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/3540654100},
    date-added = {2010-03-15 05:01:16},
    day = {07},
    edition = {Corrected},
    howpublished = {Hardcover},
    isbn = {3540654100},
    keywords = {static-analysis},
    month = dec,
    priority = {2},
    publisher = {Springer},
    title = {Principles of Program Analysis},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/3540654100},
    year = {2004}
}

@inbook{mattmight:Scott:1966:Formal,
    author = {Scott, Dana and Strachey, Christopher},
    booktitle = {Formal Language Description Languages for Computer Programming},
    citeulike-article-id = {6849694},
    date-added = {2010-03-15 04:58:27},
    editor = {Steel, T. B.},
    keywords = {formal-semantics},
    pages = {197--220},
    priority = {2},
    title = {Towards a formal semantics},
    year = {1966}
}

@inproceedings{mattmight:Wand:1999:UVE,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has opted to expose the complete List rather than only correct and linked references.},
    address = {New York, NY, USA},
    author = {Wand, Mitchell and Siveroni, Igor},
    booktitle = {POPL '99: Proceedings of the 26th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {6849676},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=292567},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/292540.292567},
    date-added = {2010-03-15 04:46:28},
    doi = {10.1145/292540.292567},
    isbn = {1-58113-095-3},
    keywords = {cfa, correctness, optimization, static-analysis},
    location = {San Antonio, Texas, United States},
    pages = {291--302},
    priority = {0},
    publisher = {ACM},
    title = {Constraint systems for useless variable elimination},
    url = {http://dx.doi.org/10.1145/292540.292567},
    year = {1999}
}

@article{mattmight:Miller:2010:ModelChecking,
    abstract = {A translator framework enables the use of model checking in complex avionics systems and other industrial settings.},
    address = {New York, NY, USA},
    author = {Miller, Steven P. and Whalen, Michael W. and Cofer, Darren D.},
    citeulike-article-id = {6798608},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1646353.1646372},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1646353.1646372},
    date-added = {2010-03-11 01:53:59},
    doi = {10.1145/1646353.1646372},
    issn = {0001-0782},
    journal = {Communications of the ACM},
    keywords = {hybrid-systems, model-checking},
    number = {2},
    pages = {58--64},
    priority = {2},
    publisher = {ACM},
    title = {Software model checking takes off},
    url = {http://dx.doi.org/10.1145/1646353.1646372},
    volume = {53},
    year = {2010}
}

@inproceedings{mattmight:Casagrande:2008:HybridAutomata,
    abstract = {Most of the observable natural phenomena exhibit a mixed discrete-continuous behavior characterized by laws changing according to a phase cycle. Such behaviors can be modeled in a very natural way by a class of automata called hybrid automata. In this class the evolution of measurable quantities, such as concentrations, is represented according to both dynamical system evolutions - on dense domains - and rules phases through a discrete transition structure. Once the real systems are modeled in such a framework, one may want to analyze them by applying automatic techniques, such as model checking or abstract interpretation. Unfortunately, the interleaving of dense and discrete evolutions soon leads to undecidability results on hybrid automata. This paper addresses questions regarding the decidability of reachability problem for hybrid automata (i.e., ldquocan the systems reach a state a from a state b?rdquo) by proposing a more ldquonaturerdquo-oriented semantics. In particular, after observing that dense domains are abstractions of real world, we suggest that, for any biological system, there should be a value isin such that if the distance of two objects are less than isin, we cannot distinguish them. Using the above considerations, we propose a new semantics for hybrid automata which guarantees the decidability of reachability. Moreover, we provide a biological example showing that the new semantics mimics the real world behaviors better than the ldquoclassicalrdquo one.},
    author = {Casagrande, A. and Piazza, C. and Policriti, A.},
    booktitle = {9th International Workshop on Discrete Event Systems. WODES 2008.},
    citeulike-article-id = {3658495},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/WODES.2008.4605960},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4605960},
    date-added = {2010-03-08 23:17:22},
    doi = {10.1109/WODES.2008.4605960},
    journal = {Discrete Event Systems, 2008. WODES 2008. 9th International Workshop on},
    keywords = {hybrid-systems},
    pages = {281--286},
    priority = {2},
    title = {Discreteness, hybrid automata, and biology},
    url = {http://dx.doi.org/10.1109/WODES.2008.4605960},
    year = {2008}
}

@article{mattmight:Tiwari:2008:HybridAbstraction,
    abstract = {Abstract   We present a procedure for constructing sound finite-state discrete abstractions of hybrid systems. This procedure uses ideas from predicate abstraction to abstract the discrete dynamics and qualitative reasoning to abstract the continuous dynamics of the hybrid system. It relies on the ability to decide satisfiability of quantifier-free formulas in some theory rich enough to encode the hybrid system. We characterize the sets of predicates that can be used to create high quality abstractions and we present new approaches to discover such useful sets of predicates. Under certain assumptions, the abstraction procedure can be applied compositionally to abstract a hybrid system described as a composition of two hybrid automata. We show that the constructed abstractions are always sound, but are relatively complete only under certain assumptions.},
    author = {Tiwari, Ashish},
    citeulike-article-id = {3642630},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10703-007-0044-3},
    citeulike-linkout-1 = {http://www.springerlink.com/content/560u205650k788lh},
    date-added = {2010-03-08 23:15:48},
    day = {6},
    doi = {10.1007/s10703-007-0044-3},
    journal = {Formal Methods in System Design},
    keywords = {hybrid-systems},
    month = feb,
    number = {1},
    pages = {57--83},
    priority = {2},
    title = {Abstractions for hybrid systems},
    url = {http://dx.doi.org/10.1007/s10703-007-0044-3},
    volume = {32},
    year = {2008}
}

@article{mattmight:Torrisi:2004:HYSDEL,
    abstract = {This paper presents a computational framework for modeling hybrid systems in discrete-time. We introduce the class of discrete hybrid automata ({DHA}) and show its relation with several other existing model paradigms: piecewise affine systems, mixed logical dynamical systems, (extended) linear complementarity systems, min-max-plus-scaling systems. We present {HYSDEL} (hybrid systems description language), a high-level modeling language for {DHA}, and a set of tools for translating {DHA} into any of the former hybrid models. Such a multimodeling capability of {HYSDEL} is particularly appealing for exploiting a large number of available analysis and synthesis techniques, each one developed for a particular class of hybrid models. An automotive example shows the modeling capabilities of {HYSDEL} and how the different models allow to use several computational tools.},
    author = {Torrisi, F. D. and Bemporad, A.},
    citeulike-article-id = {1205801},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1281781},
    date-added = {2010-03-08 23:13:41},
    journal = {Control Systems Technology, IEEE Transactions on},
    keywords = {hybrid-systems},
    number = {2},
    pages = {235--249},
    priority = {2},
    title = {{HYSDEL}-a tool for generating computational hybrid models for analysis and synthesis problems},
    url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1281781},
    volume = {12},
    year = {2004}
}

@article{mattmight:Tomlin:2003:Verification,
    abstract = {Hybrid system theory lies at the intersection of the fields of engineering control theory and computer science verification. It is defined as the modeling, analysis, and control of systems that involve the interaction of both discrete state systems, represented by finite automata, and continuous state dynamics, represented by differential equations. The embedded autopilot of a modern commercial jet is a prime example of a hybrid system: the autopilot modes correspond to the application of different control laws, and the logic of mode switching is determined by the continuous state dynamics of the aircraft, as well as through interaction with the pilot. To understand the behavior of hybrid systems, to simulate, and to control these systems, theoretical advances, analyses, and numerical tools are needed. In this paper, we first present a general model for a hybrid system along with an overview of methods for verifying continuous and hybrid systems. We describe a particular verification technique for hybrid systems, based on two-person zero-sum game theory for automata and continuous dynamical systems. We then outline a numerical implementation of this technique using level set methods, and we demonstrate its use in the design and analysis of aircraft collision avoidance protocols and in verification of autopilot logic.},
    author = {Tomlin, C. J. and Mitchell, I. and Bayen, A. M. and Oishi, M.},
    citeulike-article-id = {5972463},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/JPROC.2003.814621},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1215682},
    date-added = {2010-03-08 23:12:42},
    day = {28},
    doi = {10.1109/JPROC.2003.814621},
    journal = {Proceedings of the IEEE},
    keywords = {hybrid-systems},
    month = jul,
    number = {7},
    pages = {986--1001},
    priority = {2},
    title = {Computational techniques for the verification of hybrid systems},
    url = {http://dx.doi.org/10.1109/JPROC.2003.814621},
    volume = {91},
    year = {2003}
}

@article{mattmight:Julius:2009:Approximation,
    abstract = {<para> This paper develops a notion of approximation for a class of stochastic hybrid systems that includes, as special cases, both jump linear stochastic systems and linear stochastic hybrid automata. Our approximation framework is based on the recently developed notion of the so-called stochastic simulation functions. These Lyapunov-like functions can be used to rigorously quantify the distance or error between a system and its approximate abstraction. For the class of jump linear stochastic systems and linear stochastic hybrid automata, we show that the computation of stochastic simulation functions can be cast as a tractable linear matrix inequality problem. This enables us to compute the modeling error incurred by abstracting some of the continuous dynamics, or by neglecting the influence of stochastic noise, or even the influence of stochastic discrete jumps. </para>},
    author = {Julius, A. A. and Pappas, G. J.},
    booktitle = {Automatic Control, IEEE Transactions on},
    citeulike-article-id = {4899889},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/TAC.2009.2019791},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4982634},
    date-added = {2010-03-08 23:11:58},
    doi = {10.1109/TAC.2009.2019791},
    journal = {Automatic Control, IEEE Transactions on},
    keywords = {hybrid-systems},
    number = {6},
    pages = {1193--1203},
    priority = {2},
    title = {Approximations of Stochastic Hybrid Systems},
    url = {http://dx.doi.org/10.1109/TAC.2009.2019791},
    volume = {54},
    year = {2009}
}

@article{mattmight:Alur:1996:Automatic,
    abstract = {. We present a model checking procedure and its implementation for the automatic verification of embedded systems. Systems are represented by Hybrid Automata ---machines with finite control and real-valued variables modeling continuous environment parameters such as time, pressure, and temperature. System properties are specified in a real-time temporal logic and verified by symbolic computation. The verification procedure, implemented in Mathematica, is used to prove digital controllers and distributed algorithms correct. The verifier checks safety, liveness, time-bounded, and duration properties of hybrid automata. 1 Introduction  A hybrid system consists of a discrete program that is embedded in a continuously changing environment and interacts with the environment in real time. More and more real-life processes, from elevators to aircraft, are controlled by such programs. Obviously, correctness is of vital importance for hybrid systems. Yet traditional program verification methods ...},
    author = {Alur, Rajeev and Henzinger, Thomas A. and Ho, Pei-Hsin},
    citeulike-article-id = {5869436},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.52.484},
    date-added = {2010-03-08 23:10:44},
    journal = {IEEE Transactions on Software Engineering},
    keywords = {hybrid-systems},
    pages = {181--201},
    priority = {2},
    title = {Automatic Symbolic Verification of Embedded Systems},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.52.484},
    volume = {22},
    year = {1996}
}

@inproceedings{mattmight:Silva:2000:CheckMate,
    abstract = {We present a formal verification of a control algorithm from the literature for a four-cylinder four-stroke engine in the cutoff mode. The controlled system is modeled, simulated and verified using {CheckMate}, a tool for formal verification of hybrid systems developed at Carnegie Mellon University. {CheckMate} automatically constructs a polyhedral-invariant hybrid automaton ({PIHA}) from a {Matlab/Simulink} model of the hybrid system and performs the verification using discrete model approximations. This case study illustrates how verification can be performed directly on a model of the hybrid system dynamics without first constructing an approximation to the continuous dynamics using timed automata or linear hybrid automata models},
    author = {Silva, B. I. and Krogh, B. H.},
    booktitle = {Proceedings of the 2000 American Control Conference},
    citeulike-article-id = {5972359},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ACC.2000.879487},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=879487},
    date-added = {2010-03-08 23:09:48},
    day = {06},
    doi = {10.1109/ACC.2000.879487},
    journal = {American Control Conference, 2000. Proceedings of the 2000},
    keywords = {hybrid-systems},
    month = aug,
    pages = {1679--1683 vol.3},
    priority = {2},
    title = {Formal verification of hybrid systems using {CheckMate}: a case study},
    url = {http://dx.doi.org/10.1109/ACC.2000.879487},
    volume = {3},
    year = {2000}
}

@article{mattmight:Henzinger:1997:HYTECH,
    abstract = {A hybrid system is a dynamical system whose behavior exhibits both discrete and continuouschange. A hybrid automaton is a mathematical model for hybrid systems, which combines, ina single formalism, automaton transitions for capturing discrete change with differential equationsfor capturing continuous change. {HyTech} is a symbolic model checker for linear hybridautomata, a subclass of hybrid automata that can be analyzed automatically by computing withpolyhedral state sets. A key feature of ...},
    author = {Henzinger, Thomas A. and Ho, Pei H. and Toi, Howard W.},
    citeulike-article-id = {965053},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.2086},
    date-added = {2010-03-08 23:08:54},
    journal = {International Journal on Software Tools for Technology Transfer},
    number = {1-2},
    pages = {110--122},
    priority = {2},
    title = {{HYTECH}: A Model Checker for Hybrid Systems},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.2086},
    volume = {1},
    year = {1997}
}

@article{mattmight:Chutinan:2000:Approximating,
    abstract = {This paper presents a new algorithm for generating finite-state automata models of hybrid systems in which the continuous-state dynamics can be switched when the continuous-state trajectory generates threshold events. The automata state transitions correspond to threshold events and the automata states correspond to portions of the threshold surfaces in the continuous state space. The hybrid system dynamics are approximated by the automata models in the sense that the languages of threshold event sequences generated by the automata contain the threshold event language for the hybrid system. Properties of the algorithm for constructing and refining the approximating automata are demonstrated and the application of approximating automata for system verification is illustrated for a switching controller for an inverted pendulum. Relationships to other approaches to hybrid system synthesis and verification are also discussed.},
    author = {Chutinan, Alongkrit and Krogh, Bruce H.},
    citeulike-article-id = {4067312},
    citeulike-linkout-0 = {http://dx.doi.org/10.1076/1387-3954(200003)6:1;1-Q;FT030},
    date-added = {2010-03-08 22:59:54},
    doi = {10.1076/1387-3954(200003)6:1;1-Q;FT030},
    journal = {Mathematical and Computer Modelling of Dynamical Systems},
    keywords = {hybrid-systems},
    number = {1},
    pages = {30--50},
    priority = {2},
    publisher = {Taylor \& Francis},
    title = {Computing Approximating Automata for a Class of Hybrid Systems},
    url = {http://dx.doi.org/10.1076/1387-3954(200003)6:1;1-Q;FT030},
    volume = {6},
    year = {2000}
}

@incollection{mattmight:Platzer:2008:KeYmaera,
    abstract = {{KeYmaera} is a hybrid verification tool for hybrid systems that combines deductive, real algebraic, and computer algebraic prover technologies. It is an automated and interactive theorem prover for a natural specification and verification logic for hybrid systems. {KeYmaera} supports differential dynamic logic, which is a real-valued first-order dynamic logic for hybrid programs, a program notation for hybrid automata. For automating the verification process, {KeYmaera} implements a generalized free-variable sequent calculus and automatic proof strategies that decompose the hybrid system specification symbolically. To overcome the complexity of real arithmetic, we integrate real quantifier elimination following an iterative background closure strategy. Our tool is particularly suitable for verifying parametric hybrid systems and has been used successfully for verifying collision avoidance in case studies from train control and air traffic management.},
    address = {Berlin, Heidelberg},
    author = {Platzer, Andr\'{e} and Quesel, Jan-David},
    booktitle = {Automated Reasoning },
    chapter = {15},
    citeulike-article-id = {6778344},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-71070-7\_15},
    citeulike-linkout-1 = {http://www.springerlink.com/content/h630xm5n36116311},
    date-added = {2010-03-08 22:58:03},
    doi = {10.1007/978-3-540-71070-7\_15},
    editor = {Armando, Alessandro and Baumgartner, Peter and Dowek, Gilles},
    isbn = {978-3-540-71069-1},
    issn = {0302-9743},
    keywords = {hybrid-systems},
    pages = {171--178},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{KeYmaera}: A Hybrid Theorem Prover for Hybrid Systems (System Description)},
    url = {http://dx.doi.org/10.1007/978-3-540-71070-7\_15},
    volume = {5195},
    year = {2008}
}

@article{mattmight:Strohbehn:1984:Hyperthermia,
    author = {Strohbehn, J. W. and Roemer, R. B.},
    citeulike-article-id = {6778320},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/TBME.1984.325380},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/6373568},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=6373568},
    date-added = {2010-03-08 22:27:14},
    doi = {10.1109/TBME.1984.325380},
    issn = {0018-9294},
    journal = {IEEE transactions on bio-medical engineering},
    month = jan,
    number = {1},
    pages = {136--149},
    pmid = {6373568},
    priority = {2},
    title = {A survey of computer simulations of hyperthermia treatments.},
    url = {http://dx.doi.org/10.1109/TBME.1984.325380},
    volume = {31},
    year = {1984}
}

@incollection{mattmight:Podelski:2006:ModelChecking,
    abstract = {We call a hybrid system stable if every trajectory inevitably ends up in a given region. Our notion of stability deviates from classical definitions in control theory. In this paper, we present a model checking algorithm for stability in the new sense. The idea of the algorithm is to reduce the stability proof for the whole system to a set of (smaller) proofs for several one-mode systems.},
    address = {Berlin, Heidelberg},
    author = {Podelski, Andreas and Wagner, Silke},
    booktitle = {Hybrid Systems: Computation and Control },
    chapter = {38},
    citeulike-article-id = {6778307},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11730637\_38},
    citeulike-linkout-1 = {http://www.springerlink.com/content/fp4085t181368630},
    date-added = {2010-03-08 22:19:57},
    doi = {10.1007/11730637\_38},
    editor = {Hespanha, Jo\~{a}o P. and Tiwari, Ashish},
    isbn = {978-3-540-33170-4},
    pages = {507--521},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Model Checking of Hybrid Systems: From Reachability Towards Stability},
    url = {http://dx.doi.org/10.1007/11730637\_38},
    volume = {3927},
    year = {2006}
}

@incollection{mattmight:Platzer:2009:Flight,
    abstract = {Aircraft collision avoidance maneuvers are important and complex applications. Curved flight exhibits nontrivial continuous behavior. In combination with the control choices during air traffic maneuvers, this yields hybrid systems with challenging interactions of discrete and continuous dynamics. As a case study illustrating the use of a new proof assistant for a logic for nonlinear hybrid systems, we analyze collision freedom of roundabout maneuvers in air traffic control, where appropriate curved flight, good timing, and compatible maneuvering are crucial for guaranteeing safe spatial separation of aircraft throughout their flight. We show that formal verification of hybrid systems can scale to curved flight maneuvers required in aircraft control applications. We introduce a fully flyable variant of the roundabout collision avoidance maneuver and verify safety properties by compositional verification.},
    address = {Berlin, Heidelberg},
    author = {Platzer, Andr\'{e} and Clarke, Edmund},
    booktitle = {FM 2009: Formal Methods},
    chapter = {35},
    citeulike-article-id = {6778007},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-05089-3\_35},
    citeulike-linkout-1 = {http://www.springerlink.com/content/1013762161uu55h7},
    date-added = {2010-03-08 20:19:25},
    doi = {10.1007/978-3-642-05089-3\_35},
    editor = {Cavalcanti, Ana and Dams, Dennis R.},
    isbn = {978-3-642-05088-6},
    keywords = {hybrid-systems},
    pages = {547--562},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {Formal Verification of Curved Flight Collision Avoidance Maneuvers: A Case Study},
    url = {http://dx.doi.org/10.1007/978-3-642-05089-3\_35},
    volume = {5850},
    year = {2009}
}

@article{mattmight:Platzer:2009:Computing,
    abstract = {Abstract  We introduce a fixedpoint algorithm for verifying safety properties of hybrid systems with differential equations whose right-hand sides are polynomials in the state variables. In order to verify nontrivial systems without solving their differential equations and without numerical errors, we use a continuous generalization of induction, for which our algorithm computes the required differential invariants. As a means for combining local differential invariants into global system invariants in a sound way, our fixedpoint algorithm works with a compositional verification logic for hybrid systems. With this compositional approach we exploit locality in system designs. To improve the verification power, we further introduce a saturation procedure that refines the system dynamics successively with differential invariants until safety becomes provable. By complementing our symbolic verification algorithm with a robust version of numerical falsification, we obtain a fast and sound verification procedure. We verify roundabout maneuvers in air traffic management and collision avoidance in train control and car control.},
    author = {Platzer, Andr\'{e} and Clarke, Edmund M.},
    citeulike-article-id = {5178814},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10703-009-0079-8},
    citeulike-linkout-1 = {http://www.springerlink.com/content/l225768t54022840},
    date-added = {2010-03-08 19:17:23},
    day = {10},
    doi = {10.1007/s10703-009-0079-8},
    issn = {1572-8102},
    journal = {Formal Methods in System Design},
    keywords = {hybrid-systems},
    month = jul,
    number = {1},
    pages = {98--120},
    priority = {2},
    title = {Computing differential invariants of hybrid systems as fixedpoints},
    url = {http://dx.doi.org/10.1007/s10703-009-0079-8},
    volume = {35},
    year = {2009}
}

@incollection{mattmight:Platzer:2007:Dynamic,
    abstract = {We introduce a first-order dynamic logic for reasoning about systems with discrete and continuous state transitions, and we present a sequent calculus for this logic. As a uniform model, our logic supports hybrid programs with discrete and differential actions. For handling real arithmetic during proofs, we lift quantifier elimination to dynamic logic. To obtain a modular combination, we use side deductions for verifying interacting dynamics. With this, our logic supports deductive verification of hybrid systems with symbolic parameters and first-order definable flows. Using our calculus, we prove a parametric inductive safety constraint for speed supervision in a train control system.},
    address = {Berlin, Heidelberg},
    author = {Platzer, Andr\'{e}},
    booktitle = {Automated Reasoning with Analytic Tableaux and Related Methods },
    chapter = {17},
    citeulike-article-id = {5957379},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-73099-6\_17},
    citeulike-linkout-1 = {http://www.springerlink.com/content/m755147247522794},
    date-added = {2010-03-08 19:16:56},
    doi = {10.1007/978-3-540-73099-6\_17},
    editor = {Olivetti, Nicola},
    isbn = {978-3-540-73098-9},
    issn = {0302-9743},
    journal = {Automated Reasoning with Analytic Tableaux and Related Methods},
    keywords = {hybrid-systems},
    pages = {216--232},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {Differential Dynamic Logic for Verifying Parametric Hybrid Systems},
    url = {http://dx.doi.org/10.1007/978-3-540-73099-6\_17},
    volume = {4548},
    year = {2007}
}

@article{mattmight:Platzer:2008:Differential,
    abstract = {Abstract  Hybrid systems are models for complex physical systems and are defined as dynamical systems with interacting discrete transitions and continuous evolutions along differential equations. With the goal of developing a theoretical and practical foundation for deductive verification of hybrid systems, we introduce a dynamic logic for hybrid programs, which is a program notation for hybrid systems. As a verification technique that is suitable for automation, we introduce a free variable proof calculus with a novel combination of real-valued free variables and Skolemisation for lifting quantifier elimination for real arithmetic to dynamic logic. The calculus is compositional, i.e., it reduces properties of hybrid programs to properties of their parts. Our main result proves that this calculus axiomatises the transition behaviour of hybrid systems completely relative to differential equations. In a case study with cooperating traffic agents of the European Train Control System, we further show that our calculus is well-suited for verifying realistic hybrid systems with parametric system dynamics.},
    author = {Platzer, Andr\'{e}},
    citeulike-article-id = {3615134},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10817-008-9103-8},
    citeulike-linkout-1 = {http://www.springerlink.com/content/r25m38256747082g},
    date-added = {2010-03-08 19:16:36},
    day = {1},
    doi = {10.1007/s10817-008-9103-8},
    issn = {0168-7433},
    journal = {Journal of Automated Reasoning},
    keywords = {hybrid-systems},
    month = aug,
    number = {2},
    pages = {143--189},
    priority = {2},
    title = {Differential Dynamic Logic for Hybrid Systems},
    url = {http://dx.doi.org/10.1007/s10817-008-9103-8},
    volume = {41},
    year = {2008}
}

@inproceedings{mattmight:Henzinger:1995:Decidable,
    address = {New York, NY, USA},
    author = {Henzinger, Thomas A. and Kopke, Peter W. and Puri, Anuj and Varaiya, Pravin},
    booktitle = {STOC '95: Proceedings of the twenty-seventh annual ACM symposium on Theory of computing},
    citeulike-article-id = {1921552},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=225058.225162},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/225058.225162},
    date-added = {2010-03-06 18:18:21},
    doi = {10.1145/225058.225162},
    isbn = {0897917189},
    keywords = {hybrid-systems},
    pages = {373--382},
    priority = {2},
    publisher = {ACM},
    title = {What's decidable about hybrid automata?},
    url = {http://dx.doi.org/10.1145/225058.225162},
    year = {1995}
}

@misc{mattmight:Toi:1997:Synthesis,
    abstract = {We present a semidecision procedure for synthesizingcontrollers for hybrid systems modeled as linear hybridautomata. The procedure is easily modified for partialobservability, at the cost of completeness. The procedurehas been implemented, and tested on the synthesisof controllers for various models of a steam {boiler.Since} the synthesis procedure may generate controllersthat are Zeno, i.e. they prevent time from diverging,we provide sufficient, but not necessary, conditions onlinear...},
    author = {Toi, H. Wong},
    citeulike-article-id = {588247},
    citeulike-linkout-0 = {http://citeseer.ist.psu.edu/wong-toi97synthesis.html},
    citeulike-linkout-1 = {http://citeseer.lcs.mit.edu/wong-toi97synthesis.html},
    citeulike-linkout-2 = {http://citeseer.ifi.unizh.ch/wong-toi97synthesis.html},
    citeulike-linkout-3 = {http://citeseer.comp.nus.edu.sg/wong-toi97synthesis.html},
    date-added = {2010-03-06 18:17:42},
    keywords = {hybrid-systems},
    priority = {2},
    title = {The synthesis of controllers for linear hybrid automata},
    url = {http://citeseer.ist.psu.edu/wong-toi97synthesis.html},
    year = {1997}
}

@article{mattmight:Campagna:2010:HybridAutomata,
    abstract = {Hybrid automata are a powerful formalism for the representation of systems evolving according to both discrete and continuous laws. Unfortunately, undecidability soon emerges when one tries to automatically verify hybrid automata properties. An important verification problem is the reachability one that demands to decide whether a set of points is reachable from a starting region. If we focus on  semi-algebraic hybrid automata  the reachability problem is semi-decidable. However, high computational costs have to be afforded to solve it. We analyse this problem by exploiting some existing tools and we show that even simple examples cannot be efficiently solved. It is necessary to introduce approximations to reduce the number of variables, since this is the main source of runtime requirements. We propose some standard approximation methods based on Taylor polynomials and ad-hoc strategies. We implement our methods within the software  {SAHA}-Tool  and we show their effectiveness on two biological examples: the Repressilator and the {Delta-Notch} protein signaling.},
    author = {Campagna, Dario and Piazza, Carla},
    citeulike-article-id = {6526024},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.tcs.2009.12.015},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0304397509008512},
    date-added = {2010-03-06 18:16:42},
    day = {06},
    doi = {10.1016/j.tcs.2009.12.015},
    issn = {03043975},
    journal = {Theoretical Computer Science},
    keywords = {hybrid-systems},
    month = jan,
    priority = {2},
    title = {Hybrid automata, reachability, and systems Biology},
    url = {http://dx.doi.org/10.1016/j.tcs.2009.12.015},
    year = {2010}
}

@inproceedings{mattmight:Henzinger:1996:HybridAutomata,
    abstract = {We summarize several recent results about hybrid automata. Our goal is to demonstrate that concepts from the theory of discrete concurrent systems can give insights into partly continuous systems, and that methods for the verification of finite-state systems can be used to analyze certain systems with uncountable state spaces},
    author = {Henzinger, T. A.},
    booktitle = {Logic in Computer Science, 1996. LICS '96. Proceedings., Eleventh Annual IEEE Symposium on},
    citeulike-article-id = {3623016},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/LICS.1996.561342},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=561342},
    date-added = {2010-03-06 18:15:38},
    doi = {10.1109/LICS.1996.561342},
    journal = {Eleventh Annual IEEE Symposium on Logic in Computer Science, 1996. LICS '96.},
    keywords = {hybrid-systems},
    pages = {278--292},
    priority = {2},
    title = {The theory of hybrid automata},
    url = {http://dx.doi.org/10.1109/LICS.1996.561342},
    year = {1996}
}

@inproceedings{mattmight:Ghuloum:2006:Incremental,
    abstract = {Compilers are perceived to be magical artifacts, carefully crafted by the wizards, and unfathomable by the mere mortals. Books on compilers are better described as wizard-talk: written by and for a clique of all-knowing practitioners. Real-life compilers are too complex to serve as an educational tool. And the gap between real-life compilers and the educational toy compilers is too wide. The novice compiler writer stands puzzled facing an impenetrable barrier,  ” better write an interpreter instead.”

The goal of this paper is to break that barrier. We show that building a compiler can be as easy as building an interpreter. The compiler we construct accepts a large subset of the Scheme programming language and produces assembly code for the Intel-x86 architecture, the dominant architecture of personal computing. The development of the compiler is broken into many small incremental steps. Every step yields a fully working compiler for a progressively expanding subset of Scheme. Every compiler step produces real assembly code that can be assembled then executed directly by the hardware. We assume that the reader is familiar with the basic computer architecture: its components and execution model. Detailed knowledge of the Intel-x86 architecture is not required.

The development of the compiler is described in detail in an extended tutorial. Supporting material for the tutorial such as an automated testing facility coupled with a comprehensive test suite are provided with the tutorial. It is our hope that current and future implementors of Scheme find in this paper the motivation for developing high-performance compilers and the means for achieving that goal.},
    author = {Ghuloum, Abdulaziz},
    booktitle = {Scheme and Functional Programming 2006},
    citeulike-article-id = {2546691},
    citeulike-linkout-0 = {http://scheme2006.cs.uchicago.edu/11-ghuloum.pdf},
    date-added = {2010-01-06 20:26:09},
    keywords = {compiler, compilers, education},
    priority = {2},
    title = {An Incremental Approach to Compiler Construction},
    url = {http://scheme2006.cs.uchicago.edu/11-ghuloum.pdf}
}

@electronic{mattmight:Alioth:Shootout,
    citeulike-article-id = {6346218},
    citeulike-linkout-0 = {http://shootout.alioth.debian.org/},
    date-added = {2009-12-09 21:44:51},
    howpublished = {http://shootout.alioth.debian.org/},
    priority = {2},
    title = {Computer Language Benchmarks Game},
    url = {http://shootout.alioth.debian.org/},
    year = {2009}
}

@phdthesis{mattmight:Morrisett:1995:Dissertation,
    abstract = {Compilers for monomorphic languages, such as C and Pascal, take advantage of types to determine data representations, alignment, calling conventions, and register selection. However, these languages lack important features including polymorphism, abstract datatypes, and garbage collection. In contrast, modern programming languages such as Standard {ML} ({SML}), provide all of these features, but existing implementations fail to take full advantage of types. The result is that performance of {SML} code is quite bad when compared to C. In this thesis, I provide a general framework, called type-directed compilation, that allows compiler writers to take advantage of types at all stages in compilation. In the framework, types are used not only to determine efficient representations and calling conventions, but also to prove the correctness of the compiler. A key property of type- directed compilation is that all but the lowest levels of the compiler use typed intermediate languages. An advantage of this approach is that it provides a means for automatically checking the integrity of the resulting code. An important contribution of this work is the development of a new, statically- typed intermediate language, called {lambda-MLi} . This language supports dynamic type dispatch, providing a means to select operations based on types at run time. I show how to use dynamic type dispatch to support polymorphism, ad-hoc operators, and garbage collection without having to box or tag values. This allows compilers for {SML} to take advantage of techniques used in C compilers, without sacrificing language features or separate compilation. To demonstrate the applicability of my approach, I, along with others, have constructed a new compiler for {SML} called {TIL} that eliminates most restrictions on the representations of values. The code produced by {TIL} is roughly twice as fast as code produced by the {SML}/{NJ} compiler. This is due at least partially to the use of natural representations, but primarily to the conventional optimizer which manipulates typed, {lambda-MLi} code. {TIL} demonstrates that combining type-directed compilation with dynamic type dispatch yields a superior architecture for compilers of modern languages.},
    author = {Morrisett, Greg},
    citeulike-article-id = {6346253},
    date-added = {2009-12-09 21:39:15},
    keywords = {compilers, dissertation},
    month = dec,
    priority = {4},
    school = {Carnegie Mellon University},
    title = {Compiling with Types},
    year = {1995}
}

@electronic{mattmight:Stalin,
    abstract = {procedures contain single concrete procedures when the procedure has no closure-pointer slot, due to closure-pointer--slot elimination, as described below. Furthermore, the concrete aggregate objects in abstract aggregate objects such as pairs, strings, vectors, symbols, continuations, and procedures are indistinguishable when their identity is not important and the components of those aggregate objects are fictitious or unaccessed. Such a collection of indistinguishable concrete objects can be treated as a single concrete object. Finally, continuations can be indistinguishable in certain circumstances that require a must-alias property to hold. The method used by Stalin to approximate this must-alias property is the crux of the lightweight closure-conversion process and is described in detail in section 3.12. Experiments reported in section 4 show that closure-pointer--slot elimination, in practice, allows most procedures to be fictitious and the variables holding such procedures to be eliminated. Not only does the notion of fictitious variables a\#ect code generation, by eliminating the slots, parameters, passing, and spilling for such variables, as well as references to such variables, it also impacts the lightweight closure-conversion process itself. Free references to fictitious variables are ignored, allowing a greater degree of parent-slot, closure-pointer--slot, parent-parameter, parent-passing, and parent-spilling elimination.},
    author = {Siskind, Jeffrey M.},
    citeulike-article-id = {6346229},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.5.997},
    date-added = {2009-12-09 21:23:12},
    keywords = {compilers},
    priority = {2},
    title = {{Flow-Directed} Lightweight Closure Conversion},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.5.997},
    year = {1999}
}

@article{mattmight:Hughes:1989:Why,
    abstract = {As software becomes more and more complex, it is more and more important to structure it well. Well-structured software is easy to write, easy to debug, and provides a collection of modules that can be re-used to reduce future programming costs. Conventional languages place conceptual limits on the way problems can be modularised. Functional languages push those limits back. In this paper we show that two features of functional languages in particular, higher-order functions and lazy...},
    author = {Hughes, John},
    citeulike-article-id = {494117},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.3346},
    date-added = {2009-12-09 21:13:34},
    journal = {Computer Journal},
    number = {2},
    pages = {98--107},
    priority = {2},
    title = {Why Functional Programming Matters},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.3346},
    volume = {32},
    year = {1989}
}

@inproceedings{mattmight:Rees:1982:T,
    abstract = {The T project is an experiment in language design and implementation. Its purpose is to test the thesis developed by Steele and Sussman in their series of papers about the Scheme language: that Scheme may be used as the basis for a practical programming language of exceptional expressive power; and, that implementations of Scheme could perform better than other Lisp systems, and competitively with implementations of programming languages, such as C and Bliss, which are usually considered to be inherently more efficient than Lisp on conventional machine architectures. We are developing a portable implementation of T, currently targeted for the {VAX} under the Unix and {VMS} operating systems and for the Apollo, a {MC68000}-based workstation.},
    address = {New York, NY, USA},
    author = {Rees, Jonathan A. and Adams, Norman I.},
    booktitle = {LFP '82: Proceedings of the 1982 ACM Symposium on LISP and Functional Programming},
    citeulike-article-id = {6346208},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=800068.802142},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/800068.802142},
    date-added = {2009-12-09 21:11:20},
    doi = {10.1145/800068.802142},
    isbn = {0-89791-082-6},
    keywords = {compilers},
    location = {Pittsburgh, Pennsylvania, United States},
    pages = {114--122},
    priority = {2},
    publisher = {ACM},
    title = {T: A dialect of Lisp or {LAMBDA}: The ultimate software tool},
    url = {http://dx.doi.org/10.1145/800068.802142},
    year = {1982}
}

@inproceedings{mattmight:VanHorn:2007:Complexity,
    address = {New York, NY, USA},
    author = {Van{ }Horn, David and Mairson, Harry G.},
    booktitle = {ICFP '07: Proceedings of the 12th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {2784124},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1291151.1291166},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1291151.1291166},
    date-added = {2009-12-09 21:07:31},
    doi = {10.1145/1291151.1291166},
    isbn = {9781595938152},
    keywords = {cfa},
    pages = {85--96},
    priority = {2},
    publisher = {ACM},
    title = {Relating complexity and precision in control flow analysis},
    url = {http://dx.doi.org/10.1145/1291151.1291166},
    year = {2007}
}

@inproceedings{mattmight:Kranz:1986:Orbit,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has opted to expose the complete List rather than only correct and linked references.},
    address = {New York, NY, USA},
    author = {Kranz, David and Kelsey, Richard and Rees, Jonathan and Hudak, Paul and Philbin, James and Adams, Norman},
    booktitle = {SIGPLAN '86: Proceedings of the 1986 SIGPLAN Symposium on Compiler Construction},
    citeulike-article-id = {6346186},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=12276.13333},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/12276.13333},
    date-added = {2009-12-09 20:57:15},
    doi = {10.1145/12276.13333},
    isbn = {0-89791-197-0},
    keywords = {compilers},
    location = {Palo Alto, California, United States},
    pages = {219--233},
    priority = {2},
    publisher = {ACM},
    title = {{ORBIT}: An optimizing compiler for scheme},
    url = {http://dx.doi.org/10.1145/12276.13333},
    year = {1986}
}

@inbook{mattmight:Sharir:1981:CallStrings,
    address = {Englewood Cliffs, NJ},
    author = {Sharir, Micha and Pnueli, Amir},
    booktitle = {Program Flow Analysis: Theory and Applications},
    chapter = {7},
    citeulike-article-id = {812751},
    date-added = {2009-12-09 20:46:40},
    editor = {Muchnick, Steven S. and Jones, Neil D.},
    keywords = {context-sensitivity, static-analysis},
    pages = {189--234},
    priority = {2},
    publisher = {Prentice-Hall},
    title = {Two approaches to interprocedural data flow analysis},
    year = {1981}
}

@article{mattmight:Lhotak:2008:Benefits,
    abstract = {We present Paddle, a framework of {BDD}-based context-sensitive points-to and call graph analyses for Java, as well as client analyses that use their results. Paddle supports several variations of context-sensitive analyses, including call site strings and object sensitivity, and context-sensitively specializes both pointer variables and the heap abstraction. We empirically evaluate the precision of these context-sensitive analyses on significant Java programs. We find that that object-sensitive analyses are more precise than comparable variations of the other approaches, and that specializing the heap abstraction improves precision more than extending the length of context strings.},
    address = {New York, NY, USA},
    author = {Lhot\'{a}k, Ond\v{r}ej and Hendren, Laurie},
    citeulike-article-id = {6335550},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1391987},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1391984.1391987},
    date-added = {2009-12-07 19:41:12},
    doi = {10.1145/1391984.1391987},
    issn = {1049-331X},
    journal = {ACM Transactions on Software Engineering Methodology},
    keywords = {pointer-analysis},
    number = {1},
    pages = {1--53},
    priority = {2},
    publisher = {ACM},
    title = {Evaluating the benefits of context-sensitive points-to analysis using a {BDD}-based implementation},
    url = {http://dx.doi.org/10.1145/1391984.1391987},
    volume = {18},
    year = {2008}
}

@techreport{mattmight:Kudrjavets:2006:Assertions,
    author = {Kudrjavets, Gunnar and Nagappan, Nachiappan and Ball, Thomas},
    citeulike-article-id = {6240494},
    citeulike-linkout-0 = {http://research.microsoft.com/pubs/70290/tr-2006-54.pdf},
    date-added = {2009-11-29 21:57:43},
    institution = {Microsoft Research},
    keywords = {software-engineering},
    priority = {2},
    title = {Assessing the Relationship between Software Assertions and Code Quality:                        
An Empirical Investigation},
    url = {http://research.microsoft.com/pubs/70290/tr-2006-54.pdf},
    year = {2006}
}

@inproceedings{mattmight:Might:2010:Shape,
    address = {Madrid, Spain},
    author = {Might, Matthew},
    booktitle = {VMCAI 2010: International Conference on Verification, Model-Checking and Abstract Interpretation},
    citeulike-article-id = {6199686},
    date-added = {2009-11-23 21:57:08},
    keywords = {cfa, shape-analysis, static-analysis},
    month = jan,
    pages = {263--278},
    priority = {2},
    title = {Shape Analysis in the Absence of Pointers and Structure},
    year = {2010}
}

@article{mattmight:Massalin:1987:Superoptimizer,
    abstract = {Given an instruction set, the superoptimizer finds the shortest program to compute a function. Startling programs have been generated, many of them engaging in convoluted bit-fiddling bearing little resemblance to the source programs which defined the functions. The key idea in the superoptimizer is a probabilistic test that makes exhaustive searches practical for programs of useful size. The search space is defined by the processor's instruction set, which may include the whole set, but it is typically restricted to a subset. By constraining the instructions and observing the effect on the output program, one can gain insight into the design of instruction sets. In addition, superoptimized programs may be used by peephole optimizers to improve the quality of generated code, or by assembly language programmers to improve manually written code.},
    address = {New York, NY, USA},
    author = {Massalin, Henry},
    booktitle = {ASPLOS-II: Proceedings of the Second International Conference on Architectual Support for Programming Languages and Operating Systems},
    citeulike-article-id = {2308147},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=36206.36194},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/36206.36194},
    date-added = {2009-11-23 01:15:52},
    doi = {10.1145/36206.36194},
    isbn = {0-8186-0805-6},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    location = {Palo Alto, California, United States},
    month = oct,
    pages = {122--126},
    priority = {2},
    publisher = {ACM},
    title = {Superoptimizer: A look at the smallest program},
    url = {http://dx.doi.org/10.1145/36206.36194},
    volume = {22},
    year = {1987}
}

@inproceedings{mattmight:Salcianu:2001:Escape,
    abstract = {This paper presents a new combined pointer and escape analysis for multithreaded programs. The algorithm uses a new abstraction called  parallel interaction graphs  to analyze the interactions between threads and extract precise points-to, escape, and action ordering information for objects accessed by multiple threads. The analysis is compositional, analyzing each method or thread once to extract a parameterized analysis result that can be specialized for use in any context. It is also capable of analyzing programs that use the unstructured form of multithreading present in languages such as Java and standard threads packages such as {POSIX} threads. We have implemented the analysis in the {MIT} Flex compiler for Java and used the extracted information to 1) verify that programs correctly use region-based allocation constructs, 2) eliminate dynamic checks associated with the use of regions, and 3) eliminate unnecessary synchronization. Our experimental results show that analyzing the interactions between threads significantly increases the effectiveness of the region analysis and region check elimination, but has little effect for synchronization elimination.},
    address = {New York, NY, USA},
    author = {Salcianu, Alexandru and Rinard, Martin},
    booktitle = {PPoPP '01: Proceedings of the eighth ACM SIGPLAN symposium on Principles and practices of parallel programming},
    citeulike-article-id = {705812},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=379553},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/379539.379553\%3C},
    date-added = {2009-11-21 20:36:25},
    doi = {10.1145/379539.379553\%3C},
    isbn = {1-58113-346-4},
    keywords = {escape-analysis},
    location = {Snowbird, Utah, United States},
    pages = {12--23},
    priority = {2},
    publisher = {ACM},
    title = {Pointer and escape analysis for multithreaded programs},
    url = {http://dx.doi.org/10.1145/379539.379553\%3C},
    year = {2001}
}

@inproceedings{mattmight:Kurlander:1996:RegisterAllocation,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has opted to expose the complete List rather than only correct and linked references.},
    address = {New York, NY, USA},
    author = {Kurlander, Steven M. and Fischer, Charles N.},
    booktitle = {POPL '96: Proceedings of the 23rd ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {6182359},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=237721.237780},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/237721.237780},
    date-added = {2009-11-21 19:36:54},
    doi = {10.1145/237721.237780},
    isbn = {0-89791-769-3},
    keywords = {register-allocation},
    location = {St. Petersburg Beach, Florida, United States},
    pages = {230--241},
    priority = {2},
    publisher = {ACM},
    title = {Minimum cost interprocedural register allocation},
    url = {http://dx.doi.org/10.1145/237721.237780},
    year = {1996}
}

@inproceedings{mattmight:Yang:2009:Flattening,
    abstract = {Most programming languages support a call stack in the programming model and also in the runtime {system.We} show that for applications targeting low-power embedded microcontrollers ({MCUs}), {RAM} usage can be significantly decreased by partially or completely eliminating the runtime callstack. We present flattening, a transformation that absorbs a function into its caller, replacing function invocations and returns with jumps. Unlike inlining, flattening does not duplicate the bodies of functions that have multiple callsites. Applied aggressively, flattening results in  stack elimination . Flattening is most useful in conjunction with a  lifting  transformation that moves global variables into a local scope.},
    address = {New York, NY, USA},
    author = {Yang, Xuejun and Cooprider, Nathan and Regehr, John},
    booktitle = {LCTES '09: Proceedings of the 2009 ACM SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems},
    citeulike-article-id = {5907523},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1542452.1542461},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1542452.1542461},
    date-added = {2009-11-21 19:22:06},
    doi = {10.1145/1542452.1542461},
    isbn = {978-1-60558-356-3},
    keywords = {flattening, stack},
    location = {Dublin, Ireland},
    pages = {60--69},
    priority = {2},
    publisher = {ACM},
    title = {Eliminating the call stack to save {RAM}},
    url = {http://dx.doi.org/10.1145/1542452.1542461},
    year = {2009}
}

@article{mattmight:Dybvig:1993:Macro,
    abstract = {Naive program transformations can have surprising effects due to the interaction between introduced identifier references and previously existing identifier bindings, or between introduced bindings and previously existing references. These interactions can result in inadvertent binding, or capturing, of identifiers. A further complication is that transformed programs may have little resemblance to original programs, making correlation of source and object code difficult. This article describes an efficient macro system that prevents inadvertent capturing while maintaining the correlation between source and object code. The macro system allows the programmer to define program transformations using an unrestricted, general-purpose language. Previous approaches to the capturing problem have been inadequate, overly restrictive, or inefficient, and the problem of source-object correlation has been largely unaddressed. The macro system is based on a new algorithm for implementing syntactic transformations and a new representation for syntactic expressions.},
    author = {Dybvig, Kent R. and Hieb, Robert and Bruggeman, Carl},
    citeulike-article-id = {3623282},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/BF01806308},
    citeulike-linkout-1 = {http://www.springerlink.com/content/rh4u5364r6183v52},
    date-added = {2009-10-21 16:57:29},
    day = {1},
    doi = {10.1007/BF01806308},
    journal = {LISP and Symbolic Computation},
    keywords = {macros},
    month = dec,
    number = {4},
    pages = {295--326},
    priority = {2},
    title = {Syntactic abstraction in scheme},
    url = {http://dx.doi.org/10.1007/BF01806308},
    volume = {5},
    year = {1993}
}

@inproceedings{mattmight:Clinger:1991:Macros,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Clinger, William and Rees, Jonathan},
    booktitle = {POPL '91: Proceedings of the 18th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {1163},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=99607},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/99583.99607},
    comment = {Describes the efficicent implementation of syntax-rules hygienic macros.},
    date-added = {2009-10-21 06:24:56},
    doi = {10.1145/99583.99607},
    isbn = {0-89791-419-8},
    keywords = {macros},
    location = {Orlando, Florida, United States},
    pages = {155--162},
    priority = {5},
    publisher = {ACM},
    series = {POPL '91},
    title = {Macros that work},
    url = {http://dx.doi.org/10.1145/99583.99607},
    year = {1991}
}

@inproceedings{mattmight:Kohlbecker:1986:Macro,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has opted to expose the complete List rather than only correct and linked references.},
    address = {New York, NY, USA},
    author = {Kohlbecker, Eugene and Friedman, Daniel P. and Felleisen, Matthias and Duba, Bruce},
    booktitle = {LFP '86: Proceedings of the 1986 ACM Conference on LISP and Functional Programming},
    citeulike-article-id = {1345},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=319859},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/319838.319859},
    date-added = {2009-10-21 05:17:02},
    doi = {10.1145/319838.319859},
    isbn = {0-89791-200-4},
    keywords = {macros},
    location = {Cambridge, Massachusetts, United States},
    pages = {151--161},
    priority = {2},
    publisher = {ACM},
    title = {Hygienic macro expansion},
    url = {http://dx.doi.org/10.1145/319838.319859},
    year = {1986}
}

@inproceedings{mattmight:Kohlbecker:1987:Macro,
    abstract = {This paper presents two new developments. First, it describes a  ” macro-by-example” specification language for syntactic abstractions in Lisp and related languages. This specification language allows a more declarative specification of macros than conventional macro facilities do by giving a better treatment of iteration and mapping constructs. Second, it gives a formal semantics for the language and a derivation of a compiler from the semantics. This derivation is a practical application of semantics-directed compiler development methodology.},
    address = {New York, NY, USA},
    author = {Kohlbecker, Eugene E. and Wand, Mitchell},
    booktitle = {POPL '87: Proceedings of the 14th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
    citeulike-article-id = {190436},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=41632},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/41625.41632},
    date-added = {2009-10-21 05:13:33},
    doi = {10.1145/41625.41632},
    isbn = {0-89791-215-2},
    keywords = {macros},
    location = {Munich, West Germany},
    pages = {77--84},
    priority = {4},
    publisher = {ACM},
    title = {Macro-by-example: Deriving syntactic transformations from their specifications},
    url = {http://dx.doi.org/10.1145/41625.41632},
    year = {1987}
}

@incollection{mattmight:Cousot:2006:Parsing,
    author = {Cousot, Patrick and Cousot, Radhia},
    booktitle = {Program Analysis and Compilation, Theory and Practice: Essays dedicated to Reinhard Wilhelm},
    citeulike-article-id = {5914408},
    date-added = {2009-10-09 07:05:34},
    editor = {Reps, Tom and Sagiv, Mooly and Bauer, Jorg},
    keywords = {parsing},
    month = dec,
    pages = {178--203},
    priority = {2},
    publisher = {Springer\\discretionary{-}{}{-}Verlag},
    series = {LNCS 4444},
    title = {Grammar Analysis and Parsing by Abstract Interpretation, invited chapter},
    year = {2006}
}

@article{mattmight:Cousot:2003:Parsing,
    author = {Cousot, Patrick and Cousot, Radhia},
    citeulike-article-id = {5914403},
    date-added = {2009-10-09 07:03:46},
    journal = {Theoretical Computer Science},
    keywords = {parsing},
    pages = {531--544},
    priority = {2},
    title = {Parsing as Abstract Interpretation of Grammar Semantics},
    volume = {290},
    year = {2003}
}

@techreport{mattmight:DeRemer:1969:LALR,
    abstract = {A context-free syntactical translator ({CFST}) is a machine which defines a translation from one context-free language to another. A transduction grammar is a formal system based on a context-free grammar and it specifies a context-free syntactical translation. A simple suffix transduction grammar based on a context-free grammar which is {LR}(k) specifies a translation which can be defined by a deterministic push-down automation ({DPDA}). A method is presented for automatically constructing {CFSTs} ({DPDAs}) from those simple suffix transduction grammars which are based on the {LR}(k) grammars. The method is developed by first considering grammatical analysis from the string-manipulation viewpoint, then converting the resulting string-manipulation.},
    address = {Cambridge, MA, USA},
    author = {DeRemer, Frank L.},
    citeulike-article-id = {5914368},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=888578},
    date-added = {2009-10-09 06:41:14},
    priority = {2},
    publisher = {Massachusetts Institute of Technology},
    title = {Practical Translators for {LR}(k) Languages},
    url = {http://portal.acm.org/citation.cfm?id=888578},
    year = {1969}
}

@article{mattmight:DeRemer:1971:SLR,
    abstract = {A class of context-free grammars, called the  ” Simple  {LR} ( k )” or  {SLR} ( k ) grammars is defined. This class has been shown to include weak precedence and simple precedence grammars as proper subsets. How to construct parsers for the  {SLR} ( k ) grammars is also shown. These parser-construction techniques are extendible to cover all of the  {LR} ( k ) grammars of Knuth; they have been implemented and by direct comparison proved to be superior to precedence techniques, not only in the range of grammars covered, but also in the speed of parser construction and in the size and speed of the resulting parsers.},
    address = {New York, NY, USA},
    author = {DeRemer, Franklin L.},
    citeulike-article-id = {5427240},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=362625},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/362619.362625},
    date-added = {2009-10-09 06:39:26},
    doi = {10.1145/362619.362625},
    issn = {0001-0782},
    journal = {Communications of the ACM},
    keywords = {parsing},
    number = {7},
    pages = {453--460},
    priority = {2},
    publisher = {ACM},
    title = {Simple {LR}(k) grammars},
    url = {http://dx.doi.org/10.1145/362619.362625},
    volume = {14},
    year = {1971}
}

@inproceedings{mattmight:Masaru:1984:GLR,
    abstract = {{MLR}, an extended {LR} parser, is introduced, and its application to natural language parsing is discussed. An {LR} parser is a shift-reduce parser which is deterministically guided by a parsing table. A parsing table can be obtained automatically from a context-free phrase structure grammar. {LR} parsers cannot manage ambiguous grammars such as natural language grammars, because their parsing tables would have multiply-defined entries, which precludes deterministic parsing. {MLR}, however, can handle multiply-defined entries, using a dynamic programming method. When an input sentence is ambiguous, the {MLR} parser produces all possible parse trees without parsing any part of the input sentence more than once in the same way, despite the fact that the parser does not maintain a chart as in chart parsing. Our method also provides an elegant solution to the problem of multi-part-of-speech words such as "that". The {MLR} parser and its parsing table generator have been implemented at {Carnegie-Mellon} University.},
    address = {Morristown, NJ, USA},
    author = {Tomita, Masaru},
    booktitle = {ACL-22: Proceedings of the 10th International Conference on Computational Linguistics and 22nd annual meeting on Association for Computational Linguistics},
    citeulike-article-id = {5914351},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=980564},
    citeulike-linkout-1 = {http://dx.doi.org/10.3115/980431.980564},
    date-added = {2009-10-09 06:35:10},
    doi = {10.3115/980431.980564},
    keywords = {parsing},
    location = {Stanford, California},
    pages = {354--357},
    priority = {2},
    publisher = {Association for Computational Linguistics},
    title = {{LR} parsers for natural languages},
    url = {http://dx.doi.org/10.3115/980431.980564},
    year = {1984}
}

@article{mattmight:Earley:1970:Parsing,
    abstract = {A parsing algorithm which seems to be the most efficient general context-free algorithm known is described. It is similar to both Knuth's {LR}(k) algorithm and the familiar top-down algorithm. It has a time bound proportional to n3 (where n is the length of the string being parsed) in general; it has an n2 bound for unambiguous grammars; and it runs in linear time on a large class of grammars, which seems to include most practical context-free programming language grammars. In an empirical comparison it appears to be superior to the top-down and bottom-up algorithms studied by Griffiths and Petrick.},
    address = {New York, NY, USA},
    author = {Earley, Jay},
    citeulike-article-id = {5914341},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=362035},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/362007.362035},
    date-added = {2009-10-09 06:31:38},
    doi = {10.1145/362007.362035},
    issn = {0001-0782},
    journal = {Communications of the ACM},
    keywords = {parsing},
    month = feb,
    number = {2},
    pages = {94--102},
    priority = {2},
    publisher = {ACM},
    title = {An efficient context-free parsing algorithm},
    url = {http://dx.doi.org/10.1145/362007.362035},
    volume = {13},
    year = {1970}
}

@techreport{mattmight:Cocke:1970:CYK,
    address = {New York, NY},
    author = {Cocke, John and Schwartz, Jacob T.},
    citeulike-article-id = {5914339},
    date-added = {2009-10-09 06:28:24},
    institution = {Courant Institute of Mathematical Sciences, New York University},
    keywords = {parsing},
    priority = {2},
    title = {Programming languages and their compilers: Preliminary notes},
    year = {1970}
}

@techreport{mattmight:Kasami:1965:CYK,
    address = {Bedford, MA},
    author = {An efficient recognition and syntax-analysis algorithm for context-free languages},
    citeulike-article-id = {5914335},
    date-added = {2009-10-09 06:26:26},
    institution = {Air Force Cambridge Research Lab},
    priority = {2},
    title = {Tadao Kasami},
    year = {1965}
}

@article{mattmight:Younger:1967:CYK,
    author = {Younger, Daniel H.},
    citeulike-article-id = {5914327},
    date-added = {2009-10-09 06:23:37},
    journal = {Information and Control},
    keywords = {parsing},
    number = {2},
    pages = {189--208},
    priority = {2},
    title = {Recognition and parsing of context-free languages in time n3},
    volume = {10},
    year = {1967}
}

@article{mattmight:Knuth:1965:LR,
    author = {Knuth, Donald},
    citeulike-article-id = {5914311},
    date-added = {2009-10-09 06:17:47},
    journal = {Information and Control},
    keywords = {parsing},
    pages = {607--639},
    priority = {2},
    title = {On the Translation of Languages from Left to Right},
    volume = {8},
    year = {1965}
}

@article{mattmight:Floyd:1963:Syntactic,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has opted to expose the complete List rather than only correct and linked references.},
    address = {New York, NY, USA},
    author = {Floyd, Robert W.},
    citeulike-article-id = {1730732},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=321179},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/321172.321179},
    date-added = {2009-10-09 06:11:05},
    doi = {10.1145/321172.321179},
    issn = {0004-5411},
    journal = {Journal of the ACM},
    keywords = {parsing},
    month = jul,
    number = {3},
    pages = {316--333},
    priority = {2},
    publisher = {ACM},
    title = {Syntactic Analysis and Operator Precedence},
    url = {http://dx.doi.org/10.1145/321172.321179},
    volume = {10},
    year = {1963}
}

@article{mattmight:Floyd:1964:Bounded,
    abstract = {Certain phase structure grammars define languages in which the phrasehood and structure of a substring of a sentence may be determined by consideration of only a bounded context of the substring. It is possible to determine, for any specified bound on the number of contextual characters considered, whether a given grammar is such a  bounded context grammar . Such grammars are free from syntactic ambiguity. Syntactic analysis of sentences in a bounded context language may be performed by a standard process and requires a number of operations proportional to the length of sentence analyzed.   Bounded context grammars form models for most languages used in computer programming, and many methods of syntactic analysis, including analysis by operator precedence, are special cases of bounded context analysis.},
    address = {New York, NY, USA},
    author = {Floyd, Robert W.},
    citeulike-article-id = {5427196},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=363921.363927},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/363921.363927},
    date-added = {2009-10-09 06:07:02},
    doi = {10.1145/363921.363927},
    issn = {0001-0782},
    journal = {Communications of the ACM},
    keywords = {parsing},
    number = {2},
    pages = {62--67},
    priority = {2},
    publisher = {ACM},
    title = {Bounded context syntactic analysis},
    url = {http://dx.doi.org/10.1145/363921.363927},
    volume = {7},
    year = {1964}
}

@book{mattmight:Chomsky:2002:Structures,
    abstract = {{JANUA} {LINGUARUM} / Paperback / 117 pages / Syntactic Structures},
    author = {Chomsky, Noam},
    citeulike-article-id = {3158752},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/3110172798},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/3110172798},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/3110172798},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/3110172798},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/3110172798/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/3110172798},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/3110172798},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN3110172798},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=3110172798\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/3110172798},
    date-added = {2009-10-09 06:05:04},
    day = {31},
    edition = {2nd},
    howpublished = {Paperback},
    isbn = {3110172798},
    keywords = {context-free-grammars, grammars, parsing},
    month = dec,
    priority = {2},
    publisher = {de Gruyter Mouton},
    title = {Syntactic Structures},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/3110172798},
    year = {2002}
}

@inproceedings{mattmight:Pratt:1973:TopDown,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Pratt, Vaughan R.},
    booktitle = {POPL '73: Proceedings of the 1st annual ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
    citeulike-article-id = {1609132},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=512931},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/512927.512931},
    date-added = {2009-10-09 05:57:37},
    doi = {10.1145/512927.512931},
    keywords = {parsing},
    location = {Boston, Massachusetts},
    pages = {41--51},
    priority = {2},
    publisher = {ACM},
    series = {POPL '73},
    title = {Top down operator precedence},
    url = {http://dx.doi.org/10.1145/512927.512931},
    year = {1973}
}

@book{mattmight:Dijkstra:1982:ShuntingYard,
    author = {Dijkstra, Edsger W.},
    citeulike-article-id = {1458676},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0387906525},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0387906525},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0387906525},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0387906525},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0387906525/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0387906525},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0387906525},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0387906525},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0387906525\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0387906525},
    date-added = {2009-10-09 05:53:15},
    day = {25},
    howpublished = {Hardcover},
    isbn = {0387906525},
    keywords = {parsing},
    month = oct,
    priority = {2},
    publisher = {Springer},
    title = {Selected Writings on Computing: A Personal Perspective},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0387906525},
    year = {1982}
}

@book{mattmight:Wirth:1996:CompilerConstruction,
    author = {Wirth, Niklaus},
    citeulike-article-id = {5914226},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0201403536},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0201403536},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0201403536},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0201403536},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0201403536/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0201403536},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0201403536},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0201403536},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0201403536\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0201403536},
    date-added = {2009-10-09 05:45:53},
    edition = {Pap/Dsk},
    howpublished = {Paperback},
    isbn = {0201403536},
    keywords = {compilers},
    priority = {2},
    publisher = {Addison-Wesley Pub (Sd)},
    title = {Compiler Construction (International Computer Science Series)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0201403536}
}

@proceedings{mattmight:Ford:2002:Packrat,
    abstract = {Packrat parsing is a novel technique for implementing parsers in a lazy functional programming language. A packrat parser provides the power and flexibility of top-down parsing with backtracking and unlimited lookahead, but nevertheless guarantees linear parse time. Any language defined by an {LL}(k) or {LR}(k) grammar can be recognized by a packrat parser, in addition to many languages that conventional linear-time algorithms do not support. This additional power simplifies the handling of common...},
    author = {Ford, Bryan},
    booktitle = {Proceedings of the 2002 International Conference on Functional Programming},
    citeulike-article-id = {3219},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.1175},
    date-added = {2009-10-09 03:20:51},
    keywords = {parsing},
    month = oct,
    priority = {2},
    title = {Packrat Parsing: Simple, Powerful, Lazy, Linear Time},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.1175},
    year = {2002}
}

@inproceedings{mattmight:Blanchet:1998:Escape,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Blanchet, Bruno},
    booktitle = {POPL '98: Proceedings of the 25th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5908472},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=268949},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/268946.268949},
    date-added = {2009-10-08 04:31:05},
    doi = {10.1145/268946.268949},
    isbn = {0-89791-979-3},
    keywords = {abstract-interpretation, escape-analysis, static-analysis},
    location = {San Diego, California, United States},
    pages = {25--37},
    priority = {2},
    publisher = {ACM},
    series = {POPL '98},
    title = {Escape analysis: Correctness proof, implementation and experimental results},
    url = {http://dx.doi.org/10.1145/268946.268949},
    year = {1998}
}

@inproceedings{mattmight:Bravenboer:2009:Exceptions,
    abstract = {Exception analysis and points-to analysis are typically done in complete separation. Past algorithms for precise exception analysis (e.g., pairing throw clauses with catch statements) use pre-computed points-to information. Past points-to analyses either unsoundly ignore exceptions, or conservatively compute a crude approximation of exception throwing (e.g., considering an exception throw as an assignment to a global variable, accessible from any catch clause). We show that this separation results in significant slowdowns or vast imprecision. The two kinds of analyses are interdependent: neither can be performed accurately without the other. The interdependency leads us to propose a joint handling for performance and precision. We show that our exception analysis is expressible highly elegantly in a declarative form, and can apply to points-to analyses of varying precision. In fact, our specification of exception analysis is "fully precise", as it models closely the Java exception handling semantics. The necessary approximation is provided only through whichever abstractions are used for contexts and objects in the base points-to analysis. Our combined approach achieves similar precision relative to exceptions (exception-catch links) as the best past precise exception analysis, with a runtime of seconds instead of tens of minutes. At the same time, our analysis achieves much higher precision of points-to information (an average of half as many values for each reachable variable for most of the {DaCapo} benchmarks) than points-to analyses that treat exceptions conservatively, all at a fraction of the execution time.},
    address = {New York, NY, USA},
    author = {Bravenboer, Martin and Smaragdakis, Yannis},
    booktitle = {ISSTA '09: Proceedings of the Eighteenth International Symposium on Software Testing and Analysis},
    citeulike-article-id = {5908454},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1572272.1572274},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1572272.1572274},
    date-added = {2009-10-08 04:14:22},
    doi = {10.1145/1572272.1572274},
    isbn = {978-1-60558-338-9},
    keywords = {alias-analysis, exceptions},
    location = {Chicago, IL, USA},
    pages = {1--12},
    priority = {4},
    publisher = {ACM},
    title = {Exception analysis and points-to analysis: Better together},
    url = {http://dx.doi.org/10.1145/1572272.1572274},
    year = {2009}
}

@article{mattmight:Cousot:1999:ModelChecking,
    author = {Cousot, Patrick and Cousot, Radhia},
    citeulike-article-id = {5908422},
    date-added = {2009-10-08 03:57:20},
    journal = {Automated Software Engineering},
    keywords = {abstract-interpretation},
    number = {1},
    pages = {69--95},
    priority = {2},
    title = {Refining Model Checking by Abstract Interpretation},
    volume = {6},
    year = {1999}
}

@article{mattmight:Cousot:1992:Frameworks,
    author = {Cousot, Patrick and Cousot, Radhia},
    citeulike-article-id = {5908413},
    date-added = {2009-10-08 03:54:00},
    journal = {Journal of Logic and Computation},
    keywords = {abstract-interpretation},
    number = {4},
    pages = {511--547},
    priority = {0},
    publisher = {Oxford University Press, Oxford, UK},
    title = {Abstract Interpretation Frameworks},
    volume = {2},
    year = {1992}
}

@inproceedings{mattmight:Might:2009:Dependence,
    address = {Boston, Massachussetts, USA},
    author = {Might, Matthew and Prabhu, Tarun},
    booktitle = {Proceedings of the 2009 Workshop on Scheme and Functional Programming},
    citeulike-article-id = {5906649},
    citeulike-linkout-0 = {http://matt.might.net/},
    date-added = {2009-10-07 17:29:07},
    keywords = {cfa, dependence, parallelization},
    priority = {0},
    title = {Interprocedural dependence analysis of higher-order programs via stack reachability},
    url = {http://matt.might.net/},
    year = {2009}
}

@techreport{mattmight:Henglein:1992:ClosureAnalysis,
    author = {Henglein, Fritz},
    citeulike-article-id = {5906626},
    date-added = {2009-10-07 17:22:24},
    institution = {Department of Computer Science, University of Copenhagen (DIKU)},
    keywords = {cfa},
    month = mar,
    priority = {0},
    title = {Simple Closure Analysis},
    year = {1992}
}

@article{mattmight:R5RS,
    abstract = {Programming languages should be designed not by piling feature on top of feature, but by removing the weaknesses and restrictions that make additional features appear necessary. Scheme demonstrates that a very small number of rules for forming expressions, with no restrictions on how they are composed, suffice to form a practical and efficient programming language that is flexible enough to support most of the major programming paradigms in use today.},
    author = {Kelsey, Richard and Clinger, William and Editors, Jonathan R.},
    citeulike-article-id = {4855},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.4808},
    date-added = {2009-10-07 17:16:28},
    editor = {Kelsey, Richard and Clinger, William and Rees, Jonathan},
    journal = {ACM SIGPLAN Notices},
    keywords = {r5rs, scheme},
    number = {9},
    pages = {26--76},
    priority = {0},
    title = {Fifth Revised Report on the Algorithmic Language Scheme},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.4808},
    volume = {33},
    year = {1998}
}

@misc{mattmight:McBride:2001:Derivative,
    abstract = {Polymorphic regular types are tree-like datatypes generated by polynomial type expressions over a set of free variables and closed under least fixed point. The `equality types' of Core {ML} can be expressed in this form. Given such a type expression T with x free, this paper shows a way to represent the one-hole contexts for elements of x within elements of T , together with an operation which will plug an element of x into the hole of such a context. One-hole contexts are given as inhabitants of ...},
    author = {McBride, Conor},
    citeulike-article-id = {3318},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.8611},
    date-added = {2009-10-07 17:09:43},
    keywords = {derivative, type-theory},
    priority = {2},
    title = {The derivative of a regular type is its type of one-hole contexts},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.8611},
    year = {2001}
}

@misc{mattmight:Comon:2007:TATA,
    author = {Comon, H. and Dauchet, M. and Gilleron, R. and L\"{o}ding, C. and Jacquemard, F. and Lugiez, D. and Tison, S. and Tommasi, M.},
    citeulike-article-id = {5906243},
    comment = {release October, 12th 2007},
    date-added = {2009-10-07 17:03:49},
    howpublished = {Available on: {\tt http://www.grappa.univ-lille3.fr/tata}},
    keywords = {tree-automata},
    priority = {2},
    title = {Tree Automata Techniques and Applications},
    year = {2007}
}

@phdthesis{mattmight:Felleisen:1987:Dissertation,
    author = {Felleisen, Matthias},
    citeulike-article-id = {5906226},
    date-added = {2009-10-07 16:58:55},
    keywords = {cek},
    priority = {2},
    school = {Indiana University},
    title = {The Calculi of {Lambda-v-CS} Conversion: A Syntactic Theory of Control and State in Imperative {Higher-Order} Programming Languages},
    year = {1987}
}

@inproceedings{mattmight:Felleisen:1986:CEK,
    author = {Felleisen, Matthias and Friedman, Daniel P.},
    booktitle = {3rd Working Conference on the Formal Description of Programming Concepts},
    citeulike-article-id = {5906202},
    date-added = {2009-10-07 16:53:00},
    keywords = {cek},
    month = aug,
    priority = {2},
    title = {Control operators, the {SECD}-machine, and the lambda-calculus},
    year = {1986}
}

@inproceedings{mattmight:Midtgaard:2009:CFA,
    abstract = {We derive a control-flow analysis that approximates the interprocedural control-flow of both function calls and returns in the presence of first-class functions and tail-call optimization. In addition to an abstract environment, our analysis computes for each expression an abstract control stack, effectively approximating where function calls return across optimized tail calls. The analysis is systematically calculated by abstract interpretation of the stack-based {CaEK} abstract machine of Flanagan et al. using a series of Galois connections. Abstract interpretation provides a unifying setting in which we 1) prove the analysis equivalent to the composition of a continuation-passing style ({CPS}) transformation followed by an abstract interpretation of a stack-less {CPS} machine, and 2) extract an equivalent constraint-based formulation, thereby providing a rational reconstruction of a constraint-based control-flow analysis from abstract interpretation principles.},
    address = {New York, NY, USA},
    author = {Midtgaard, Jan and Jensen, Thomas P.},
    booktitle = {ICFP '09: Proceedings of the 14th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {5904200},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1596550.1596592},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1596550.1596592},
    date-added = {2009-10-07 03:27:09},
    doi = {10.1145/1596550.1596592},
    isbn = {978-1-60558-332-7},
    keywords = {abstract-interpretation, cfa, control-flow-analysis},
    location = {Edinburgh, Scotland},
    pages = {287--298},
    priority = {0},
    publisher = {ACM},
    title = {Control-flow analysis of function calls and returns by abstract interpretation},
    url = {http://dx.doi.org/10.1145/1596550.1596592},
    year = {2009}
}

@inproceedings{mattmight:Warth:2008:PEG,
    abstract = {Packrat parsing offers several advantages over other parsing techniques, such as the guarantee of linear parse times while supporting backtracking and unlimited look-ahead. Unfortunately, the limited support for left recursion in packrat parser implementations makes them difficult to use for a large class of grammars (Java's, for example). This paper presents a modification to the memoization mechanism used by packrat parser implementations that makes it possible for them to support (even indirectly or mutually) left-recursive rules. While it is possible for a packrat parser with our modification to yield super-linear parse times for some left-recursive grammars, our experimentsshow that this is not the case for typical uses of left recursion.},
    address = {New York, NY, USA},
    author = {Warth, Alessandro and Douglass, James R. and Millstein, Todd},
    booktitle = {PEPM '08: Proceedings of the 2008 ACM SIGPLAN Symposium on Partial Evaluation and Semantics-based Program Manipulation},
    citeulike-article-id = {4140249},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1328408.1328424},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1328408.1328424},
    date-added = {2009-09-22 23:43:12},
    doi = {10.1145/1328408.1328424},
    isbn = {978-1-59593-977-7},
    keywords = {compilers, parsing, peg},
    location = {San Francisco, California, USA},
    pages = {103--110},
    priority = {2},
    publisher = {ACM},
    title = {Packrat parsers can support left recursion},
    url = {http://dx.doi.org/10.1145/1328408.1328424},
    year = {2008}
}

@article{mattmight:Owens:2009:Derivative,
    abstract = {Regular-expression derivatives are an old, but elegant, technique for compiling regular expressions to deterministic finite-state machines. It easily supports extending the regular-expression operators with boolean operations, such as intersection and complement. Unfortunately, this technique has been lost in the sands of time and few computer scientists are aware of it. In this paper, we reexamine regular-expression derivatives and report on our experiences in the context of two different functional-language implementations. The basic implementation is simple and we show how to extend it to handle large character sets (e.g., Unicode). We also show that the derivatives approach leads to smaller state machines than the traditional algorithm given by {McNaughton} and Yamada.},
    address = {New York, NY, USA},
    author = {Owens, Scott and Reppy, John and Turon, Aaron},
    citeulike-article-id = {5794072},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1520288},
    citeulike-linkout-1 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=4584140},
    citeulike-linkout-2 = {http://dx.doi.org/10.1017/S0956796808007090},
    date-added = {2009-09-17 06:41:14},
    doi = {10.1017/S0956796808007090},
    issn = {0956-7968},
    journal = {Journal of Functional Programming},
    keywords = {lexing},
    number = {02},
    pages = {173--190},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Regular-expression derivatives re-examined},
    url = {http://dx.doi.org/10.1017/S0956796808007090},
    volume = {19},
    year = {2009}
}

@article{mattmight:Shannon:1948:Communication,
    author = {Shannon, Claude E.},
    citeulike-article-id = {5671619},
    date-added = {2009-08-29 14:40:29},
    journal = {The Bell Systems Technical Journal},
    keywords = {information-theory},
    month = jul,
    pages = {379--423},
    priority = {4},
    title = {A Mathematical Theory of Communication},
    volume = {27},
    year = {1948}
}

@article{mattmight:Jones:2008:SizeChange,
    author = {Jones, Neil D. and Bohr, Nina},
    citeulike-article-id = {5666342},
    citeulike-linkout-0 = {http://www.lmcs-online.org/ojs/viewarticle.php?id=333\&\#38;layout=abstract},
    date-added = {2009-08-29 04:23:52},
    journal = {Logical Methods in Computer Science},
    number = {1},
    pages = {1--39},
    priority = {4},
    title = {Call-by-value termination in the untyped lambda-calculus},
    url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=333\&\#38;layout=abstract},
    volume = {4},
    year = {2008}
}

@inproceedings{mattmight:Jones:1981:LambdaFlow,
    address = {London, UK},
    author = {Jones, Neil D.},
    booktitle = {Proceedings of the 8th Colloquium on Automata, Languages and Programming},
    citeulike-article-id = {5666324},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=682702},
    date-added = {2009-08-29 04:20:13},
    isbn = {3-540-10843-2},
    keywords = {abstract-interpretation, cfa, control-flow-analysis, static-analysis},
    pages = {114--128},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Flow Analysis of Lambda Expressions (Preliminary Version)},
    url = {http://portal.acm.org/citation.cfm?id=682702},
    year = {1981}
}

@inproceedings{mattmight:Jagannathan:1998:Single,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Jagannathan, Suresh and Thiemann, Peter and Weeks, Stephen and Wright, Andrew},
    booktitle = {POPL '98: Proceedings of the 25th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5666257},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=268973},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/268946.268973},
    date-added = {2009-08-29 04:00:34},
    doi = {10.1145/268946.268973},
    isbn = {0-89791-979-3},
    keywords = {constraint-solving},
    location = {San Diego, California, United States},
    pages = {329--341},
    priority = {0},
    publisher = {ACM},
    series = {POPL '98},
    title = {Single and loving it: must-alias analysis for higher-order languages},
    url = {http://dx.doi.org/10.1145/268946.268973},
    year = {1998}
}

@inproceedings{mattmight:Gulwani:2008:Quantified,
    abstract = {We describe a general technique for building abstract interpreters over powerful  universally quantified  abstract domains that leverage existing quantifier-free domains. Our quantified abstract domain can represent universally quantified facts like ∀ i (0 ≤  i  <  n  ⇒ a[ i ] = 0). The principal challenge in this effort is that, while most domains supply over-approximations of operations like join, meet, and variable elimination, working with the guards of quantified facts requires  under -approximation. We present an automatic technique to convert the standard over-approximation operations provided with all domains into sound under-approximations. We establish the correctness of our abstract interpreters by identifying two lattices---one that establishes the soundness of the abstract interpreter and another that defines its precision, or completeness. Our experiments on a variety of programs using arrays and pointers (including several sorting algorithms) demonstrate the feasibility of the approach on challenging examples.},
    address = {New York, NY, USA},
    author = {Gulwani, Sumit and {Mccloskey}, Bill and Tiwari, Ashish},
    booktitle = {POPL '08: Proceedings of the 35th annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5665539},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1328468},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1328438.1328468},
    date-added = {2009-08-29 02:50:43},
    doi = {10.1145/1328438.1328468},
    isbn = {978-1-59593-689-9},
    keywords = {abstract-interpretation},
    location = {San Francisco, California, USA},
    pages = {235--246},
    priority = {0},
    publisher = {ACM},
    title = {Lifting abstract interpreters to quantified logical domains},
    url = {http://dx.doi.org/10.1145/1328438.1328468},
    year = {2008}
}

@inproceedings{mattmight:Schmidt:1997:SmallStep,
    address = {London, UK},
    author = {Schmidt, David A.},
    booktitle = {Selected papers from the 5th LOMAPS Workshop on Analysis and Verification of Multiple-Agent Languages},
    citeulike-article-id = {5665466},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=710955},
    date-added = {2009-08-29 02:42:27},
    isbn = {3-540-62503-8},
    keywords = {abstract-interpretation, static-analysis},
    pages = {76--99},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Abstract Interpretation of {Small-Step} Semantics},
    url = {http://portal.acm.org/citation.cfm?id=710955},
    year = {1997}
}

@article{mattmight:Cousot:1991:HigherOrder,
    abstract = {We propose a method for the separate static analysis of higher-order functions and procedures using relational abstract domains as opposed to the abstraction of functions by functions on abstract values (as in minimal function graphs).},
    author = {Cousot, Patrick and Cousot, Radhia},
    citeulike-article-id = {5664368},
    date-added = {2009-08-28 21:12:37},
    journal = {BIGRE},
    keywords = {abstract-interpretation},
    pages = {33--36},
    priority = {2},
    publisher = {IRISA, Rennes, France},
    title = {Relational abstract interpretation of higher-order functional programs. {JTASPEFL'91}, {B}ordeaux},
    volume = {74},
    year = {1991}
}

@inproceedings{mattmight:Cousot:1994:HigherOrder,
    abstract = {The original formulation of abstract interpretation represents program properties by sets. A property is understood as the set of semantic values satisfying it. Strongest program properties are defined by the collecting semantics which extends the standard semantics to powersets of semantic values. The approximation relation corresponding to the logical implication of program properties is subset inclusion. This was expressed using set and lattice theory in the context of transition systems. Some applications of abstract interpretation, such as strictness analysis for lazy functional languages, require infinite behaviours of higher-order functions to be taken into account. We solve the problem by returning to the sources of abstract interpretation, which consists in considering collecting semantics. By using Galois connections, properties of the standard semantics naturally transfer to the collecting and then to the abstract semantics. This set-theoretic abstract interpretation framework is formulated in a way which is independent of both the programming language and the method used to specify its semantics. It is illustrated for a higher-order monomorphically typed lazy functional language starting from its standard denotational semantics},
    author = {Cousot, Patrick and Cousot, Radhia},
    booktitle = {Proceedings of the 1994 International Conference on Computer Languages},
    citeulike-article-id = {5664358},
    citeulike-linkout-0 = {http://www.di.ens.fr/\~{}cousot/COUSOTpapers/ICCL94.shtml},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ICCL.1994.288389},
    date-added = {2009-08-28 21:10:57},
    doi = {10.1109/ICCL.1994.288389},
    keywords = {abstract-interpretation},
    location = {Toulouse, France},
    pages = {95--112},
    priority = {2},
    publisher = {IEEE Computer Society Press},
    title = {Higher-order abstract interpretation (and application to comportment analysis generalizing strictness, termination, projection and {PER} analysis of functional languages)},
    url = {http://www.di.ens.fr/\~{}cousot/COUSOTpapers/ICCL94.shtml},
    year = {1994}
}

@inproceedings{mattmight:Kidd:2009:Random,
    abstract = {This paper describes the methods used in  Empire , a tool to detect concurrency-related bugs, namely atomic-set serializability violations in Java programs. The correctness criterion is based on  atomic sets  of memory locations, which share a consistency property, and  units of work , which preserve consistency when executed sequentially.  Empire  checks that, for each atomic set, its units of work are serializable. This notion subsumes data races (single-location atomic sets), and serializability (all locations in one atomic set).},
    address = {Berlin, Heidelberg},
    author = {Kidd, Nicholas and Reps, Thomas and Dolby, Julian and Vaziri, Mandana},
    booktitle = {VMCAI '09: Proceedings of the 10th International Conference on Verification, Model Checking, and Abstract Interpretation},
    citeulike-article-id = {5663689},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1505383},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-93900-9\_18},
    date-added = {2009-08-28 16:30:37},
    doi = {10.1007/978-3-540-93900-9\_18},
    isbn = {978-3-540-93899-6},
    location = {Savannah, GA},
    pages = {198--213},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Finding {Concurrency-Related} Bugs Using Random Isolation},
    url = {http://dx.doi.org/10.1007/978-3-540-93900-9\_18},
    year = {2009}
}

@inproceedings{mattmight:Dimoulas:2009:Aggregate,
    abstract = {We present a multi-pass interprocedural analysis and transformation for the functional aggregate update problem. Our solution handles untyped programs, including unrestricted closures and nested arrays. Also, it can handle programs that contain a mix of functional and destructive updates. Correctness of all the analyses and of the transformation itself is proved.},
    address = {Berlin, Heidelberg},
    author = {Dimoulas, Christos and Wand, Mitchell},
    booktitle = {VMCAI '09: Proceedings of the 10th International Conference on Verification, Model Checking, and Abstract Interpretation},
    citeulike-article-id = {5663680},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1505373},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-93900-9\_8},
    date-added = {2009-08-28 16:24:27},
    doi = {10.1007/978-3-540-93900-9\_8},
    isbn = {978-3-540-93899-6},
    keywords = {cfa, control-flow-analysis, static-analysis},
    location = {Savannah, GA},
    pages = {44--58},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {The {Higher-Order} Aggregate Update Problem},
    url = {http://dx.doi.org/10.1007/978-3-540-93900-9\_8},
    year = {2009}
}

@phdthesis{mattmight:Sestoft:1991:Dissertation,
    abstract = {machines and implementations : : : : : : : : : : : : : : : : : : : 7
1.4 Optimized implementation : : : : : : : : : : : : : : : : : : : : : : : : : : : 9
1.5 Plan of the report : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 10
2 {Semantics-Based} Program Analysis 12
2.1 Semantics and program analysis : : : : : : : : : : : : : : : : : : : : : : : : 12
2.2 Abstract interpretation : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 12
2.3 Semantic analysis information : : : :...},
    address = {Denmark},
    author = {Sestoft, Peter},
    citeulike-article-id = {1541919},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.8.7762},
    date-added = {2009-08-28 16:22:05},
    keywords = {cfa, control-flow-analysis, static-analysis},
    month = oct,
    priority = {2},
    school = {University of Copenhagen},
    title = {Analysis and efficient implementation of functional programs},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.8.7762},
    year = {1991}
}

@inproceedings{mattmight:Wand:1994:Lightweight,
    abstract = {We consider the problem of selective and lightweight closure conversion, in which multiple procedure-calling protocols may coexist in the same code. Flow analysis is used to match the protocol expected by each procedure and the protocol used at each of its possible call sites. We formulate the flow analysis as the solution of a set of constraints, and show that any solution to the constraints justifies the resulting transformation. Some of the techniques used are suggested by those of abstract interpretation, but others arise out of alternative approaches.},
    address = {New York, NY, USA},
    author = {Wand, Mitchell and Steckler, Paul},
    booktitle = {POPL '94: Proceedings of the 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5663668},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=178044},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/174675.178044},
    date-added = {2009-08-28 16:19:00},
    doi = {10.1145/174675.178044},
    isbn = {0-89791-636-0},
    keywords = {cfa, environment-analysis, static-analysis},
    location = {Portland, Oregon, United States},
    pages = {435--445},
    priority = {2},
    publisher = {ACM},
    title = {Selective and lightweight closure conversion},
    url = {http://dx.doi.org/10.1145/174675.178044},
    year = {1994}
}

@inproceedings{mattmight:Chase:1990:Analysis,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Chase, David R. and Wegman, Mark and Zadeck, F. Kenneth},
    booktitle = {PLDI '90: Proceedings of the ACM SIGPLAN 1990 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {741317},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=93585},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/93542.93585},
    date-added = {2009-08-28 16:11:22},
    doi = {10.1145/93542.93585},
    isbn = {0-89791-364-7},
    keywords = {alias-analysis, pointer-analysis, shape-analysis, static-analysis},
    location = {White Plains, New York, United States},
    pages = {296--310},
    priority = {0},
    publisher = {ACM},
    series = {PLDI '90},
    title = {Analysis of pointers and structures},
    url = {http://dx.doi.org/10.1145/93542.93585},
    year = {1990}
}

@inproceedings{mattmight:DallaPreda:2007:Malware,
    abstract = {Malware detection is a crucial aspect of software security. Current malware detectors work by checking for "signatures," which attempt to capture (syntactic) characteristics of the machine-level byte sequence of the malware. This reliance on a syntactic approach makes such detectors vulnerable to code obfuscations, increasingly used by malware writers, that alter syntactic properties of the malware byte sequence without significantly affecting their execution {behavior.This} paper takes the position that the key to malware identification lies in their semantics. It proposes a semantics-based framework for reasoning about malware detectors and proving properties such as soundness and completeness of these detectors. Our approach uses a trace semantics to characterize the behaviors of malware as well as the program being checked for infection, and uses abstract interpretation to "hide" irrelevant aspects of these behaviors. As a concrete application of our approach, we show that the semantics-aware malware detector proposed by Christodorescu  et al.  is complete with respect to a number of common obfuscations used by malware writers.},
    address = {New York, NY, USA},
    author = {Preda, Mila D. and Christodorescu, Mihai and Jha, Somesh and Debray, Saumya},
    booktitle = {POPL '07: Proceedings of the 34th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {2630382},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1190216.1190270},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1190216.1190270},
    date-added = {2009-08-18 06:09:05},
    doi = {10.1145/1190216.1190270},
    isbn = {1-59593-575-4},
    keywords = {security},
    location = {Nice, France},
    pages = {377--388},
    priority = {5},
    publisher = {ACM},
    title = {A semantics-based approach to malware detection},
    url = {http://dx.doi.org/10.1145/1190216.1190270},
    year = {2007}
}

@article{mattmight:Necula:2005:CCured,
    abstract = {This article describes {CCured}, a program transformation system that adds type safety guarantees to existing C programs. {CCured} attempts to verify statically that memory errors cannot occur, and it inserts run-time checks where static verification is {insufficient.CCured} extends C's type system by separating pointer types according to their usage, and it uses a surprisingly simple type inference algorithm that is able to infer the appropriate pointer kinds for existing C programs. {CCured} uses physical subtyping to recognize and verify a large number of type casts at compile time. Additional type casts are verified using run-time type information. {CCured} uses two instrumentation schemes, one that is optimized for performance and one in which metadata is stored in a separate data structure whose shape mirrors that of the original user data. This latter scheme allows instrumented programs to invoke external functions directly on the program's data without the use of a wrapper {function.We} have used {CCured} on real-world security-critical network daemons to produce instrumented versions without memory-safety vulnerabilities, and we have found several bugs in these programs. The instrumented code is efficient enough to be used in day-to-day operations.},
    address = {New York, NY, USA},
    author = {Necula, George C. and Condit, Jeremy and Harren, Matthew and Mcpeak, Scott and Weimer, Westley},
    citeulike-article-id = {716333},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1065892},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1065887.1065892},
    date-added = {2009-08-18 05:50:16},
    doi = {10.1145/1065887.1065892},
    issn = {0164-0925},
    journal = {ACM Transactions on Programming Languages and Systems},
    keywords = {security},
    month = may,
    number = {3},
    pages = {477--526},
    priority = {2},
    publisher = {ACM},
    title = {{CCured}: Type-safe retrofitting of legacy software},
    url = {http://dx.doi.org/10.1145/1065887.1065892},
    volume = {27},
    year = {2005}
}

@inproceedings{mattmight:Jim:2002:Cyclone,
    abstract = {Cyclone is a safe dialect of C. It has been designedfrom the ground up to prevent the bu\#er overflows,format string attacks, and memory management errorsthat are common in C programs, while {retainingC}'s syntax and semantics. This paper examinessafety violations enabled by C's design, and showshow Cyclone avoids them, without giving up C'shallmark control over low-level details such as datarepresentation and memory management.},
    author = {Jim, Trevor and Morrisett, Greg and Grossman, Dan and Hicks, Michael and Cheney, James and Wang, Yanling},
    booktitle = {USENIX Annual Technical Conference},
    citeulike-article-id = {257826},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.5.4986},
    date-added = {2009-08-18 03:03:29},
    keywords = {security},
    month = jun,
    priority = {2},
    title = {Cyclone: A safe dialect of {C}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.5.4986},
    year = {2002}
}

@electronic{mattmight:UCombinator,
    address = {Salt Lake City, Utah},
    author = {Might, Matthew},
    citeulike-article-id = {5446071},
    citeulike-linkout-0 = {http://www.ucombinator.org/},
    date-added = {2009-08-17 02:04:02},
    howpublished = {http://www.ucombinator.org/},
    institution = {University of Utah},
    keywords = {ucombinator},
    organization = {U Combinator},
    priority = {0},
    title = {A Research Group for Static Analysis of {Higher-Order} Languages},
    url = {http://www.ucombinator.org/}
}

@unpublished{mattmight:Lawson:2008:ChinaCisco,
    author = {Lawson, Stephen and Mcmillan, Robert},
    citeulike-article-id = {5445980},
    citeulike-linkout-0 = {http://www.infoworld.com/d/security-central/fbi-worried-dod-sold-counterfeit-cisco-gear-266},
    date-added = {2009-08-17 01:46:09},
    day = {12},
    howpublished = {http://www.infoworld.com/d/security-central/fbi-worried-dod-sold-counterfeit-cisco-gear-266},
    keywords = {security},
    month = may,
    organization = {InfoWorld},
    priority = {0},
    title = {{FBI} worried as {DoD} sold counterfeit {Cisco} gear: By tampering with networking equipment, spies could open up a back door to sensitive military systems},
    url = {http://www.infoworld.com/d/security-central/fbi-worried-dod-sold-counterfeit-cisco-gear-266},
    year = {2008}
}

@unpublished{mattmight:Behar:2008:Satyam,
    author = {Behar, Richard},
    citeulike-article-id = {5445978},
    citeulike-linkout-0 = {http://www.foxnews.com/story/0,2933,435681,00.html},
    date-added = {2009-08-17 01:42:41},
    day = {10},
    howpublished = {http://www.foxnews.com/story/0,2933,435681,00.html},
    keywords = {security},
    month = oct,
    priority = {0},
    publisher = {FOX News},
    title = {World Bank Under Cyber Siege in `Unprecedented Crisis'},
    url = {http://www.foxnews.com/story/0,2933,435681,00.html},
    year = {2008}
}

@techreport{mattmight:DoD:2007:ForeignInfluence,
    address = {Washington, D.C.},
    author = {Lucky, Robert},
    citeulike-article-id = {5445733},
    date-added = {2009-08-16 21:12:44},
    institution = {Department of Defense},
    keywords = {dod, malware, security},
    priority = {0},
    title = {Mission Impact of Foreign Influence  
on {DoD} Software},
    year = {2007}
}

@inproceedings{mattmight:Derrin:2009:seL4,
    abstract = {Complete formal verification is the only way to guarantee that a system is free of programming errors.

We present ent our experience in performing the formal, machine-checked verification of the {seL4} microkernel from an abstract specification down to its C implementation. We assume correctness of compiler, assembly code, and hardware, and we used a unique design approach that fuses formal and operating systems techniques. To our knowledge, this is the first formal proof of functional correctness of a complete, general-purpose operating-system kernel. Functional correctness means here that the implementation always strictly follows our high-level abstract specification of kernel behaviour. This encompasses traditional design and implementation safety properties such as the kernel will never crash, and it will never perform an unsafe operation. It also proves much more: we can predict precisely how the kernel will behave in every possible situation.

{seL4}, a third-generation microkernel of L4 provenance, comprises 8,700 lines of C code and 600 lines of assembler. Its performance is comparable to other high-performance L4 kernels.},
    address = {Big Sky, Montana},
    author = {Klein, Gerwin and Elphinstone, Kevin and Heiser, Gernot and Andronick, June and Cock, David and Derrin, Philip and Elkaduwe, Dhammika and Engelhardt, Kai and Kolanski, Rafal and Norrish, Michael and Sewell, Thomas and Tuch, Harvey and Winwood, Simon},
    booktitle = {SOSP 2009: Proceedings of the 22nd ACM Symposium on Operating Systems Principles},
    citeulike-article-id = {5445596},
    date-added = {2009-08-16 17:28:37},
    keywords = {verification},
    month = oct,
    organization = {ACM},
    priority = {2},
    title = {{seL4}: Formal verification of an {OS} kernel},
    year = {2009}
}

@article{mattmight:Levenshtein:1966:Correcting,
    abstract = {Not Available},
    author = {Levenshtein, Vladimir I.},
    citeulike-article-id = {1667643},
    citeulike-linkout-0 = {http://adsabs.harvard.edu/cgi-bin/nph-bib\_query?bibcode=1966SPhD...10..707L},
    date-added = {2009-08-16 15:37:30},
    journal = {Soviet Physics Doklady},
    keywords = {error-correcting-codes},
    month = feb,
    number = {8},
    pages = {707--710},
    priority = {2},
    title = {Binary Codes Capable of Correcting Deletions, Insertions and Reversals},
    url = {http://adsabs.harvard.edu/cgi-bin/nph-bib\_query?bibcode=1966SPhD...10..707L},
    volume = {10},
    year = {1966}
}

@inproceedings{mattmight:Rehof:2001:TypeBased,
    abstract = {We present a novel approach to scalable implementation of type-based flow analysis with polymorphic subtyping. Using a new presentation of polymorphic subytping with instantiation constraints, we are able to apply context-free language ({CFL}) reachability techniques to type-based flow analysis. We develop a {CFL}-based algorithm for computing flow-information in time O( n \&sup3;), where  n  is the size of the typed program. The algorithm substantially improves upon the best previously known algorithm for flow analysis based on polymorphic subtyping with complexity O( n 8 ). Our technique also yields the first demand-driven algorithm for polymorphic subtype-based flow-computation. It works directly on higher-order programs with structured data of finite type (unbounded data structures are incorporated via finite approximations), supports context-sensitive, global flow summariztion and includes polymorphic recursion.},
    address = {New York, NY, USA},
    author = {Rehof, Jakob and F\"{a}hndrich, Manuel},
    booktitle = {POPL '01: Proceedings of the 28th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5442196},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=360204.360208},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/360204.360208},
    date-added = {2009-08-15 05:13:36},
    doi = {10.1145/360204.360208},
    isbn = {1-58113-336-7},
    keywords = {cfa, control-flow-analysis, type-based-analysis},
    location = {London, United Kingdom},
    pages = {54--66},
    priority = {2},
    publisher = {ACM},
    title = {Type-based flow analysis: From polymorphic subtyping to {CFL}-reachability},
    url = {http://dx.doi.org/10.1145/360204.360208},
    year = {2001}
}

@article{mattmight:Brzozowski:1964:Derivative,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Brzozowski, Janusz A.},
    citeulike-article-id = {341515},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=321249},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/321239.321249},
    date-added = {2009-08-14 02:33:11},
    doi = {10.1145/321239.321249},
    issn = {0004-5411},
    journal = {Journal of the ACM},
    keywords = {compiler, lexing, regular-expressions},
    month = oct,
    number = {4},
    pages = {481--494},
    priority = {0},
    publisher = {ACM},
    title = {Derivatives of Regular Expressions},
    url = {http://dx.doi.org/10.1145/321239.321249},
    volume = {11},
    year = {1964}
}

@inproceedings{mattmight:Nielson:1997:Infinitary,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has opted to expose the complete List rather than only correct and linked references.},
    address = {New York, NY, USA},
    author = {Nielson, Flemming and Nielson, Hanne R.},
    booktitle = {POPL '97: Proceedings of the 24th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5406388},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=263745},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/263699.263745},
    date-added = {2009-08-10 22:39:26},
    doi = {10.1145/263699.263745},
    isbn = {0-89791-853-3},
    keywords = {cfa, control-flow-analysis, static-analysis},
    location = {Paris, France},
    pages = {332--345},
    priority = {0},
    publisher = {ACM},
    title = {Infinitary control flow analysis: a collecting semantics for closure analysis},
    url = {http://dx.doi.org/10.1145/263699.263745},
    year = {1997}
}

@inproceedings{mattmight:Jagannathan:1995:Unified,
    abstract = {We describe a framework for flow analysis in higher-order languages. It is both a synthesis and extension of earlier work in this area, most notably [20, 22] The framework makes explicit use of  flow graphs  for modeling control and data flow properties of untyped higher-order programs. The framework is parameterized, and can express a hierarchy of analyses with different cost/accuracy tradeoffs. The framework is also amenable to a direct, efficient implementation. We develop several instantiations of the framework, and prove their running-time complexity. In addition, we use the simplest instantiation to demonstrate the equivalence of a {0CFA} style analysis and the set-based analysis of [8].},
    address = {New York, NY, USA},
    author = {Jagannathan, Suresh and Weeks, Stephen},
    booktitle = {POPL '95: Proceedings of the 22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5406327},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=199536},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/199448.199536},
    date-added = {2009-08-10 22:19:52},
    doi = {10.1145/199448.199536},
    isbn = {0-89791-692-1},
    keywords = {cfa, control-flow-analysis, static-analysis},
    location = {San Francisco, California, United States},
    pages = {393--407},
    priority = {0},
    publisher = {ACM},
    title = {A unified treatment of flow analysis in higher-order languages},
    url = {http://dx.doi.org/10.1145/199448.199536},
    year = {1995}
}

@techreport{mattmight:Kelsey:1997:PreScheme,
    abstract = {{Pre-Scheme} is a statically typed dialect of Scheme that gives the programmer the efficiency and low-level machine access of C while retaining many of the desirable features of Scheme. The {Pre-Scheme} compiler makes use of type inference, partial evaluation and Scheme and Lisp compiler technology to compile the problematic features of Scheme, such as closures, into C code without significant run-time overhead. Use of such features in {Pre-Scheme} programs is restricted to those cases that can be compiled into efficient code. Type reconstruction is done using a modified {Hindley/Milner} algorithm that allows overloaded user-defined functions. All top-level forms in {Pre-Scheme} programs are evaluated at compile time, which gives the user additional control over the compiler's partial evaluation of a program. {Pre-Scheme} has been implemented and used to write a byte-code interpreter and associated support code for a complete Scheme implementation.},
    address = {Princeton, NJ},
    author = {Kelsey, Richard A.},
    citeulike-article-id = {5398076},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.3.4031},
    date-added = {2009-08-08 16:45:45},
    institution = {NEC Research Institute},
    keywords = {compiler, scheme},
    priority = {4},
    title = {{Pre-Scheme}: A Scheme Dialect for Systems Programming},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.3.4031},
    year = {1997}
}

@article{mattmight:Moss:2001:Benchmarking,
    abstract = {Every designer of a new data structure wants to know how well it performs in comparison with others. But finding, coding and testing applications as benchmarks can be tedious and time-consuming. Besides, how a benchmark uses a data structure may considerably affect its apparent efficiency, so the choice of applications may bias the results. We address these problems by developing a tool for  inductive benchmarking . This tool,  Auburn , can generate benchmarks across a wide distribution of uses. We precisely define 'the use of a data structure', upon which we build the core algorithms of Auburn: how to generate a benchmark from a description of use, and how to extract a description of use from an application. We then apply inductive classification techniques to obtain decision trees for the choice between competing data structures. We test Auburn by benchmarking several implementations of three common data structures: queues, random-access lists and heaps. These and other results show Auburn to be a useful and accurate tool, but they also reveal some limitations of the approach.},
    address = {New York, NY, USA},
    author = {Moss, Graeme E. and Runciman, Colin},
    citeulike-article-id = {5382955},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=968439},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/S0956796801004063},
    date-added = {2009-08-06 16:29:25},
    doi = {10.1017/S0956796801004063},
    issn = {0956-7968},
    journal = {Journal of Functional Programming},
    keywords = {benchmarking, functional-programming},
    number = {5},
    pages = {525--556},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Inductive benchmarking for purely functional data structures},
    url = {http://dx.doi.org/10.1017/S0956796801004063},
    volume = {11},
    year = {2001}
}

@inproceedings{mattmight:Sridharan:2006:Refinement,
    address = {New York, NY, USA},
    author = {Sridharan, Manu and Bodik, Rastislav},
    booktitle = {PLDI '06: Proceedings of the 2006 ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {1865431},
    citeulike-linkout-0 = {http://dx.doi.org/10.1145/1133981.1134027},
    date-added = {2009-08-03 22:04:12},
    doi = {10.1145/1133981.1134027},
    issn = {0362-1340},
    keywords = {alias-analysis, pointer-analysis},
    pages = {387--400},
    priority = {0},
    publisher = {ACM},
    title = {Refinement-based context-sensitive points-to analysis for Java},
    url = {http://dx.doi.org/10.1145/1133981.1134027},
    year = {2006}
}

@phdthesis{mattmight:Feeley:1993:Future,
    author = {Feeley, Marc},
    citeulike-article-id = {5292261},
    date-added = {2009-07-28 16:38:32},
    keywords = {lambda-calculus, parallelization},
    month = apr,
    priority = {0},
    school = {Brandeis University},
    title = {An Efficient and General Implementation of Futures on Large Scale {Shared-Memory} Multiprocessors},
    year = {1993}
}

@inproceedings{mattmight:Flanagan:1995:Future,
    abstract = {The  future  annotations of {MultiLisp} provide a simple method for taming the implicit parallelism of functional programs. Past research concerning  future s has focused on implementation issues. In this paper, we present a series of operational semantics for an idealized functional language with  future s with varying degrees of intensionality. We develop a set-based analysis algorithm from the most intensional semantics, and use that algorithm to perform  touch  optimization on programs. Experiments with the Gambit compiler indicates that this optimization substantially reduces program execution times.},
    address = {New York, NY, USA},
    author = {Flanagan, Cormac and Felleisen, Matthias},
    booktitle = {POPL '95: Proceedings of the 22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {4158},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=199484},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/199448.199484},
    date-added = {2009-07-28 16:31:26},
    doi = {10.1145/199448.199484},
    isbn = {0-89791-692-1},
    keywords = {parallelization},
    location = {San Francisco, California, United States},
    pages = {209--220},
    priority = {2},
    publisher = {ACM},
    title = {The semantics of future and its use in program optimization},
    url = {http://dx.doi.org/10.1145/199448.199484},
    year = {1995}
}

@article{mattmight:Igarashi:2001:Java,
    abstract = {Several recent studies have introduced lightweight versions of Java: reduced languages in which complex features like threads and reflection are dropped to enable rigorous arguments about key properties such as type safety. We carry this process a step further, omitting almost all features of the full language (including interfaces and even assignment) to obtain a small calculus, Featherweight Java, for which rigorous proofs are not only possible but easy. Featherweight Java bears a similar relation to Java as the lambda-calculus does to languages such as {ML} and Haskell. It offers a similar computational "feel," providing classes, methods, fields, inheritance, and dynamic typecasts with a semantics closely following Java's. A proof of type safety for Featherweight Java thus illustrates many of the interesting features of a safety proof for the full language, while remaining pleasingly compact. The minimal syntax, typing rules, and operational semantics of Featherweight Java make it a handy tool for studying the consequences of extensions and variations. As an illustration of its utility in this regard, we extend Featherweight Java with  generic classes  in the style of {GJ} (Bracha, Odersky, Stoutamire, and Wadler) and give a detailed proof of type safety. The extended system formalizes for the first time some of the key features of {GJ}.},
    address = {New York, NY, USA},
    author = {Igarashi, Atsushi and Pierce, Benjamin C. and Wadler, Philip},
    citeulike-article-id = {3425305},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=503505},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/503502.503505},
    date-added = {2009-07-21 06:31:41},
    doi = {10.1145/503502.503505},
    issn = {0164-0925},
    journal = {ACM Transactions on Programming Languages and Systems},
    keywords = {java},
    number = {3},
    pages = {396--450},
    priority = {2},
    publisher = {ACM},
    title = {Featherweight Java: A minimal core calculus for Java and {GJ}},
    url = {http://dx.doi.org/10.1145/503502.503505},
    volume = {23},
    year = {2001}
}

@inproceedings{mattmight:Blanchet:2003:ASTREE,
    abstract = {We show that abstract interpretation-based static program analysis can be made efficient and precise enough to formally verify a class of properties for a family of large programs with few or no false alarms. This is achieved by refinement of a general purpose static analyzer and later adaptation to particular programs of the family by the end-user through parametrization. This is applied to the proof of soundness of data manipulation operations at the machine level for periodic synchronous safety critical embedded {software.The} main novelties are the design principle of static analyzers by refinement and adaptation through parametrization (Sect. 3 and 7), the symbolic manipulation of expressions to improve the precision of abstract transfer functions (Sect. 6.3), the octagon (Sect. 6.2.2), ellipsoid (Sect. 6.2.3), and decision tree (Sect. 6.2.4) abstract domains, all with sound handling of rounding errors in oating point computations, widening strategies (with thresholds: Sect. 7.1.2, delayed: Sect. 7.1.3) and the automatic determination of the parameters (parametrized packing: Sect. 7.2).},
    address = {New York, NY, USA},
    author = {Blanchet, Bruno and Cousot, Patrick and Cousot, Radhia and Feret, J\'{e}rome and Mauborgne, Laurent and Min\'{e}, Antoine and Monniaux, David and Rival, Xavier},
    booktitle = {PLDI '03: Proceedings of the ACM SIGPLAN 2003 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {2353363},
    citeulike-linkout-0 = {http://citeseer.ist.psu.edu/561514.html},
    citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=781153},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/781131.781153},
    date-added = {2009-07-17 04:15:58},
    doi = {10.1145/781131.781153},
    isbn = {1-58113-662-5},
    keywords = {abstract-interpretation, static-analysis},
    location = {San Diego, California, USA},
    pages = {196--207},
    priority = {2},
    publisher = {ACM},
    series = {PLDI '03},
    title = {A static analyzer for large safety-critical software},
    url = {http://citeseer.ist.psu.edu/561514.html},
    year = {2003}
}

@article{mattmight:Holzmann:1997:SPIN,
    abstract = {{Abstract—SPIN} is an efficient verification system for models of distributed software systems. It has been used to detect design errors in applications ranging from high-level descriptions of distributed algorithms to detailed code for controlling telephone exchanges. This paper gives an overview of the design and structure of the verifier, reviews its theoretical foundation, and gives an overview of significant practical applications. Index {Terms—Formal} methods, program verification, design verification, model checking, distributed systems, concurrency.},
    author = {Holzmann, Gerard J.},
    citeulike-article-id = {3276363},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.8056},
    date-added = {2009-07-17 04:10:21},
    journal = {IEEE Transactions on Software Engineering},
    keywords = {model-checking, static-analysis},
    pages = {279--295},
    priority = {2},
    title = {The model checker {SPIN}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.8056},
    volume = {23},
    year = {1997}
}

@inproceedings{mattmight:Ball:2001:PredicateAbstraction,
    abstract = {Model checking has been widely successful in validating and debugging designs in the hardware and protocol domains. However, state-space explosion limits the applicability of model checking tools, so model checkers typically operate on abstractions of systems.},
    address = {New York, NY, USA},
    author = {Ball, Thomas and Majumdar, Rupak and Millstein, Todd and Rajamani, Sriram K.},
    booktitle = {PLDI '01: Proceedings of the ACM SIGPLAN 2001 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {1376607},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=378795.378846},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/378795.378846},
    date-added = {2009-07-17 03:59:59},
    doi = {10.1145/378795.378846},
    isbn = {1-58113-414-2},
    issn = {0362-1340},
    keywords = {abstract-interpretation, predicate-abstraction, static-analysis},
    location = {Snowbird, Utah, United States},
    pages = {203--213},
    priority = {2},
    publisher = {ACM},
    title = {Automatic predicate abstraction of C programs},
    url = {http://dx.doi.org/10.1145/378795.378846},
    year = {2001}
}

@incollection{mattmight:Clarke:2008:ModelChecking,
    abstract = { ” When the time is ripe for certain things, these things appear in different places in the manner of violets coming to light in early spring.” (Wolfgang Bolyai to his son Johann in urging him to claim the invention of non- Euclidean geometry without delay [Vit88]).},
    author = {Clarke, Edmund},
    booktitle = {25 Years of Model Checking},
    citeulike-article-id = {3372907},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1423536},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-69850-0\_1},
    citeulike-linkout-2 = {http://www.springerlink.com/content/j335v4472745r366},
    date-added = {2009-07-17 03:51:28},
    doi = {10.1007/978-3-540-69850-0\_1},
    journal = {25 Years of Model Checking},
    keywords = {model-checking, static-analysis},
    pages = {1--26},
    priority = {2},
    title = {The Birth of Model Checking},
    url = {http://dx.doi.org/10.1007/978-3-540-69850-0\_1},
    year = {2008}
}

@article{mattmight:Kam:1977:Monotone,
    abstract = {We consider a generalization of Kildall's lattice theoretic approach to data flow analysis, which we call monotone data flow analysis frameworks. Many flow analysis problems which appear in practice meet the monotonicity condition but not Kildall's condition called distributivity. We show that the maximal fixed point solution exists for every instance of every monotone framework, and that it can be obtained by Kildall's algorithm. However, whenever the framework is monotone but not distributive, there are instances in which the desired solution—the  meet over all paths solution  — differs from the maximal fixed point. Finally, we show the nonexistence of an algorithm to compute the meet over all paths solution for monotone frameworks.},
    author = {Kam, John B. and Ullman, Jeffrey D.},
    citeulike-article-id = {4066051},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/BF00290339},
    citeulike-linkout-1 = {http://www.springerlink.com/content/k4160428k4200pm7},
    date-added = {2009-07-17 03:45:53},
    day = {1},
    doi = {10.1007/BF00290339},
    issn = {0001-5903},
    journal = {Acta Informatica},
    keywords = {data-flow-analysis, static-analysis},
    month = sep,
    number = {3},
    pages = {305--317},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {Monotone data flow analysis frameworks},
    url = {http://dx.doi.org/10.1007/BF00290339},
    volume = {7},
    year = {1977}
}

@inproceedings{mattmight:Kildall:1973:DFA,
    abstract = {A technique is presented for global analysis of program structure in order to perform compile time optimization of object code generated for expressions. The global expression optimization presented includes constant propagation, common subexpression elimination, elimination of redundant register load operations, and live expression analysis. A general purpose program flow analysis algorithm is developed which depends upon the existence of an "optimizing function." The algorithm is defined formally using a directed graph model of program flow structure, and is shown to be correct. Several optimizing functions are defined which, when used in conjunction with the flow analysis algorithm, provide the various forms of code optimization. The flow analysis algorithm is sufficiently general that additional functions can easily be defined for other forms of global code optimization.},
    address = {New York, NY, USA},
    author = {Kildall, Gary A.},
    booktitle = {POPL '73: Proceedings of the 1st Annual ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
    citeulike-article-id = {1127705},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=512945},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/512927.512945},
    date-added = {2009-07-17 03:44:45},
    doi = {10.1145/512927.512945},
    keywords = {data-flow-analysis, static-analysis},
    location = {Boston, Massachusetts},
    pages = {194--206},
    priority = {0},
    publisher = {ACM},
    series = {POPL '73},
    title = {A unified approach to global program optimization},
    url = {http://dx.doi.org/10.1145/512927.512945},
    year = {1973}
}

@inproceedings{mattmight:Hudak:1985:Sharing,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has opted to expose the complete List rather than only correct and linked references.},
    address = {New York, NY, USA},
    author = {Hudak, Paul},
    booktitle = {LFP '86: Proceedings of the 1986 ACM Conference on LISP and Functional Programming},
    citeulike-article-id = {350023},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=319838.319876},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/319838.319876},
    date-added = {2009-07-16 22:21:01},
    doi = {10.1145/319838.319876},
    isbn = {0-89791-200-4},
    keywords = {abstract-counting, abstract-interpretation, static-analysis},
    location = {Cambridge, Massachusetts, United States},
    pages = {351--363},
    priority = {0},
    publisher = {ACM},
    title = {A semantic model of reference counting and its abstraction},
    url = {http://dx.doi.org/10.1145/319838.319876},
    year = {1986}
}

@book{mattmight:Seacord:2008:CERT-C,
    abstract = {{\_ ” I}'m an enthusiastic supporter of the {CERT} Secure Coding Initiative.
Programmers have lots of sources of advice on correctness, clarity,
maintainability, performance, and even safety. Advice on how specific language
features affect security has been missing. {\_The} {CERT}® C Secure

Coding Standard\_ fills this need.”

{\_—Randy} Meyers, Chairman of {ANSI} C\_



 ” For years we have relied upon the {CERT}/{CC} to publish advisories documenting
an endless stream of security problems. Now {CERT} has embodied the advice of
leading technical experts to give programmers and managers the practical
guidance needed to avoid those problems in new  applications and to help
secure legacy systems. Well done!”\_

—Dr. Thomas Plum, founder of Plum Hall, Inc.


{\_ ” Connectivity} has sharply increased the need for secure, hacker-safe
applications. By combining this {CERT} standard with other safety guidelines,
customers gain all-round protection and approach the goal of zero-defect
software.”\_

—Chris Tapp, Field Applications Engineer, {LDRA} Ltd.


{\_ ” I}'ve found this standard to be an indispensable collection of expert
information on exactly how modern software systems fail in practice. It is the
perfect place to start for establishing internal secure coding guidelines. You
won't find this information elsewhere, and, when it comes to software
security, what you don't know is often exactly what hurts you.”\_

—John {McDonald}, coauthor of {\_The} Art of Software Security Assessment\_



Software security has major implications for the operations and assets of
organizations, as well as for the welfare of individuals. To create secure
software, developers must know where the dangers lie. Secure programming in C
can be more difficult than even many experienced  programmers believe.


This book is an essential desktop reference documenting the first official
release of  **{\_The} {CERT}® C Secure Coding Standard\_**. The standard itemizes
those coding errors that are the root causes of software vulnerabilities in C
and prioritizes them by severity, likelihood of exploitation, and remediation
costs. Each guideline provides examples of insecure code as well as secure,
alternative implementations. If uniformly applied, these guidelines will
eliminate the critical coding errors that lead to buffer overflows, format
string vulnerabilities, integer  overflow, and other common software
vulnerabilities.},
    author = {Seacord, Robert C.},
    citeulike-article-id = {5161149},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0321563212},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0321563212},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0321563212},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0321563212},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0321563212/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0321563212},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0321563212},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0321563212},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0321563212\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0321563212},
    date-added = {2009-07-15 19:36:00},
    day = {24},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0321563212},
    keywords = {security},
    month = oct,
    priority = {4},
    publisher = {Addison-Wesley Professional},
    title = {The {CERT} C Secure Coding Standard ({SEI} Series in Software Engineering)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0321563212},
    year = {2008}
}

@article{mattmight:Boyer:1975:BoyerMoore,
    address = {New York, NY, USA},
    author = {Boyer, Robert S. and Moore, J. Strother},
    citeulike-article-id = {2081202},
    citeulike-linkout-0 = {http://dx.doi.org/10.1145/321864.321875},
    date-added = {2009-07-15 18:04:49},
    doi = {10.1145/321864.321875},
    issn = {0004-5411},
    journal = {Journal of the ACM},
    keywords = {theorem-proving, verification},
    month = jan,
    number = {1},
    pages = {129--144},
    priority = {2},
    publisher = {ACM},
    title = {Proving Theorems about {LISP} Functions},
    url = {http://dx.doi.org/10.1145/321864.321875},
    volume = {22},
    year = {1975}
}

@proceedings{mattmight:Gordon:1991:HOL,
    author = {Gordon, Mike},
    booktitle = {HOL Theorem Proving System and Its Applications, 1991., International Workshop on the},
    citeulike-article-id = {2478943},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=596265},
    date-added = {2009-07-15 18:01:50},
    journal = {HOL Theorem Proving System and Its Applications, 1991., International Workshop on the},
    keywords = {theorem-proving, verification},
    pages = {2--3},
    priority = {2},
    title = {Introduction To The Hol System},
    url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=596265},
    year = {1991}
}

@unpublished{mattmight:Yves:2008:Coq,
    abstract = {These notes provide a quick introduction to the Coq system and show how itcan be used to define logical concepts and functions and reason about them. Itis designed as a tutorial, so that readers can quickly start their ownexperiments, learning only a few of the capabilities of the system. A much morecomprehensive study is provided in [1], which also provides an extensivecollection of exercises to train on.},
    archivePrefix = {arXiv},
    author = {Bertot, Yves},
    citeulike-article-id = {3501167},
    citeulike-linkout-0 = {http://arxiv.org/abs/cs/0603118},
    citeulike-linkout-1 = {http://arxiv.org/pdf/cs/0603118},
    date-added = {2009-07-15 18:00:06},
    day = {7},
    eprint = {cs/0603118},
    keywords = {coq, theorem-proving},
    month = nov,
    priority = {2},
    title = {Coq in a Hurry},
    url = {http://arxiv.org/abs/cs/0603118},
    year = {2008}
}

@inproceedings{mattmight:Abraham:2009:Culture,
    abstract = {The effect of cultural differences is often overlooked or neglected when analysing attractive, cost-effective options for software development. This papers aims to highlight people issues that arise out of cultural differences between interacting software development teams, particularly between Indians and {non-Indians}. The author's intent is to merely bring out the differences and not to provide solutions or recommendations or to identify root causes for the behavior. This is an experience paper, mostly based on observations and sharing of personal experiences from various colleagues and coworkers.},
    address = {New York, NY, USA},
    author = {Abraham, Lavanya R.},
    booktitle = {ISEC '09: Proceeding of the 2nd annual conference on India software engineering conference},
    citeulike-article-id = {5160153},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1506234},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1506216.1506234},
    date-added = {2009-07-15 17:28:15},
    doi = {10.1145/1506216.1506234},
    isbn = {978-1-60558-426-3},
    keywords = {software-engineering},
    location = {Pune, India},
    pages = {95--100},
    priority = {2},
    publisher = {ACM},
    title = {Cultural differences in software engineering},
    url = {http://dx.doi.org/10.1145/1506216.1506234},
    year = {2009}
}

@article{mattmight:Church:1936:LambdaCalculus,
    author = {Church, Alonzo},
    citeulike-article-id = {126966},
    citeulike-linkout-0 = {http://www.jstor.org/stable/2269326},
    date-added = {2009-07-15 05:37:05},
    journal = {Journal of Symbolic Logic},
    keywords = {lambda-calculus},
    number = {1},
    pages = {40--41},
    priority = {2},
    title = {A Note on the Entscheidungsproblem},
    url = {http://www.jstor.org/stable/2269326},
    volume = {1},
    year = {1936}
}

@inproceedings{mattmight:Siek:2006:Gradual,
    abstract = {Static and dynamic type systems have well-known strengths and weaknesses, and each is better suited for different programming tasks. There have been many efforts to integrate static and dynamic typing and thereby combine the benefits of both typing disciplines in the same language. The flexibility of static typing can be improved by adding a type Dynamic and a typecase form. The safety and performance of dynamic typing can be improved by adding optional type annotations or by performing type...},
    author = {Siek, Jeremy G. and Taha, Walid},
    booktitle = {Scheme and Functional Programming Workshop},
    citeulike-article-id = {2841470},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.8890},
    date-added = {2009-07-15 05:33:35},
    keywords = {type-theory},
    month = sep,
    priority = {2},
    title = {Gradual typing for functional languages},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.8890},
    year = {2006}
}

@inproceedings{mattmight:Xi:1998:Dependent,
    abstract = {We present a type-based approach to eliminating array bound checking and list tag checking by conservatively extending Standard {ML} with a restricted form of dependent types. This enables the programmer to capture more invariants through types while type-checking remains decidable in theory and can still be performed efficiently in practice. We illustrate our approach through concrete examples and present the result of our preliminary experiments which support support the feasibility and effectiveness of our approach.},
    address = {New York, NY, USA},
    author = {Xi, Hongwei and Pfenning, Frank},
    booktitle = {PLDI '98: Proceedings of the ACM SIGPLAN 1998 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {1262431},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=277650.277732},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/277650.277732},
    date-added = {2009-07-15 05:28:36},
    doi = {10.1145/277650.277732},
    isbn = {0-89791-987-4},
    issn = {0362-1340},
    keywords = {dependent-types, type-theory},
    location = {Montreal, Quebec, Canada},
    pages = {249--257},
    priority = {2},
    publisher = {ACM},
    title = {Eliminating array bound checking through dependent types},
    url = {http://dx.doi.org/10.1145/277650.277732},
    year = {1998}
}

@inproceedings{mattmight:Kobayashi:2009:HORS,
    abstract = {We propose a new verification method for temporal properties of higher-order functional programs, which takes advantage of Ong's recent result on the decidability of the model-checking problem for higher-order recursion schemes ({HORS}'s). A program is transformed to an {HORS} that generates a tree representing all the possible event sequences of the program, and then the {HORS} is model-checked. Unlike most of the previous methods for verification of higher-order programs, our verification method is sound and complete. Moreover, this new verification framework allows a smooth integration of abstract model checking techniques into verification of higher-order programs. We also present a type-based verification algorithm for {HORS}'s. The algorithm can deal with only a fragment of the properties expressed by modal mu-calculus, but the algorithm and its correctness proof are (arguably) much simpler than those of Ong's game-semantics-based algorithm. Moreover, while the {HORS} model checking problem is {n-EXPTIME} in general, our algorithm is linear in the size of {HORS}, under the assumption that the sizes of types and specification formulas are bounded by a constant.},
    address = {New York, NY, USA},
    author = {Kobayashi, Naoki},
    booktitle = {POPL '09: Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5154855},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1480881.1480933},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1480881.1480933},
    date-added = {2009-07-15 05:17:36},
    doi = {10.1145/1480881.1480933},
    isbn = {978-1-60558-379-2},
    keywords = {static-analysis, verification},
    location = {Savannah, GA, USA},
    pages = {416--428},
    priority = {0},
    publisher = {ACM},
    title = {Types and higher-order recursion schemes for verification of higher-order programs},
    url = {http://dx.doi.org/10.1145/1480881.1480933},
    year = {2009}
}

@electronic{mattmight:GCC,
    address = {http://gcc.gnu.org/},
    citeulike-article-id = {5154844},
    date-added = {2009-07-15 05:15:50},
    organization = {Free Software Foundation},
    priority = {2},
    title = {{GNU} C Compiler}
}

@inproceedings{mattmight:Lattner:2003:LLVM,
    abstract = {This paper presents a design and implementation of a whole-program interprocedural optimizer built in the {GCC} framework. Through the introduction of a new language-independent intermediate representation, we extend the current {GCC} architecture to include a powerful mid-level optimizer and add link-time interprocedural analysis and optimization capabilities. This intermediate representation is an {SSA}-based, low-level, strongly-typed, representation which is designed to support both efficient...},
    address = {Ottawa, Canada},
    author = {Lattner, Chris and Adve, Vikram},
    booktitle = {Proceedings of the First Annual GCC Developers' Summit},
    citeulike-article-id = {481259},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.13.9621},
    date-added = {2009-07-15 05:12:23},
    keywords = {compiler, llvm, ssa},
    month = may,
    priority = {2},
    title = {Architecture for a {Next-Generation} {GCC}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.13.9621},
    year = {2003}
}

@inproceedings{mattmight:Balakrishnan:2006:Recency,
    abstract = {In this paper, we present an abstraction for heap-allocated storage, called the recency-abstraction, that allows abstract-interpretation algorithms to recover some non-trivial information for heap-allocated data objects. As an application of the recency-abstraction, we show how it can resolve virtual-function calls in stripped executables (i.e., executables from which debugging information has been removed). This approach succeeded in resolving 55\% of virtual-function call-sites, whereas previous tools for analyzing executables fail to resolve any of the virtual-function call-sites.},
    address = {Berlin, Heidelberg},
    author = {Balakrishnan, Gogul and Reps, Thomas},
    booktitle = {SAS '06: Static Analysis Symposium},
    chapter = {15},
    citeulike-article-id = {5154774},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11823230\_15},
    citeulike-linkout-1 = {http://www.springerlink.com/content/g857n7xn2751624q},
    date-added = {2009-07-15 05:06:29},
    doi = {10.1007/11823230\_15},
    editor = {Yi, Kwangkeun},
    isbn = {978-3-540-37756-6},
    journal = {Static Analysis},
    keywords = {shape-analysis, static-analysis},
    pages = {221--239},
    priority = {0},
    publisher = {Springer-Verlag},
    series = {Lecture Notes in Computer Science},
    title = {{Recency-Abstraction} for {Heap-Allocated} Storage},
    url = {http://dx.doi.org/10.1007/11823230\_15},
    volume = {4134},
    year = {2006}
}

@inproceedings{mattmight:Chang:2008:Relational,
    abstract = {Shape analyses are concerned with precise abstractions of the heap to capture detailed structural properties. To do so, they need to build and decompose summaries of disjoint memory regions. Unfortunately, many data structure invariants require relations be tracked across disjoint regions, such as intricate numerical data invariants or structural invariants concerning back and cross pointers. In this paper, we identify issues inherent to analyzing relational structures and design an abstract domain that is parameterized both by an abstract domain for pure data properties and by user-supplied specifications of the data structure invariants to check. Particularly, it supports hybrid invariants about shape and data and features a generic mechanism for materializing summaries at the beginning, middle, or end of inductive structures. Around this domain, we build a shape analysis whose interesting components include a pre-analysis on the user-supplied specifications that guides the abstract interpretation and a widening operator over the combined shape and data domain. We then demonstrate our techniques on the proof of preservation of the red-black tree invariants during insertion.},
    address = {New York, NY, USA},
    author = {Chang, Bor-Yuh E. and Rival, Xavier},
    booktitle = {POPL '08: Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5154749},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1328469},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1328438.1328469},
    date-added = {2009-07-15 05:03:40},
    doi = {10.1145/1328438.1328469},
    isbn = {978-1-59593-689-9},
    keywords = {shape-analysis, static-analysis},
    location = {San Francisco, California, USA},
    pages = {247--260},
    priority = {2},
    publisher = {ACM},
    title = {Relational inductive shape analysis},
    url = {http://dx.doi.org/10.1145/1328438.1328469},
    year = {2008}
}

@inproceedings{mattmight:Cherem:2007:Shape,
    abstract = {This paper presents a novel shape analysis algorithm with local reasoning that is designed to analyze heap structures with structural invariants, such as doubly-linked lists. The algorithm abstracts and analyzes one single heap cell at a time. In order to maintain the structural invariants, the analysis uses a local heap abstraction that models the sub-heap consisting of one cell and its immediate neighbors. The proposed algorithm can successfully analyze standard doubly-linked list manipulations.},
    address = {Nice, France},
    author = {Cherem, Sigmund and Rugina, Radu},
    booktitle = {In VMCAI '07: Verification, Model Checking, and Abstract Interpretation},
    citeulike-article-id = {5153481},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-69738-1\_17},
    citeulike-linkout-1 = {http://www.springerlink.com/content/a285820353w614w3},
    date-added = {2009-07-15 02:07:53},
    doi = {10.1007/978-3-540-69738-1\_17},
    journal = {Verification, Model Checking, and Abstract Interpretation},
    keywords = {shape-analysis, static-analysis},
    pages = {234--250},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Maintaining {Doubly-Linked} List Invariants in Shape Analysis with Local Reasoning},
    url = {http://dx.doi.org/10.1007/978-3-540-69738-1\_17},
    year = {2007}
}

@article{mattmight:Sagiv:2002:TVLA,
    abstract = {Shape analysis concerns the problem of determining "shape invariants" for programs that perform destructive updating on dynamically allocated storage. This article presents a parametric framework for shape analysis that can be instantiated in different ways to create different shape-analysis algorithms that provide varying degrees of efficiency and precision. A key innovation of the work is that the stores that can possibly arise during execution are represented (conservatively) using 3-valued logical structures. The framework is instantiated in different ways by varying the predicates used in the 3-valued logic. The class of programs to which a given instantiation of the framework can be applied is not limited a priori (i.e., as in some work on shape analysis, to programs that manipulate only lists, trees, {DAGS}, etc.); each instantiation of the framework can be applied to any program, but may produce imprecise results (albeit conservative ones) due to the set of predicates employed.},
    address = {New York, NY, USA},
    author = {Sagiv, Mooly and Reps, Thomas and Wilhelm, Reinhard},
    citeulike-article-id = {1411970},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=514190},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/514188.514190},
    date-added = {2009-07-15 02:05:16},
    doi = {10.1145/514188.514190},
    issn = {0164-0925},
    journal = {ACM Transactions on Programming Languages and Systems},
    keywords = {shape-analysis, static-analysis, tvla},
    month = may,
    number = {3},
    pages = {217--298},
    priority = {2},
    publisher = {ACM},
    title = {Parametric shape analysis via 3-valued logic},
    url = {http://dx.doi.org/10.1145/514188.514190},
    volume = {24},
    year = {2002}
}

@inproceedings{mattmight:Cousot:2007:ASTREE,
    abstract = {We explain the design of the interpretation-based static analyzer {ASTR\'{E}E} and its use to prove the absence of run-time errors in safety-critical codes.},
    address = {New York, NY, USA},
    author = {Cousot, Patrick},
    booktitle = {EMSOFT '07: Proceedings of the 7th ACM and IEEE International Conference on Embedded Software},
    citeulike-article-id = {5153445},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1289932},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1289927.1289932},
    date-added = {2009-07-15 02:01:58},
    doi = {10.1145/1289927.1289932},
    isbn = {978-1-59593-825-1},
    keywords = {abstract-interpretation, static-analysis},
    location = {Salzburg, Austria},
    pages = {7--9},
    priority = {2},
    publisher = {ACM},
    title = {Proving the absence of run-time errors in safety-critical avionics code},
    url = {http://dx.doi.org/10.1145/1289927.1289932},
    year = {2007}
}

@article{mattmight:Reps:1998:CFL,
    abstract = {This paper describes how a number of program-analysis problems can be solved by transforming them to graph-reachability problems. Some of the program-analysis problems that are amenable to this treatment include program slicing, certain dataflow-analysis problems, one version of the problem of approximating the possible "shapes" that heap-allocated structures in a program can take on, and flow-insensitive points-to analysis. Relationships between graph reachability and other approaches to program analysis are described. Some techniques that go beyond pure graph reachability are also discussed.},
    author = {Reps, Thomas},
    citeulike-article-id = {1864450},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0950-5849(98)00093-7},
    citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/B6V0B-3W1PXRV-C/2/c2a7f356bd45876f8d74fcd259f1ee8e},
    date-added = {2009-07-15 01:58:21},
    day = {1},
    doi = {10.1016/S0950-5849(98)00093-7},
    journal = {Information and Software Technology},
    keywords = {cfl, static-analysis},
    month = dec,
    number = {11-12},
    pages = {701--726},
    priority = {2},
    title = {Program analysis via graph reachability},
    url = {http://dx.doi.org/10.1016/S0950-5849(98)00093-7},
    volume = {40},
    year = {1998}
}

@article{mattmight:Cook:2006:Termination,
    abstract = {Program termination is central to the process of ensuring that systems code can always react. We describe a new program termination prover that performs a path-sensitive and context-sensitive program analysis and provides capacity for large program fragments (i.e. more than 20,000 lines of code) together with support for programming language features such as arbitrarily nested loops, pointers, function-pointers, side-effects, {etc.We} also present experimental results on device driver dispatch routines from {theWindows} operating system. The most distinguishing aspect of our tool is how it shifts the balance between the two tasks of constructing and respectively checking the termination argument. Checking becomes the hard step. In this paper we show how we solve the corresponding challenge of checking with binary reachability analysis.},
    address = {New York, NY, USA},
    author = {Cook, Byron and Podelski, Andreas and Rybalchenko, Andrey},
    booktitle = {PLDI '06: Proceedings of the 2006 ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {3042545},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1134029},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1133981.1134029},
    date-added = {2009-07-15 01:54:14},
    doi = {10.1145/1133981.1134029},
    isbn = {1-59593-320-4},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {static-analysis, termination},
    location = {Ottawa, Ontario, Canada},
    month = jun,
    pages = {415--426},
    priority = {2},
    publisher = {ACM},
    title = {Termination proofs for systems code},
    url = {http://dx.doi.org/10.1145/1133981.1134029},
    volume = {41},
    year = {2006}
}

@inproceedings{mattmight:Yong:1999:Pointer,
    abstract = {Type casting allows a program to access an object as if it had a type different from its declared type. This complicates the design of a pointer-analysis algorithm that treats structure fields as separate objects; therefore, some previous pointer-analysis algorithms "collapse" a structure into a single variable. The disadvantage of this approach is that it can lead to very imprecise points-to information. Other algorithms treat each field as a separate object based on its offset and size. While this approach leads to more precise results, the results are not portable because the memory layout of structures is implementation {dependent.This} paper first describes the complications introduced by type casting, then presents a tunable pointer-analysis framework for handling structures in the presence of casting. Different instances of this framework produce algorithms with different levels of precision, portability, and efficiency. Experimental results from running our implementations of four instances of this framework show that (i) it is important to distinguish fields of structures in pointer analysis, but (ii) making conservative approximations when casting is involved usually does not cost much in terms of time, space, or the precision of the results.},
    address = {New York, NY, USA},
    author = {Yong, Suan H. and Horwitz, Susan and Reps, Thomas},
    booktitle = {PLDI '99: Proceedings of the ACM SIGPLAN 1999 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {2681070},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=301618.301647},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/301618.301647},
    date-added = {2009-07-15 00:17:10},
    doi = {10.1145/301618.301647},
    isbn = {1-58113-094-5},
    keywords = {alias-analysis, static-analysis},
    location = {Atlanta, Georgia, United States},
    pages = {91--103},
    priority = {2},
    publisher = {ACM},
    title = {Pointer analysis for programs with structures and casting},
    url = {http://dx.doi.org/10.1145/301618.301647},
    year = {1999}
}

@inproceedings{mattmight:Mine:2006:FieldSensitive,
    abstract = {We propose a memory abstraction able to lift existing numerical static analyses to C programs containing union types, pointer casts, and arbitrary pointer arithmetics. Our framework is that of a combined points-to and data-value analysis. We abstract the contents of compound variables in a field-sensitive way, whether these fields contain numeric or pointer values, and use stock numerical abstract domains to find an overapproximation of all possible memory states---with the ability to discover relationships between variables. A main novelty of our approach is the dynamic mapping scheme we use to associate a flat collection of abstract cells of scalar type to the set of accessed memory locations, while taking care of byte-level aliases--- i.e.,  C variables with incompatible types allocated in overlapping memory locations. We do not rely on static type information which can be misleading in C programs as it does not account for all the uses a memory zone may be put {to.Our} work was incorporated within the A str\'{e}e  static analyzer that checks for the absence of run-time-errors in embedded, safety-critical, numerical-intensive software. It replaces the former memory domain limited to well-typed, union-free, pointer-cast free data-structures. Early results demonstrate that this abstraction allows analyzing a larger class of C programs, without much cost overhead.},
    address = {New York, NY, USA},
    author = {Min\'{e}, Antoine},
    booktitle = {LCTES '06: Proceedings of the 2006 ACM SIGPLAN/SIGBED conference on Language, Compilers, and Tool Support for Embedded Systems},
    citeulike-article-id = {5152312},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1134650.1134659},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1134650.1134659},
    date-added = {2009-07-15 00:12:13},
    doi = {10.1145/1134650.1134659},
    isbn = {1-59593-362-X},
    keywords = {alias-analysis, static-analysis},
    location = {Ottawa, Ontario, Canada},
    pages = {54--63},
    priority = {2},
    publisher = {ACM},
    title = {Field-sensitive value analysis of embedded C programs with union types and pointer arithmetics},
    url = {http://dx.doi.org/10.1145/1134650.1134659},
    year = {2006}
}

@article{mattmight:Kozen:1983:MuCalculus,
    abstract = {In this paper we define and study a propositional μ-calculus  L μ, which consists essentially of propositional modal logic with a least fixpoint operator.  L μ is syntactically simpler yet strictly more expressive than Propositional Dynamic Logic ({PDL}). For a restricted version we give an exponential-time decision procedure, small model property, and complete deductive system, theory subsuming the corresponding results for {PDL}.},
    author = {Kozen, Dexter},
    citeulike-article-id = {2924303},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0304-3975(82)90125-6},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/0304-3975(82)90125-6},
    citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B6V1G-45TK9RG-T/1/ef3e449e6e7a1b5d604db549e096af9c},
    date-added = {2009-07-15 00:08:51},
    doi = {10.1016/0304-3975(82)90125-6},
    issn = {03043975},
    journal = {Theoretical Computer Science},
    keywords = {model-checking, verification},
    number = {3},
    pages = {333--354},
    priority = {2},
    title = {Results on the propositional μ-calculus},
    url = {http://dx.doi.org/10.1016/0304-3975(82)90125-6},
    volume = {27},
    year = {1983}
}

@inproceedings{mattmight:VanHorn:2008:EXPTIME,
    abstract = {We give an exact characterization of the computational complexity of the  k {CFA} hierarchy. For any  k  > 0, we prove that the control flow decision problem is complete for deterministic exponential time. This theorem validates empirical observations that such control flow analysis is intractable. It also provides more general insight into the complexity of abstract interpretation.},
    author = {Van Horn, David and Mairson, Harry G.},
    booktitle = {ICFP '08: Proceedings of the 13th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {5152280},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1411243},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1411204.1411243},
    date-added = {2009-07-15 00:06:32},
    doi = {10.1145/1411204.1411243},
    isbn = {978-1-59593-919-7},
    keywords = {cfa},
    location = {Victoria, BC, Canada},
    pages = {275--282},
    priority = {2},
    publisher = {ACM Press},
    title = {Deciding {k-CFA} is complete for {EXPTIME}},
    url = {http://dx.doi.org/10.1145/1411204.1411243},
    year = {2008}
}

@inproceedings{mattmight:Steensgard:1996:PointsTo,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Steensgaard, Bjarne},
    booktitle = {POPL '96: Proceedings of the 23rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {329717},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=237727},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/237721.237727},
    date-added = {2009-07-14 23:59:52},
    doi = {10.1145/237721.237727},
    isbn = {0-89791-769-3},
    keywords = {alias-analysis, static-analysis},
    location = {St. Petersburg Beach, Florida, United States},
    pages = {32--41},
    priority = {0},
    publisher = {ACM},
    series = {POPL '96},
    title = {Points-to analysis in almost linear time},
    url = {http://dx.doi.org/10.1145/237721.237727},
    year = {1996}
}

@inproceedings{mattmight:Nanevski:2006:HTT,
    abstract = {In previous work, we proposed a  Hoare Type Theory  ({HTT}) which combines effectful higher-order functions, dependent types and Hoare Logic specifications into a unified framework. However, the framework did not support polymorphism, and ailed to provide a modular treatment of state in specifications. In this paper, we address these shortcomings by showing that the addition of polymorphism alone is sufficient for capturing modular state specifications in the style of Separation Logic. Furthermore, we argue that polymorphism is an essential ingredient of the extension, as the treatment of higher-order functions requires operations not encodable via the spatial connectives of Separation Logic.},
    address = {New York, NY, USA},
    author = {Nanevski, Aleksandar and Morrisett, Greg and Birkedal, Lars},
    booktitle = {ICFP '06: Proceedings of the Eleventh ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {5151789},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1159803.1159812},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1159803.1159812},
    date-added = {2009-07-14 23:05:36},
    doi = {10.1145/1159803.1159812},
    isbn = {1-59593-309-3},
    keywords = {dependent-types, hoare-logic, type-theory, verification},
    location = {Portland, Oregon, USA},
    pages = {62--73},
    priority = {2},
    publisher = {ACM},
    title = {Polymorphism and separation in hoare type theory},
    url = {http://dx.doi.org/10.1145/1159803.1159812},
    year = {2006}
}

@inproceedings{mattmight:Nanevski:2008:Ynot,
    abstract = {We describe an axiomatic extension to the Coq proof assistant, that supports writing, reasoning about, and extracting higher-order, dependently-typed programs with  side-effects . Coq already includes a powerful functional language that supports dependent types, but that language is limited to pure, total functions. The key contribution of our extension, which we call Ynot, is the added support for computations that may have effects such as non-termination, accessing a mutable store, and throwing/catching exceptions.},
    address = {New York, NY, USA},
    author = {Nanevski, Aleksandar and Morrisett, Greg and Shinnar, Avraham and Govereau, Paul and Birkedal, Lars},
    booktitle = {ICFP '08: Proceeding of the 13th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {3390918},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1411204.1411237},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1411204.1411237},
    date-added = {2009-07-14 23:01:55},
    doi = {10.1145/1411204.1411237},
    isbn = {978-1-59593-919-7},
    keywords = {dependent-types, type-theory},
    location = {Victoria, BC, Canada},
    pages = {229--240},
    priority = {2},
    publisher = {ACM},
    title = {Ynot: Dependent types for imperative programs},
    url = {http://dx.doi.org/10.1145/1411204.1411237},
    year = {2008}
}

@inproceedings{mattmight:Cartwright:1991:SoftTyping,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has opted to expose the complete List rather than only correct and linked references.},
    address = {New York, NY, USA},
    author = {Cartwright, Robert and Fagan, Mike},
    booktitle = {PLDI '91: Proceedings of the ACM SIGPLAN 1991 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {2792466},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=113445.113469},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/113445.113469},
    date-added = {2009-07-14 22:55:46},
    doi = {10.1145/113445.113469},
    isbn = {0-89791-428-7},
    keywords = {type-theory},
    location = {Toronto, Ontario, Canada},
    pages = {278--292},
    priority = {2},
    publisher = {ACM},
    title = {Soft typing},
    url = {http://dx.doi.org/10.1145/113445.113469},
    year = {1991}
}

@inproceedings{mattmight:Flanagan:1993:ANF,
    abstract = {In order to simplify the compilation process, many compilers for higher-order languages use the continuation-passing style ({CPS}) transformation in a first phase to generate an intermediate representation of the source program. The salient aspect of this intermediate form is that all procedures take an argument that represents the rest of the computation (the  ” continuation”). Since the nai¨ve {CPS} transformation considerably increases the size of programs, {CPS} compilers perform reductions to produce a more compact intermediate representation. Although often implemented as a part of the {CPS} transformation, this step is conceptually a second phase. Finally, code generators for typical {CPS} compilers treat continuations specially in order to optimize the interpretation of continuation parameters.   A thorough analysis of the abstract machine for {CPS} terms show that the actions of the code generator  invert  the nai¨ve {CPS} translation step. Put differently, the combined effect of the three phases is equivalent to a source-to-source transformation that simulates the compaction phase. Thus, fully developed {CPS} compilers do not need to employ the {CPS} transformation but can achieve the same results with a simple source-level transformation.},
    address = {New York, NY, USA},
    author = {Flanagan, Cormac and Sabry, Amr and Duba, Bruce F. and Felleisen, Matthias},
    booktitle = {PLDI '93: Proceedings of the ACM SIGPLAN 1993 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {190446},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=155113},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/155090.155113},
    date-added = {2009-07-14 22:50:09},
    doi = {10.1145/155090.155113},
    isbn = {0-89791-598-4},
    keywords = {anf},
    location = {Albuquerque, New Mexico, United States},
    month = jun,
    pages = {237--247},
    priority = {2},
    publisher = {ACM},
    title = {The essence of compiling with continuations},
    url = {http://dx.doi.org/10.1145/155090.155113},
    year = {1993}
}

@inproceedings{mattmight:Fahndrich:2007:NonNull,
    abstract = {Mainstream object-oriented languages such as C\# and Java provide an initialization model for objects that does not guarantee programmer controlled initialization of fields. Instead, all fields are initialized to default values (0 for scalars and  null  for non-scalars) on allocation. This is in stark contrast to functional languages, where all parts of an allocation are initialized to programmer-provided values. These choices have a direct impact on two main issues: 1) the prevalence of  null  in object oriented languages (and its general absence in functional languages), and 2) the ability to initialize circular data structures. This paper explores connections between these differing approaches and proposes a fresh look at initialization. Delayed types are introduced to express and formalize prevalent initialization patterns in object-oriented languages.},
    address = {New York, NY, USA},
    author = {Fahndrich, Manuel and Xia, Songtao},
    booktitle = {OOPSLA '07: Proceedings of the 22nd Annual ACM SIGPLAN Conference on Object-oriented programming systems and applications},
    citeulike-article-id = {4636352},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1297027.1297052},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1297027.1297052},
    date-added = {2009-07-14 22:47:00},
    doi = {10.1145/1297027.1297052},
    isbn = {978-1-59593-786-5},
    keywords = {non-nullability, type-theory},
    location = {Montreal, Quebec, Canada},
    pages = {337--350},
    priority = {2},
    publisher = {ACM},
    title = {Establishing object invariants with delayed types},
    url = {http://dx.doi.org/10.1145/1297027.1297052},
    year = {2007}
}

@inproceedings{mattmight:Fahndrich:2003:NonNull,
    address = {New York, NY, USA},
    author = {F\"{a}hndrich, Manuel and Rustan},
    booktitle = {OOPSLA '03: Proceedings of the 18th Annual ACM SIGPLAN Conference on Object-oriented programing, systems, languages, and applications},
    citeulike-article-id = {5151648},
    citeulike-linkout-0 = {http://dx.doi.org/http://doi.acm.org/10.1145/949305.949332},
    date-added = {2009-07-14 22:45:07},
    doi = {http://doi.acm.org/10.1145/949305.949332},
    keywords = {non-nullability, type-theory},
    location = {Anaheim, California, USA},
    pages = {302--312},
    priority = {0},
    publisher = {ACM},
    title = {Declaring and checking non-null types in an object-oriented language},
    url = {http://dx.doi.org/http://doi.acm.org/10.1145/949305.949332},
    year = {2003}
}

@book{mattmight:Martin-Lof:1984:Intuitionistic,
    address = {Naples},
    author = {Martin-L\"{o}f, Per},
    citeulike-article-id = {2425748},
    citeulike-linkout-0 = {http://www.ams.org/mathscinet-getitem?mr=769301},
    date-added = {2009-07-14 22:36:04},
    keywords = {type-theory},
    mrnumber = {MR769301},
    priority = {2},
    publisher = {Bibliopolis},
    series = {Studies in Proof Theory},
    title = {Intuitionistic type theory},
    url = {http://www.ams.org/mathscinet-getitem?mr=769301},
    volume = {1},
    year = {1984}
}

@inproceedings{mattmight:Andersen:1992:PartialEvaluation,
    address = {London, UK},
    author = {Andersen, Lars O.},
    booktitle = {CC '92: Proceedings of the 4th International Conference on Compiler Construction},
    citeulike-article-id = {5151532},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=727274},
    date-added = {2009-07-14 22:30:58},
    isbn = {3-540-55984-1},
    keywords = {partial-evaluation, static-analysis},
    pages = {251--257},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Partial Evaluation of C and Automatic Compiler Generation (Extended Abstract)},
    url = {http://portal.acm.org/citation.cfm?id=727274},
    year = {1992}
}

@techreport{mattmight:Steele:1978:Rabbit,
    abstract = {We have developed a compiler for the lexically-scoped dialect of {LISP} known as {SCHEME}. The compiler knows relatively little about specific data manipulation primitives such as arithmetic operators, but concentrates on general issues of environment and control. Rather than having specialized knowledge about a large variety of control and environment constructs, the compiler handles only a small basis set which reflects the semantics of lambda-calculus. All of the traditional imperative constructs, such as sequencing, assignment, looping, {GO} {TO}, as well as many standard {LISP} constructs such as {AND}, {OR} and {COND}, are expressed as macros in terms of the applicative basis set. A small number of optimization techniques, coupled with the treatment of function calls as {GO} {TO} statements, serves to produce code as good as that produced by more traditional compilers.},
    address = {Cambridge, MA, USA},
    author = {Steele, Guy L.},
    citeulike-article-id = {82938},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=889478},
    date-added = {2009-07-14 22:29:27},
    institution = {Massachusetts Institute of Technology},
    keywords = {compiler, cps, lambda-calculus, scheme},
    priority = {2},
    publisher = {Massachusetts Institute of Technology},
    title = {Rabbit: A Compiler for Scheme},
    url = {http://portal.acm.org/citation.cfm?id=889478},
    year = {1978}
}

@inproceedings{mattmight:Heintze:1997:Cubic,
    abstract = {We prove that certain data-flow and control-flow problems are {2NPDA}-complete. This means that these problems are in the class {2NPDA} and that they are hard for that class. The fact that they are in {2NPDA} demonstrates the richness of the class. The fact that they are hard for {2NPDA} can be interpreted as evidence they can not be solved in sub-cubic time --- the cubic time decision procedure for an arbitrary {2NPDA} problem has not been improved since its discovery in 1968.},
    address = {Washington, DC, USA},
    author = {Heintze, Nevin and Mcallester, David},
    booktitle = {LICS '97: Proceedings of the 12th Annual IEEE Symposium on Logic in Computer Science},
    citeulike-article-id = {5151505},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=788876},
    date-added = {2009-07-14 22:27:05},
    isbn = {0-8186-7925-5},
    pages = {342+},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {On the Cubic Bottleneck in Subtyping and Flow Analysis},
    url = {http://portal.acm.org/citation.cfm?id=788876},
    year = {1997}
}

@inproceedings{mattmight:Gulwani:2009:SPEED,
    abstract = {This paper describes an inter-procedural technique for computing symbolic bounds on the number of statements a procedure executes in terms of its scalar inputs and user-defined quantitative functions of input data-structures. Such computational complexity bounds for even simple programs are usually disjunctive, non-linear, and involve numerical properties of heaps. We address the challenges of generating these bounds using two novel ideas.},
    address = {New York, NY, USA},
    author = {Gulwani, Sumit and Mehra, Krishna K. and Chilimbi, Trishul},
    booktitle = {POPL '09: Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5151481},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1480881.1480898},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1480881.1480898},
    date-added = {2009-07-14 22:23:10},
    doi = {10.1145/1480881.1480898},
    isbn = {978-1-60558-379-2},
    keywords = {abstract-interpretation, static-analysis, wcet},
    location = {Savannah, GA, USA},
    pages = {127--139},
    priority = {2},
    publisher = {ACM},
    title = {{SPEED}: Precise and efficient static estimation of program computational complexity},
    url = {http://dx.doi.org/10.1145/1480881.1480898},
    year = {2009}
}

@article{mattmight:Hoare:1969:HoareLogic,
    abstract = {In this paper an attempt is made to explore the logical foundations of computer programming by use of techniques which were first applied in the study of geometry and have later been extended to other branches of mathematics. This involves the elucidation of sets of axioms and rules of inference which can be used in proofs of the properties of computer programs. Examples are given of such axioms and rules, and a formal proof of a simple theorem is displayed. Finally, it is argued that important advantage, both theoretical and practical, may follow from a pursuance of these topics.},
    address = {New York, NY, USA},
    author = {Hoare, C. A. R.},
    citeulike-article-id = {163708},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=363259},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/363235.363259},
    date-added = {2009-07-14 22:15:46},
    doi = {10.1145/363235.363259},
    issn = {0001-0782},
    journal = {Communications of the ACM},
    keywords = {hoare-logic, verification},
    month = oct,
    number = {10},
    pages = {576--580},
    priority = {2},
    publisher = {ACM},
    title = {An axiomatic basis for computer programming},
    url = {http://dx.doi.org/10.1145/363235.363259},
    volume = {12},
    year = {1969}
}

@inproceedings{mattmight:Damas:1982:Type,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Damas, Luis and Milner, Robin},
    booktitle = {POPL '82: Proceedings of the 9th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {370442},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=582176},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/582153.582176},
    date-added = {2009-07-11 23:56:32},
    doi = {10.1145/582153.582176},
    isbn = {0-89791-065-6},
    keywords = {damas-milner, ml, type-inference, type-theory},
    location = {Albuquerque, New Mexico},
    pages = {207--212},
    priority = {2},
    publisher = {ACM},
    series = {POPL '82},
    title = {Principal type-schemes for functional programs},
    url = {http://dx.doi.org/10.1145/582153.582176},
    year = {1982}
}

@inproceedings{mattmight:Grove:1997:OOCFA,
    abstract = {Interprocedural analyses enable optimizing compilers to more precisely model the effects of non-inlined procedure calls, potentially resulting in substantial increases in application performance. Applying interprocedural analysis to programs written in object-oriented or functional languages is complicated by the difficulty of constructing an accurate program call graph. This paper presents a parameterized algorithmic framework for call graph construction in the presence of message sends and/or first class functions. We use this framework to describe and to implement a number of well-known and new algorithms. We then empirically assess these algorithms by applying them to a suite of medium-sized programs written in Cecil and Java, reporting on the relative cost of the analyses, the relative precision of the constructed call graphs, and the impact of this precision on the effectiveness of a number of interprocedural optimizations.},
    address = {New York, NY, USA},
    author = {Grove, David and Defouw, Greg and Dean, Jeffrey and Chambers, Craig},
    booktitle = {OOPSLA '97: Proceedings of the 12th ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications},
    citeulike-article-id = {277250},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=264352},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/263698.264352},
    date-added = {2009-07-11 23:19:42},
    doi = {10.1145/263698.264352},
    isbn = {0-89791-908-4},
    issn = {0362-1340},
    keywords = {cfa, control-flow-analysis},
    location = {Atlanta, Georgia, United States},
    month = oct,
    number = {10},
    pages = {108--124},
    priority = {2},
    publisher = {ACM},
    series = {OOPSLA '97},
    title = {Call graph construction in object-oriented languages},
    url = {http://dx.doi.org/10.1145/263698.264352},
    volume = {32},
    year = {1997}
}

@inproceedings{mattmight:Agesen:1995:CPA,
    address = {London, UK},
    author = {Agesen, Ole},
    booktitle = {ECOOP '95: Proceedings of the 9th European Conference on Object-Oriented Programming},
    citeulike-article-id = {5121259},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=646153.679533},
    date-added = {2009-07-11 23:15:25},
    isbn = {3-540-60160-0},
    keywords = {cfa, control-flow-analysis, static-analysis},
    pages = {2--26},
    priority = {0},
    publisher = {Springer-Verlag},
    title = {The Cartesian Product Algorithm: Simple and Precise Type Inference Of Parametric Polymorphism},
    url = {http://portal.acm.org/citation.cfm?id=646153.679533},
    year = {1995}
}

@article{mattmight:Wright:1998:Polymorphic,
    abstract = {This article describes a general-purpose program analysis that  computes global control-flow and data-flow information for  higher-order, call-by-value languages.  The analysis employs a  novel form of polyvariance called polymorhic splitting that uses  let-expressions as syntactic clues to gain precision. The information  derived from the analysis is used both to eliminate run-time checks and to inline procedure. The analysis and optimizations have been  applied to a suite of Scheme programs. Experimental results obtained  from the prototype implementation indicate that the analysis is  extremely precise and has reasonable cost. Compared to monovariant flow analyses such as {0CFA}, or analyses based on type inference such as  soft typing, the analysis eliminates significantly more    run-time checks. Run-time check elimination and inlining together typically yield a 20 to 40\% performance improvement for the benchmark suite, with some programs running four times as fast.},
    address = {New York, NY, USA},
    author = {Wright, Andrew K. and Jagannathan, Suresh},
    citeulike-article-id = {4884},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=271523},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/271510.271523},
    date-added = {2009-07-11 22:55:47},
    doi = {10.1145/271510.271523},
    issn = {0164-0925},
    journal = {ACM Transactions on Programming Languages and Systems},
    keywords = {cfa, constraint-solving, control-flow-analysis, static-analysis},
    month = jan,
    number = {1},
    pages = {166--207},
    priority = {0},
    publisher = {ACM},
    title = {Polymorphic splitting: An effective polyvariant flow analysis},
    url = {http://dx.doi.org/10.1145/271510.271523},
    volume = {20},
    year = {1998}
}

@article{mattmight:Palsberg:1995:CFA,
    abstract = {Flow analyses of untyped higher-order functional programs have in the past decade been presented by Ayers, Bondorf, Consel, Jones, Heintze, Sestoft, Shivers, Steckler, Wand, and others. The analyses are usually defined as abstract interpretations and are used for rather different tasks such as type recovery, globalization, and binding-time analysis. The analyses all contain a global closure analysis that computes information about higher-order control-flow. Sestoft proved in 1989 and 1991 that closure analysis is correct with respect to call-by-name and call-by-value semantics, but it remained open if correctness holds for arbitrary {beta-reduction.This} article answers the question; both closure analysis and others are correct with respect to arbitrary beta-reduction. We also prove a subject-reduction result: closure information is still valid after beta-reduction. The core of our proof technique is to define closure analysis using a constraint system. The constraint system is equivalent to the closure analysis of Bondorf, which in turn is based on Sestoft's.},
    address = {New York, NY, USA},
    author = {Palsberg, Jens},
    citeulike-article-id = {4157},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=201001},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/200994.201001},
    date-added = {2009-07-11 22:37:15},
    doi = {10.1145/200994.201001},
    issn = {0164-0925},
    journal = {ACM Transactions on Programming Languages and Systems},
    keywords = {cfa, constraint-solving, control-flow-analysis, static-analysis},
    month = jan,
    number = {1},
    pages = {47--62},
    priority = {2},
    publisher = {ACM},
    title = {Closure analysis in constraint form},
    url = {http://dx.doi.org/10.1145/200994.201001},
    volume = {17},
    year = {1995}
}

@article{mattmight:Gulwani:2006:Combining,
    abstract = {We present a methodology for automatically combining abstract interpreters over given lattices to construct an abstract interpreter for the combination of those lattices. This lends modularity to the process of design and implementation of abstract {interpreters.We} define the notion of logical product of lattices. This kind of combination is more precise than the reduced product combination. We give algorithms to obtain the join operator and the existential quantification operator for the combined lattice from the corresponding operators of the individual lattices. We also give a bound on the number of steps required to reach a fixed point across loops during analysis over the combined lattice in terms of the corresponding bounds for the individual lattices. We prove that our combination methodology yields the most precise abstract interpretation operators over the logical product of lattices when the individual lattices are over theories that are convex, stably infinite, and {disjoint.We} also present an interesting application of logical product wherein some lattices can be reduced to combination of other (unrelated) lattices with known abstract interpreters.},
    address = {New York, NY, USA},
    author = {Gulwani, Sumit and Tiwari, Ashish},
    booktitle = {PLDI '06: Proceedings of the 2006 ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {3091102},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1133981.1134026},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1133981.1134026},
    date-added = {2009-06-28 21:31:36},
    doi = {10.1145/1133981.1134026},
    isbn = {1595933204},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {abstract-interpretation},
    location = {Ottawa, Ontario, Canada},
    month = jun,
    pages = {376--386},
    priority = {4},
    publisher = {ACM},
    title = {Combining abstract interpreters},
    url = {http://dx.doi.org/10.1145/1133981.1134026},
    volume = {41},
    year = {2006}
}

@inproceedings{mattmight:Reps:1995:Precise,
    abstract = {The paper shows how a large class of interprocedural dataflow-analysis problems can be solved precisely in polynomial time by transforming them into a special kind of graph-reachability problem. The only restrictions are that the set of dataflow facts must be a finite set, and that the dataflow functions must distribute over the confluence operator (either union or intersection). This class of probable problems includes—but is not limited to—the classical separable problems (also known as  ” gen/kill” or  ” bit-vector” problems)—e.g., reaching definitions, available expressions, and live variables. In addition, the class of problems that our techniques handle includes many non-separable problems, including truly-live variables, copy constant propagation, and possibly-uninitialized {variables.Results} are reported from a preliminary experimental study of C programs (for the problem of finding possibly-uninitialized variables).},
    address = {New York, NY, USA},
    author = {Reps, Thomas and Horwitz, Susan and Sagiv, Mooly},
    booktitle = {POPL '95: Proceedings of the 22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {778826},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=199462},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/199448.199462},
    date-added = {2009-06-26 20:16:37},
    doi = {10.1145/199448.199462},
    isbn = {0-89791-692-1},
    keywords = {graph-reachability, pushdown-analysis},
    location = {San Francisco, California, United States},
    pages = {49--61},
    priority = {3},
    publisher = {ACM},
    series = {POPL '95},
    title = {Precise interprocedural dataflow analysis via graph reachability},
    url = {http://dx.doi.org/10.1145/199448.199462},
    year = {1995}
}

@article{mattmight:Anderson:2009:Harmful,
    abstract = {This paper develops a model of computer systems research to help prospective authors understand the often obscure workings of conference program committees. We present data to show that the variability between reviewers is often the dominant factor as to whether a paper is accepted. We argue that paper merit is likely to be zipf distributed, making it inherently difficult for program committees to distinguish between most papers. We use game theory to show that with noisy reviews and zipf merit, authors have an incentive to submit papers too early and too often. These factors make conference reviewing, and systems research as a whole, less efficient and less effective. We describe some recent changes in conference design to address these issues, and we suggest some further potential improvements.},
    address = {New York, NY, USA},
    author = {Anderson, Thomas},
    citeulike-article-id = {4959554},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1531793.1531815},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1531793.1531815},
    date-added = {2009-06-25 18:59:16},
    doi = {10.1145/1531793.1531815},
    issn = {0163-5980},
    journal = {SIGOPS Operating Systems Review},
    keywords = {peer-review},
    number = {2},
    pages = {108--116},
    priority = {4},
    publisher = {ACM},
    title = {Conference reviewing considered harmful},
    url = {http://dx.doi.org/10.1145/1531793.1531815},
    volume = {43},
    year = {2009}
}

@inproceedings{mattmight:Walton:2007:Resource,
    abstract = {The software that runs on a typical wireless sensor network node must address a variety of constraints that are imposed by its purpose and implementation platform. Examples of such constraints include real-time behavior, highly limited {RAM} and {ROM}, and other scarce resources. These constraints lead to crosscutting concerns for the implementations of sensor network software: that is, all parts of the software must be carefully written to respect its resource constraints. Neither traditional languages (such as C) nor component-based languages (such as {nesC}) for implementing sensor network software allow programmers to deal with crosscutting resource constraints in a modular fashion.},
    address = {New York, NY, USA},
    author = {Walton, Sean and Eide, Eric},
    booktitle = {PLOS '07: Proceedings of the 4th Workshop on Programming Languages and Operating Systems},
    citeulike-article-id = {4014035},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1376789.1376796},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1376789.1376796},
    date-added = {2009-06-22 00:13:22},
    doi = {10.1145/1376789.1376796},
    isbn = {978-1-59593-922-7},
    keywords = {operating-systems, sensor-nets},
    location = {Stevenson, Washington},
    pages = {1--5},
    priority = {2},
    publisher = {ACM},
    title = {Resource management aspects for sensor network software},
    url = {http://dx.doi.org/10.1145/1376789.1376796},
    year = {2007}
}

@inproceedings{mattmight:Diatchki:2008:House,
    abstract = {Current practices for developing systems software usually rely on fairly low-level programming languages and tools. As an alternative, our group has been investigating the possibility of using a high-level functional language, Haskell, for kernel and device driver construction, with the hope that it will allow us to produce more reliable and secure software. In this paper, we describe our experience developing a prototype operating system, House, in which the kernel, device drivers, and even a simple {GUI}, are all written in Haskell. The House system demonstrates that it is indeed possible to construct systems software in a functional language. However, it also suggests some ideas for a new Haskell dialect with features that target specific needs in this domain, including strongly typed support for low-level data structures and facilities for explicit memory accounting.},
    address = {New York, NY, USA},
    author = {Diatchki, Iavor S. and Hallgren, Thomas and Jones, Mark P. and Leslie, Rebekah and Tolmach, Andrew},
    booktitle = {PLOS '07: Proceedings of the 4th Workshop on Programming Languages and Operating Systems},
    citeulike-article-id = {4920595},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1376789.1376791},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1376789.1376791},
    date-added = {2009-06-22 00:11:24},
    doi = {10.1145/1376789.1376791},
    isbn = {978-1-59593-922-7},
    keywords = {haskell, operating-systems},
    location = {Stevenson, Washington},
    pages = {1--5},
    priority = {2},
    publisher = {ACM},
    title = {Writing systems software in a functional language: {An} experience report},
    url = {http://dx.doi.org/10.1145/1376789.1376791},
    year = {2007}
}

@inproceedings{mattmight:Might:2007:ModelChecking,
    abstract = {We present and discuss techniques for performing and improving the model-checking of higher-order, functional programs based upon abstract interpretation [4]. We use continuation-passing-style conversion to produce an abstractable state machine, and then utilize abstract garbage collection and abstract counting [9] to indirectly prune false branches in the abstract state-to-state transition graph. In the process, we generalize abstract garbage collection to conditional garbage collection; that is, we collect values which an ordinary reaching-based collector would have deemed live when it is provable that such values will never be referenced. In addition, we enhance abstract counting, and then exploit it to more precisely evaluate conditions in the abstract.},
    author = {Might, Matthew and Chambers, Benjamin and Shivers, Olin},
    booktitle = {Verification, Model Checking, and Abstract Interpretation},
    citeulike-article-id = {4915352},
    citeulike-linkout-0 = {http://matt.might.net/},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-69738-1\_4},
    date-added = {2009-06-20 06:43:41},
    doi = {10.1007/978-3-540-69738-1\_4},
    keywords = {abstract-garbage-collection, abstract-interpretation, gamma-cfa, model-checking},
    location = {Nice, France},
    month = jan,
    pages = {59--73},
    priority = {0},
    title = {Model Checking via {Gamma-CFA}},
    url = {http://matt.might.net/},
    year = {2007}
}

@article{mattmight:Harrison:1989:Parallelization,
    abstract = {Lisp and its descendants are among the most important and widely used of programming languages. At the same time, parallelism in the architecture of computer systems is becoming commonplace. There is a pressing need to extend the technology of automatic parallelization that has become available to Fortran programmers of parallel machines, to the realm of Lisp programs and symbolic computing. In this paper we present a comprehensive approach to the compilation of Scheme programs for shared-memory multiprocessors. Our strategy has two principal components:interprocedural analysis andprogram restructuring. We introduceprocedure strings andstack configurations as a framework in which to reason about interprocedural side-effects and object lifetimes, and develop a system of interprocedural analysis, using abstract interpretation, that is used in the dependence analysis and memory management of Scheme programs. We introduce the transformations ofexit-loop translation andrecursion splitting to treat the control structures of iteration and recursion that arise commonly in Scheme programs. We propose an alternative representation for s-expressions that facilitates the parallel creation and access of lists. We have implemented these ideas in a parallelizing Scheme compiler and run-time system, and we complement the theory of our work with  ” snapshots” of programs during the restructuring process, and some preliminary performance results of the execution of object codes produced by the compiler.},
    author = {Harrison, Williams L.},
    citeulike-article-id = {3623280},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/BF01808954},
    citeulike-linkout-1 = {http://www.springerlink.com/content/w06452201433576m},
    date-added = {2009-06-20 04:26:11},
    day = {1},
    doi = {10.1007/BF01808954},
    journal = {LISP and Symbolic Computation},
    keywords = {continuation, dissertation, lambda-calculus, parallelization},
    month = oct,
    number = {3},
    pages = {179--396},
    priority = {0},
    title = {The interprocedural analysis and automatic parallelization of Scheme programs},
    url = {http://dx.doi.org/10.1007/BF01808954},
    volume = {2},
    year = {1989}
}

@phdthesis{mattmight:Shivers:1991:CFA,
    abstract = {Programs written in powerful, higher-order languages like Scheme, {ML}, and Common Lisp should run as fast as their {FORTRAN} and C counterparts. They should, but they don't. A major reason is the level of optimisation applied to these two classes of languages. Many {FORTRAN} and C compilers employ an arsenal of sophisticated global optimisations that depend upon data-ﬂow analysis: common-subexpression elimination, loop-invariant detection, induction-variable elimination, and many, many more. Compilers for higher- order languages do not provide these optimisations. Without them, Scheme, {LISP} and {ML} compilers are doomed to produce code that runs slower than their {FORTRAN} and C counterparts. The problem is the lack of an explicit control-ﬂow graph at compile time, something which traditional data-ﬂow analysis techniques require. In this dissertation, I present a technique for recovering the control-ﬂow graph of a Scheme program at compile time. I give examples of how this information can be used to perform several data-ﬂow analysis optimisations, including copy propagation, induction-variable elimination, useless-variable elimination, and type recovery. The analysis is deﬁned in terms of a non-standard semantic interpretation. The denotational semantics is carefully developed, and several theorems establishing the correctness of the semantics and the implementing algorithms are proven.},
    address = {Pittsburgh, PA, USA},
    author = {Shivers, Olin G.},
    citeulike-article-id = {82936},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=124950},
    date-added = {2009-06-20 04:16:00},
    keywords = {abstract-interpretation, cfa, control-flow-analysis, cps, dissertation, static-analysis},
    priority = {0},
    publisher = {Carnegie Mellon University},
    school = {Carnegie Mellon University},
    title = {{Control-Flow} Analysis of {Higher-Order} Languages},
    url = {http://portal.acm.org/citation.cfm?id=124950},
    year = {1991}
}

@article{mattmight:Shivers:1988:CFA,
    abstract = {Traditional flow analysis techniques, such as the ones typically employed by optimizing Fortran compilers, do not work for Scheme-like languages. This paper presents a flow analysis technique —  control flow analysis  — which is applicable to Scheme-like languages. As a demonstration application, the information gathered by control flow analysis is used to perform a traditional flow analysis problem, induction variable elimination. Extensions and limitations are discussed.   The techniques presented in this paper are backed up by working code. They are applicable not only to Scheme, but also to related languages, such as Common Lisp and {ML}.},
    address = {New York, NY, USA},
    author = {Shivers, Olin},
    booktitle = {Proceedings of the ACM SIGPLAN 1988 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {1354},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=54007},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/53990.54007},
    date-added = {2009-06-20 04:08:28},
    doi = {10.1145/53990.54007},
    isbn = {0-89791-269-1},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {cfa, continuation-passing-style, control-flow-analysis, cps, static-analysis},
    location = {Atlanta, Georgia, United States},
    month = jun,
    number = {7},
    pages = {164--174},
    priority = {0},
    publisher = {ACM},
    title = {Control flow analysis in {Scheme}},
    url = {http://dx.doi.org/10.1145/53990.54007},
    volume = {23},
    year = {1988}
}

@inproceedings{mattmight:SMLNJ,
    abstract = {The Standard {ML} of New Jersey compiler has been under development for five years now. We have developed a robust and complete environment for Standard {ML} that supports the implementation of large software systems and generates efficient code. The compiler has also served as a laboratory for developing novel implementation techniques for a sophisticated type and module system, continuation based code generation, efficient pattern matching, and concurrent programming features.},
    author = {Appel, Andrew W. and Macqueen, David B.},
    booktitle = {Proceedings of the Third International Symposium on Programming Language Implementation and Logic Programming},
    citeulike-article-id = {342292},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.9444},
    date-added = {2009-06-20 03:48:31},
    editor = {Maluszynski, J. and Wirsing, M.},
    keywords = {ml, sml},
    number = {528},
    pages = {1--13},
    priority = {2},
    publisher = {Springer Verlag},
    title = {Standard {ML} of {New} {Jersey}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.9444},
    year = {1991}
}

@book{mattmight:SML:1997,
    abstract = {{Standard ML is a general-purpose programming language designed for large projects. This book provides a formal definition of Standard ML for the benefit of all concerned with the language, including users and implementers. Because computer programs are increasingly required to withstand rigorous analysis, it is all the more important that the language in which they are written be defined with full rigor.<br /> <br /> One purpose of a language definition is to establish a theory of meanings upon which the understanding of particular programs may rest. To properly define a programming language, it is necessary to use some form of notation other than a programming language. Given a concern for rigor, mathematical notation is an obvious choice. The authors have defined their semantic objects in mathematical notation that is completely independent of Standard ML.<br /> <br /> In defining a language one must also define the rules of evaluation precisely--that is, define what meaning results from evaluating any phrase of the language. The definition thus constitutes a formal specification for an implementation. The authors have developed enough of their theory to give sense to their rules of evaluation.<br /> <br /> <I>The Definition of Standard ML</I> is the essential point of reference for Standard ML. Since its publication in 1990, the implementation technology of the language has advanced enormously and the number of users has grown. The revised edition includes a number of new features, omits little-used features, and corrects mistakes of definition.}},
    author = {Milner, Robin and Tofte, Mads and Harper, Robert and Macqueen, David},
    citeulike-article-id = {113339},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262631814},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262631814},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262631814},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262631814},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262631814/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262631814},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0262631814},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0262631814},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0262631814\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0262631814},
    date-added = {2009-06-20 03:44:09},
    day = {15},
    edition = {Rev Sub},
    howpublished = {Paperback},
    isbn = {0262631814},
    keywords = {ml, sml, specification},
    month = may,
    priority = {0},
    publisher = {The MIT Press},
    title = {The Definition of Standard {ML} - Revised},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262631814},
    year = {1997}
}

@inproceedings{mattmight:Wadler:1990:Linear,
    abstract = {The linear logic of {J.-Y}. Girard suggests a new type system for functional  languages, one which supports operations that "change the world". Values belonging  to a linear type must be used exactly once: like the world, they cannot be  duplicated or destroyed. Such values require no reference counting or garbage collection, and safely admit destructive array update. Linear types extend Schmidt's  notion of single threading; provide an alternative to Hudak and Bloss' update  analysis; and offer a practical complement to Lafont and Holmstr\"{o}m's elegant linear languages.},
    author = {Wadler, Philip},
    booktitle = {Programming Concepts and Methods},
    citeulike-article-id = {4914025},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.31.5002},
    date-added = {2009-06-20 03:34:59},
    keywords = {linear-type, type-theory},
    month = apr,
    priority = {2},
    title = {Linear Types Can Change the World!},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.31.5002},
    year = {1990}
}

@article{mattmight:Hannan:1998:Escape,
    abstract = {An important issue faced by implementors of higher-order functional programming languages is the allocation and deallocation of storage for variables. The possibility of variables escaping their scope during runtime makes traditional stack allocation inadequate. We consider the problem of detecting when variables in such languages do not escape their scope, and thus can have their bindings allocated in an efficient manner. We use an annotated type system to infer information about the use of variables in a higher-order, strict functional language and combine this system with a translation to an annotated language which explicitly indicates which variables do not escape. The type system uses a notion of annotated types which extends the traditional simple type system with information about the extent of variables. To illustrate the use of this information we define an operational semantics for the annotated language which supports both stack and environment allocation of variable bindings. Only the stack allocated bindings need follow the protocol for stacks: their extent may not exceed their scope. Environment allocated bindings can have any extent, and their allocation has no impact on the stack allocated ones. We prove the analysis and translation correct with respect to this operational semantics by adapting a traditional type consistency proof to our setting. We have encoded the proof into the Elf programming language and typechecked it, providing a partially machine-checked proof.},
    address = {New York, NY, USA},
    author = {Hannan, John},
    citeulike-article-id = {4913926},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=969609},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/S0956796898003025},
    date-added = {2009-06-20 03:26:00},
    doi = {10.1017/S0956796898003025},
    issn = {0956-7968},
    journal = {Journal of Functional Programming},
    keywords = {escape-analysis, static-analysis, type-based-analysis, type-theory},
    number = {3},
    pages = {239--273},
    priority = {0},
    publisher = {Cambridge University Press},
    title = {A type-based escape analysis for functional languages},
    url = {http://dx.doi.org/10.1017/S0956796898003025},
    volume = {8},
    year = {1998}
}

@book{mattmight:Scala:2008,
    abstract = {Programming in Scala is the definitive book on Scala, the new language for {theJava} Platform that blends object-oriented and functional programming conceptsinto a unique and powerful tool for {developers.Coauthored} by the designer of the Scala language, this authoritative book willteach you, one step at a time, the Scala language and the ideas behind {it.The} book is carefully crafted to help you learn. The first few chapters willgive you enough of the basics that you can already start using Scala forsimple tasks. The entire book is organized so that each new concept builds onconcepts that came before - a series of steps that promises to help you masterthe Scala language and the important ideas about programming that {Scalaembodies.A} comprehensive tutorial and reference for Scala, this book covers the entirelanguage and important libraries.},
    author = {Odersky, Martin and Spoon, Lex and Venners, Bill},
    citeulike-article-id = {4913791},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0981531601},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0981531601},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0981531601},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0981531601},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0981531601/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0981531601},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0981531601},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0981531601},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0981531601\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0981531601},
    date-added = {2009-06-20 03:02:37},
    day = {26},
    edition = {1St Edition},
    howpublished = {Paperback},
    isbn = {0981531601},
    keywords = {scala, specification},
    month = nov,
    priority = {0},
    publisher = {Artima Inc},
    title = {Programming in Scala: A Comprehensive Step-by-step Guide},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0981531601},
    year = {2008}
}

@article{mattmight:Milner:1978:Polymorphism,
    abstract = {The aim of this work is largely a practical one. A widely employed style of programming, particularly in structure-processing languages which impose no discipline of types, entails defining procedures which work well on objects of a wide variety. We present a formal type discipline for such polymorphic procedures in the context of a simple programming language, and a compile time type-checking algorithm },
    author = {Milner, Robin},
    citeulike-article-id = {134009},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0022-0000(78)90014-4},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/0022-0000(78)90014-4},
    citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B6WJ0-4B4YSKG-2D/2/64deca1176fc1a45585d3442521fec04},
    date-added = {2009-06-20 02:47:05},
    doi = {10.1016/0022-0000(78)90014-4},
    issn = {00220000},
    journal = {Journal of Computer and System Sciences},
    keywords = {ml, type-theory},
    month = dec,
    number = {3},
    pages = {348--375},
    priority = {0},
    title = {A theory of type polymorphism in programming},
    url = {http://dx.doi.org/10.1016/0022-0000(78)90014-4},
    volume = {17},
    year = {1978}
}

@inproceedings{mattmight:GHC:1993,
    abstract = {We give an overview of the Glasgow Haskell compiler, focusing especially on way in which we have been able to exploit the rich theory of functional languages to give very practical improvements in the compiler. The compiler is portable, modular, generates good code, and is freely available. 1 Introduction Computer Science is both a scientific and an engineering discipline. As a scientific discipline, it seeks to establish generic principles and theories that can be used to explain or underpin a ...},
    author = {Peyton-Jones, Simon L. and Hall, Cordelia V. and Hammond, Kevin and Partain, Will and Wadler, Philip},
    booktitle = {Proc. UK Joint Framework for Information Technology (JFIT) Technical Conference},
    citeulike-article-id = {313740},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.6555},
    comment = {GHC is the de facto standard for Haskell.},
    date-added = {2009-06-20 01:23:04},
    keywords = {compiler, ghc, haskell},
    priority = {2},
    title = {The {Glasgow} {Haskell} Compiler: A Technical Overview},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.6555},
    year = {93}
}

@electronic{mattmight:MLton,
    author = {Weeks, Stephen and Fluet, Matthew and Cejtin, Henry and Jagannathan, Suresh},
    citeulike-article-id = {4913099},
    citeulike-linkout-0 = {http://mlton.org/},
    comment = {MLton produces extremely efficient executables for SML code.},
    date-added = {2009-06-20 01:17:23},
    howpublished = {http://www.mlton.org/},
    keywords = {compiler, mlton, sml},
    priority = {0},
    title = {The {MLton} Compiler},
    url = {http://mlton.org/}
}

@book{mattmight:C:1988,
    abstract = {{Just about every C programmer I respect learned C from this book. Unlike many of the 1,000 page doorstops stuffed with CD-ROMs that have become popular, this volume is concise and powerful (if somewhat dangerous) -- like C itself. And it was written by Kernighan himself. Need we say more?}},
    author = {Kernighan, Brian W. and Ritchie, Dennis M.},
    citeulike-article-id = {167576},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0131103628},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0131103628},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0131103628},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0131103628},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0131103628/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0131103628},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0131103628},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0131103628},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0131103628\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0131103628},
    date-added = {2009-06-19 17:05:39},
    day = {01},
    edition = {2},
    howpublished = {Paperback},
    isbn = {0131103628},
    keywords = {c, specification},
    location = {Englewood Cliffs, NJ},
    month = mar,
    priority = {0},
    publisher = {Prentice Hall},
    title = {C Programming Language (2nd Edition)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0131103628},
    year = {1988}
}

@article{mattmight:King:1976:Symbolic,
    abstract = {This paper describes the symbolic execution of programs. Instead of supplying the normal inputs to a program (e.g. numbers) one supplies symbols representing arbitrary values. The execution proceeds as in a normal execution except that values may be symbolic formulas over the input symbols. The difficult, yet interesting issues arise during the symbolic execution of conditional branch type statements. A particular system called {EFFIGY} which provides symbolic execution for program testing and debugging is also described. It interpretively executes programs written in a simple {PL}/I style programming language. It includes many standard debugging features, the ability to manage and to prove things about symbolic expressions, a simple program testing manager, and a program verifier. A brief discussion of the relationship between symbolic execution and program proving is also included.},
    address = {New York, NY, USA},
    author = {King, James C.},
    citeulike-article-id = {80858},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=360252},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/360248.360252},
    date-added = {2009-06-17 22:47:32},
    doi = {10.1145/360248.360252},
    issn = {0001-0782},
    journal = {Communications of the ACM},
    keywords = {symbolic-execution},
    month = jul,
    number = {7},
    pages = {385--394},
    priority = {3},
    publisher = {ACM},
    title = {Symbolic execution and program testing},
    url = {http://dx.doi.org/10.1145/360248.360252},
    volume = {19},
    year = {1976}
}

@article{mattmight:Reps:2005:Weighted-PDA,
    abstract = {Recently, pushdown systems ({PDSs}) have been extended to weighted {PDSs}, in which each transition is labeled with a value, and the goal is to determine the meet-over-all-paths value (for paths that meet a certain criterion). This paper shows how weighted {PDSs} yield new algorithms for certain classes of interprocedural dataflow-analysis problems.},
    address = {Amsterdam, The Netherlands, The Netherlands},
    author = {Reps, Thomas and Schwoon, Stefan and Jha, Somesh and Melski, David},
    citeulike-article-id = {4848916},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1115650},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.scico.2005.02.009},
    date-added = {2009-06-14 23:42:48},
    doi = {10.1016/j.scico.2005.02.009},
    issn = {0167-6423},
    journal = {Science of Computer Programming},
    keywords = {pda, pushdown-automata, static-analysis},
    number = {1-2},
    pages = {206--263},
    priority = {2},
    publisher = {Elsevier North-Holland, Inc.},
    title = {Weighted pushdown systems and their application to interprocedural dataflow analysis},
    url = {http://dx.doi.org/10.1016/j.scico.2005.02.009},
    volume = {58},
    year = {2005}
}

@inproceedings{mattmight:Bouajjani:1997:PDA-Reachability,
    address = {London, UK},
    author = {Bouajjani, Ahmed and Esparza, Javier and Maler, Oded},
    booktitle = {CONCUR '97: Proceedings of the 8th International Conference on Concurrency Theory},
    citeulike-article-id = {4848905},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=701281},
    date-added = {2009-06-14 23:40:58},
    isbn = {3-540-63141-0},
    keywords = {model-checking, pushdown-automata, reachability-analysis, static-analysis},
    pages = {135--150},
    priority = {4},
    publisher = {Springer-Verlag},
    title = {Reachability Analysis of Pushdown Automata: Application to {Model-Checking}},
    url = {http://portal.acm.org/citation.cfm?id=701281},
    year = {1997}
}

@phdthesis{mattmight:Might:2007:Dissertation,
    author = {Might, Matthew},
    citeulike-article-id = {4847895},
    citeulike-linkout-0 = {http://matt.might.net/},
    date-added = {2009-06-14 20:10:41},
    day = {7},
    keywords = {abstract-interpretation, cfa, dissertation, environment-analysis, static-analysis},
    month = jun,
    priority = {0},
    school = {Georgia Institute of Technology},
    title = {Environment Analysis of {Higher-Order} Languages},
    url = {http://matt.might.net/},
    year = {2007}
}

@inproceedings{mattmight:Cousot:1979:Galois,
    abstract = {Semantic analysis of programs is essential in optimizing compilers and program verification systems. It encompasses data flow analysis, data type determination, generation of approximate invariant assertions, {etc.Several} recent papers (among others Cousot \& Cousot[77a], Graham \& Wegman[76], Kam \& Ullman[76], Kildall[73], Rosen[78], Tarjan[76], Wegbreit[75]) have introduced abstract approaches to program analysis which are tantamount to the use of a program analysis framework (A,t,\~{a}) where A is a lattice of (approximate) assertions, t is an (approximate) predicate transformer and \~{a} is an often implicit function specifying the meaning of the elements of A. This paper is devoted to the systematic and correct design of program analysis frameworks with respect to a formal {semantics.Preliminary} definitions are given in Section 2 concerning the merge over all paths and (least) fixpoint program-wide analysis methods. In Section 3 we briefly define the (forward and backward) deductive semantics of programs which is later used as a formal basis in order to prove the correctness of the approximate program analysis frameworks. Section 4 very shortly recall the main elements of the lattice theoretic approach to approximate semantic analysis of {programs.The} design of a space of approximate assertions A is studied in Section 5. We first justify the very reasonable assumption that A must be chosen such that the exact invariant assertions of any program must have an upper approximation in A and that the approximate analysis of any program must be performed using a deterministic process. These assumptions are shown to imply that A is a Moore family, that the approximation operator (wich defines the least upper approximation of any assertion) is an upper closure operator and that A is necessarily a complete lattice. We next show that the connection between a space of approximate assertions and a computer representation is naturally made using a pair of isotone adjoined functions. This type of connection between two complete lattices is related to Galois connections thus making available classical mathematical results. Additional results are proved, they hold when no two approximate assertions have the same {meaning.In} Section 6 we study and examplify various methods which can be used in order to define a space of approximate assertions or equivalently an approximation function. They include the characterization of the least Moore family containing an arbitrary set of assertions, the construction of the least closure operator greater than or equal to an arbitrary approximation function, the definition of closure operators by composition, the definition of a space of approximate assertions by means of a complete join congruence relation or by means of a family of principal {ideals.Section} 7 is dedicated to the design of the approximate predicate transformer induced by a space of approximate assertions. First we look for a reasonable definition of the correctness of approximate predicate transformers and show that a local correctness condition can be given which has to be verified for every type of elementary statement. This local correctness condition ensures that the (merge over all paths or fixpoint) global analysis of any program is correct. Since isotony is not required for approximate predicate transformers to be correct it is shown that non-isotone program analysis frameworks are manageable although it is later argued that the isotony hypothesis is natural. We next show that among all possible approximate predicate transformers which can be used with a given space of approximate assertions there exists a best one which provides the maximum information relative to a program-wide analysis method. The best approximate predicate transformer induced by a space of approximate assertions turns out to be isotone. Some interesting consequences of the existence of a best predicate transformer are examined. One is that we have in hand a formal specification of the programs which have to be written in order to implement a program analysis framework once a representation of the space of approximate assertions has been chosen. Examples are given, including ones where the semantics of programs is formalized using Hoare[78]'s sets of {traces.In} Section 8 we show that a hierarchy of approximate analyses can be defined according to the fineness of the approximations specified by a program analysis framework. Some elements of the hierarchy are shortly exhibited and related to the relevant {literature.In} Section 9 we consider global program analysis methods. The distinction between "distributive" and "non-distributive" program analysis frameworks is studied. It is shown that when the best approximate predicate transformer is considered the coincidence or not of the merge over all paths and least fixpoint global analyses of programs is a consequence of the choice of the space of approximate assertions. It is shown that the space of approximate assertions can always be refined so that the merge over all paths analysis of a program can be defined by means of a least fixpoint of isotone {equations.Section} 10 is devoted to the combination of program analysis frameworks. We study and examplify how to perform the "sum", "product" and "power" of program analysis frameworks. It is shown that combined analyses lead to more accurate information than the conjunction of the corresponding separate analyses but this can only be achieved by a new design of the approximate predicate transformer induced by the combined program analysis frameworks.},
    address = {New York, NY, USA},
    author = {Cousot, Patrick and Cousot, Radhia},
    booktitle = {POPL '79: Proceedings of the 6th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
    citeulike-article-id = {225306},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=567778},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/567752.567778},
    date-added = {2009-06-13 21:01:58},
    doi = {10.1145/567752.567778},
    keywords = {abstract-interpretation, galois-connection},
    location = {San Antonio, Texas},
    pages = {269--282},
    priority = {0},
    publisher = {ACM Press},
    series = {POPL '79},
    title = {Systematic design of program analysis frameworks},
    url = {http://dx.doi.org/10.1145/567752.567778},
    year = {1979}
}

@inproceedings{mattmight:Might:2009:APosteriori,
    abstract = {An abstract interpretation's resource-allocation policy ( e.g. , one heap summary node per allocation site) largely determines both its speed and precision. Historically, context has driven allocation policies, and as a result, these policies are said to determine the "context-sensitivity" of the analysis. This work gives analysis designers newfound freedom to manipulate speed and precision by severing the link between allocation policy and context-sensitivity: abstract allocation policies may be unhinged not only from context, but also from even a predefined correspondence with a concrete allocation policy. We do so by proving that abstract allocation policies can be made non-deterministic without sacrificing correctness; this non-determinism permits precision-guided allocation policies previously assumed to be unsafe. To prove correctness, we introduce the notion of  a posteriori  soundness for an analysis. A proof of  a posteriori  soundness differs from a standard proof of soundness in that the abstraction maps used in an  a posteriori  proof cannot be constructed until  after  an analysis has been run. Delaying construction allows them to be built so as to justify the decisions made by non-determinism. The crux of the  a posteriori  soundness theorem is to demonstrate that a justifying abstraction map can  always  be constructed.},
    author = {Might, Matthew and Manolios, Panagiotis},
    booktitle = {VMCAI '09: Proceedings of the 10th International Conference on Verification, Model Checking, and Abstract Interpretation},
    citeulike-article-id = {4838377},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1505362.1505387},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-93900-9\_22},
    date-added = {2009-06-13 20:52:21},
    doi = {10.1007/978-3-540-93900-9\_22},
    isbn = {978-3-540-93899-6},
    keywords = {abstract-interpretation, existential-cfa, static-analysis},
    location = {Savannah, GA},
    pages = {260--274},
    priority = {0},
    publisher = {Springer-Verlag},
    title = {A Posteriori Soundness for Non-deterministic Abstract Interpretations},
    url = {http://dx.doi.org/10.1007/978-3-540-93900-9\_22},
    year = {2009}
}

@article{mattmight:Might:2007:DeltaCFA,
    abstract = {Reasoning about program behaviour in programming languages based on the lambda calculus requires reasoning in a unified way about control, data and environment structure. Previous analysis work has done an inadequate job on the environment component of this task. We develop a new analytic framework,  Δ {CFA}, which is based on a new abstraction: frame strings, an enriched variant of procedure strings that can be used to model both control flow and environment allocation. This abstraction enables new environment-sensitive analyses and transformations that have not been previously attainable. We state the critical theorems needed to establish correctness of the entire technology suite, with their proofs.},
    author = {Might, Matthew and Shivers, Olin},
    citeulike-article-id = {4838326},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.tcs.2006.12.031},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0304397506009200},
    date-added = {2009-06-13 20:44:50},
    day = {01},
    doi = {10.1016/j.tcs.2006.12.031},
    issn = {03043975},
    journal = {Theoretical Computer Science},
    keywords = {cfa, control-flow-analysis, delta-cfa, environment-analysis, frame-strings},
    month = may,
    number = {1-3},
    pages = {137--168},
    priority = {0},
    title = {Analyzing the environment structure of higher-order languages using frame strings},
    url = {http://dx.doi.org/10.1016/j.tcs.2006.12.031},
    volume = {375},
    year = {2007}
}

@article{mattmight:Might:2008:Exploiting,
    abstract = {We present two complementary improvements for abstract-interpretation-based flow analysis of higher-order languages: (1) abstract garbage collection and (2) abstract counting. garbage collection is an analog to its concrete counterpart: the analysis determines when an abstract resource has become unreachable, and then, re-allocates it as fresh. This prevents flow sets from joining during abstract interpretation, which has two immediate effects: (1) the precision of the interpretation increases and (2) its running time often falls. In abstract counting, the analysis tracks how many times an abstract resource has been allocated. A count of one implies that the abstract resource momentarily represents only one concrete resource. This knowledge, in turn, drives environment analysis, expanding the kind (rather than just the degree) of optimization available to the compiler.},
    author = {Might, Matthew and Shivers, Olin},
    citeulike-article-id = {4838293},
    citeulike-linkout-0 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=2519936},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/S0956796808006941},
    date-added = {2009-06-13 20:40:21},
    doi = {10.1017/S0956796808006941},
    journal = {Journal of Functional Programming},
    keywords = {abstract-counting, abstract-garbage-collection, abstract-interpretation, gamma-cfa},
    number = {Special Double Issue 5-6},
    pages = {821--864},
    priority = {0},
    title = {Exploiting reachability and cardinality in higher-order flow analysis},
    url = {http://dx.doi.org/10.1017/S0956796808006941},
    volume = {18},
    year = {2008}
}

@inproceedings{mattmight:Shivers:2006:Continuations,
    abstract = {On-line transducers are an important class of computational agent; we construct and compose together many software systems using them, such as stream processors, layered network protocols, {DSP} networks and graphics pipelines. We show an interesting use of continuations, that, when taken in a {CPS} setting, exposes the control flow of these systems. This enables a {CPS}-based compiler to optimise systems composed of these transducers, using only standard, known analyses and optimisations. Critically, the analysis permits optimisation across the composition of these transducers, allowing efficient construction of systems in a hierarchical way.},
    address = {New York, NY, USA},
    author = {Shivers, Olin and Might, Matthew},
    booktitle = {PLDI '06: Proceedings of the 2006 ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {2601605},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1134016},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1133981.1134016},
    date-added = {2009-06-13 19:04:28},
    doi = {10.1145/1133981.1134016},
    isbn = {1595933204},
    keywords = {continuation, coroutine, coroutine-fusion, super-beta, transducer-fusion},
    pages = {295--307},
    priority = {0},
    publisher = {ACM},
    title = {Continuations and transducer composition},
    url = {http://dx.doi.org/10.1145/1133981.1134016},
    year = {2006}
}

@inproceedings{mattmight:Cousot:1977:AI,
    abstract = {A program denotes computations in some universe of objects. Abstract interpretation of programs consists in using that denotation to describe computations in another universe of abstract objects, so that the resulta of abstract execution give some informations on the actual computations. An intuitive example (which we borrow from Sintzoff [72]) is the rule of signs. The text -1515*17 may be undestood to denote computations on the abstract universe {(+), (-), (+-)} where the semantics of arithmetic operators is defined by the rule of signs. The abstract execution -1515*17 ==> -(+)*(+) ==> (-)*(+) ==> (-), proves that -1515+17 is a negative number. Abstract interpretation is concerned by a particlar underlying structure of the usual universe of computations (the sign, in our example). It gives a summay of some facets of the actual executions of a program. In general this summary is simple to obtain but inacurrate (e.g. -1515+17 ==> -(+)+(+) ==> (-)+(+) ==> (+-)). Despite its fundamental incomplete results abstract interpretation allows the programmer or the compiler to answer questions which do not need full knowledge of program executions or which tolerate an imprecise answer (e.g. partial correctness proofs of programs ignoring the termination problems, type checking, program optimizations which are not carried in the absence of certainty about their feasibility, ...).

Section 3 describes the syntax and mathematical semantics of a simple flowchart language, Scott and Strachey[71]. This mathematical semantics is used in section 4 to built a more abstract model of the semantics of programs, in that it ignores the sequencing of control flow. This model is taken to be the most concrete of the abstract interpretations of programs. Section 5 gives the formal definition of the abstract interpretations of a program. Abstract program properties are modeled by a complete semilattice, Birkoff[61]. Elementary program constructs are locally interpreted by order-preserving functions which are used to associate a system of equations with a program. The program global properties are then defined as one of the extreme fixpoints of that system, Tarski[55]. The abstraction process is defined in section 6. It is shown that the program properties obtained by an abstract interpretation of a program are consistent with those obtained by a more refined interpretation of that program. In particular, an abstract interpretation may be shown to be consistent with the formal semantics of the language. Levels of abstraction are formalized by showing that consistent abstract interpretations form a lattice (section 7). Section 8 gives a constructive definition of abstract properties of programs based on constructive definitions of fixpoints. It shows that various classical algorithms such as Kildall[73], Wegbreit[75], compute program properties as limits of finite Kleene[52]'s sequences. Section 9 introduces finite fixpoint approximation methods to be used when Kleene's sequences are infinite, Cousot[76]. They are shown to be consistent with the abstraction process. Practical examples illustrate the various sections. The conclusion points out that the abstract interpretation of programs is a unified approach to apparently unrelated program analysis techniques.},
    address = {New York, NY, USA},
    author = {Cousot, Patrick and Cousot, Radhia},
    booktitle = {Conference Record of the Fourth ACM Symposium on Principles of Programming Languages},
    citeulike-article-id = {1314814},
    date-added = {2009-06-13 18:59:38},
    keywords = {abstract-interpretation},
    pages = {238--252},
    priority = {0},
    publisher = {ACM Press},
    title = {Abstract interpretation: A unified lattice model for static analysis of programs by construction or approximation of fixpoints},
    year = {1977}
}

@inproceedings{mattmight:Might:2006:GammaCFA,
    abstract = {We present two independent and complementary improvements for flow-based analysis of higher-order languages: (1)  abstract garbage collection  and (2) abstract counting , collectively titled {Gamma-CFA}.  Abstract garbage collection is an analog to its concrete counterpart: we determine when an abstract resource has become unreachable, and then reallocate it as fresh. This prevents flow sets from merging in the abstract, which has two immediate effects: (1) the precision of the analysis is increased, and (2) the running time of the analysis is frequently reduced. In some nontrivial cases, we achieve an order of magnitude improvement in precision and time  simultaneously .In abstract counting, we track how many times an abstract resource has been allocated. A count of one implies that the abstract resource momentarily represents only one concrete resource. This, in turn, allows us to perform environment analysis and to expand the kinds (rather than just the degree) of optimizations available to the compiler.},
    address = {New York, NY, USA},
    author = {Might, Matthew and Shivers, Olin},
    booktitle = {ICFP '06: Proceedings of the 11th {ACM} {SIGPLAN} {I}nternational {C}onference on {F}unctional {P}rogramming},
    citeulike-article-id = {4837509},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1159803.1159807},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1159803.1159807},
    date-added = {2009-06-13 18:52:37},
    doi = {10.1145/1159803.1159807},
    isbn = {1-59593-309-3},
    keywords = {abstract-counting, abstract-garbage-collection, abstract-interpretation, gamma-cfa},
    location = {Portland, Oregon, USA},
    pages = {13--25},
    priority = {0},
    publisher = {ACM},
    title = {Improving flow analyses via {Gamma-CFA}: Abstract garbage collection and counting},
    url = {http://dx.doi.org/10.1145/1159803.1159807},
    year = {2006}
}

@inproceedings{mattmight:Might:2006:DeltaCFA,
    abstract = {We describe a new program-analysis framework, based on {CPS} and procedure-string abstractions, that can handle critical analyses which the  {k-CFA} framework cannot. We present the main theorems concerning correctness, show an application analysis, and describe a running implementation.},
    address = {New York, NY, USA},
    author = {Might, Matthew and Shivers, Olin},
    booktitle = {POPL '06: {C}onference {R}ecord of the 33rd {ACM} {SIGPLAN-SIGACT} {S}ymposium on {P}rinciples of {P}rogramming {L}anguages},
    citeulike-article-id = {4837404},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1111037.1111049},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1111037.1111049},
    date-added = {2009-06-13 18:40:49},
    doi = {10.1145/1111037.1111049},
    isbn = {1-59593-027-2},
    keywords = {abstract-interpretation, delta-cfa, environment-analysis, frame-strings, static-analysis},
    location = {Charleston, South Carolina, USA},
    pages = {127--140},
    priority = {0},
    publisher = {ACM},
    title = {Environment analysis via {Delta-CFA}},
    url = {http://dx.doi.org/10.1145/1111037.1111049},
    year = {2006}
}

@inproceedings{mattmight:Might:2007:LFA,
    abstract = {This work presents a framework for fusing flow analysis and theorem proving called logic-flow analysis ({LFA}). The framework itself is the reduced product of two abstract interpretations: (1) an abstract state machine and (2) a set of propositions in a restricted first-order logic. The motivating application for {LFA} is the safe removal of implicit array-bounds checks without type information, user interaction or program annotation. {LFA} achieves this by delegating a given task to either the prover or the flow analysis depending on which is best suited to discharge it. Described within are a concrete semantics for continuation-passing style; a restricted, first-order logic; a woven product of two abstract interpretations; proofs of correctness; and a worked example.},
    address = {New York, NY, USA},
    author = {Might, Matthew},
    booktitle = {POPL '07: Proceedings of the 34th {A}nnual {ACM} {SIGPLAN-SIGACT} {S}ymposium on {P}rinciples of {P}rogramming {L}anguages},
    citeulike-article-id = {2402753},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1190216.1190247},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1190216.1190247},
    date-added = {2009-06-13 17:39:21},
    doi = {10.1145/1190216.1190247},
    isbn = {1595935754},
    keywords = {abstract-interpretation, lfa, logic-flow-analysis, predicate-abstraction},
    pages = {185--198},
    priority = {0},
    publisher = {ACM},
    title = {Logic-flow analysis of higher-order programs},
    url = {http://dx.doi.org/10.1145/1190216.1190247},
    year = {2007}
}

